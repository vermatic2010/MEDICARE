{"ast":null,"code":"/**\n * marked v15.0.12 - a markdown parser\n * Copyright (c) 2011-2025, Christopher Jeffrey. (MIT Licensed)\n * https://github.com/markedjs/marked\n */\n\n/**\n * DO NOT EDIT THIS FILE\n * The code in this file is generated from files in ./src/\n */\n\n// src/defaults.ts\nfunction _getDefaults() {\n  return {\n    async: false,\n    breaks: false,\n    extensions: null,\n    gfm: true,\n    hooks: null,\n    pedantic: false,\n    renderer: null,\n    silent: false,\n    tokenizer: null,\n    walkTokens: null\n  };\n}\nvar _defaults = _getDefaults();\nfunction changeDefaults(newDefaults) {\n  _defaults = newDefaults;\n}\n\n// src/rules.ts\nvar noopTest = {\n  exec: () => null\n};\nfunction edit(regex, opt = \"\") {\n  let source = typeof regex === \"string\" ? regex : regex.source;\n  const obj = {\n    replace: (name, val) => {\n      let valSource = typeof val === \"string\" ? val : val.source;\n      valSource = valSource.replace(other.caret, \"$1\");\n      source = source.replace(name, valSource);\n      return obj;\n    },\n    getRegex: () => {\n      return new RegExp(source, opt);\n    }\n  };\n  return obj;\n}\nvar other = {\n  codeRemoveIndent: /^(?: {1,4}| {0,3}\\t)/gm,\n  outputLinkReplace: /\\\\([\\[\\]])/g,\n  indentCodeCompensation: /^(\\s+)(?:```)/,\n  beginningSpace: /^\\s+/,\n  endingHash: /#$/,\n  startingSpaceChar: /^ /,\n  endingSpaceChar: / $/,\n  nonSpaceChar: /[^ ]/,\n  newLineCharGlobal: /\\n/g,\n  tabCharGlobal: /\\t/g,\n  multipleSpaceGlobal: /\\s+/g,\n  blankLine: /^[ \\t]*$/,\n  doubleBlankLine: /\\n[ \\t]*\\n[ \\t]*$/,\n  blockquoteStart: /^ {0,3}>/,\n  blockquoteSetextReplace: /\\n {0,3}((?:=+|-+) *)(?=\\n|$)/g,\n  blockquoteSetextReplace2: /^ {0,3}>[ \\t]?/gm,\n  listReplaceTabs: /^\\t+/,\n  listReplaceNesting: /^ {1,4}(?=( {4})*[^ ])/g,\n  listIsTask: /^\\[[ xX]\\] /,\n  listReplaceTask: /^\\[[ xX]\\] +/,\n  anyLine: /\\n.*\\n/,\n  hrefBrackets: /^<(.*)>$/,\n  tableDelimiter: /[:|]/,\n  tableAlignChars: /^\\||\\| *$/g,\n  tableRowBlankLine: /\\n[ \\t]*$/,\n  tableAlignRight: /^ *-+: *$/,\n  tableAlignCenter: /^ *:-+: *$/,\n  tableAlignLeft: /^ *:-+ *$/,\n  startATag: /^<a /i,\n  endATag: /^<\\/a>/i,\n  startPreScriptTag: /^<(pre|code|kbd|script)(\\s|>)/i,\n  endPreScriptTag: /^<\\/(pre|code|kbd|script)(\\s|>)/i,\n  startAngleBracket: /^</,\n  endAngleBracket: />$/,\n  pedanticHrefTitle: /^([^'\"]*[^\\s])\\s+(['\"])(.*)\\2/,\n  unicodeAlphaNumeric: /[\\p{L}\\p{N}]/u,\n  escapeTest: /[&<>\"']/,\n  escapeReplace: /[&<>\"']/g,\n  escapeTestNoEncode: /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/,\n  escapeReplaceNoEncode: /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/g,\n  unescapeTest: /&(#(?:\\d+)|(?:#x[0-9A-Fa-f]+)|(?:\\w+));?/ig,\n  caret: /(^|[^\\[])\\^/g,\n  percentDecode: /%25/g,\n  findPipe: /\\|/g,\n  splitPipe: / \\|/,\n  slashPipe: /\\\\\\|/g,\n  carriageReturn: /\\r\\n|\\r/g,\n  spaceLine: /^ +$/gm,\n  notSpaceStart: /^\\S*/,\n  endingNewline: /\\n$/,\n  listItemRegex: bull => new RegExp(`^( {0,3}${bull})((?:[\t ][^\\\\n]*)?(?:\\\\n|$))`),\n  nextBulletRegex: indent => new RegExp(`^ {0,${Math.min(3, indent - 1)}}(?:[*+-]|\\\\d{1,9}[.)])((?:[ \t][^\\\\n]*)?(?:\\\\n|$))`),\n  hrRegex: indent => new RegExp(`^ {0,${Math.min(3, indent - 1)}}((?:- *){3,}|(?:_ *){3,}|(?:\\\\* *){3,})(?:\\\\n+|$)`),\n  fencesBeginRegex: indent => new RegExp(`^ {0,${Math.min(3, indent - 1)}}(?:\\`\\`\\`|~~~)`),\n  headingBeginRegex: indent => new RegExp(`^ {0,${Math.min(3, indent - 1)}}#`),\n  htmlBeginRegex: indent => new RegExp(`^ {0,${Math.min(3, indent - 1)}}<(?:[a-z].*>|!--)`, \"i\")\n};\nvar newline = /^(?:[ \\t]*(?:\\n|$))+/;\nvar blockCode = /^((?: {4}| {0,3}\\t)[^\\n]+(?:\\n(?:[ \\t]*(?:\\n|$))*)?)+/;\nvar fences = /^ {0,3}(`{3,}(?=[^`\\n]*(?:\\n|$))|~{3,})([^\\n]*)(?:\\n|$)(?:|([\\s\\S]*?)(?:\\n|$))(?: {0,3}\\1[~`]* *(?=\\n|$)|$)/;\nvar hr = /^ {0,3}((?:-[\\t ]*){3,}|(?:_[ \\t]*){3,}|(?:\\*[ \\t]*){3,})(?:\\n+|$)/;\nvar heading = /^ {0,3}(#{1,6})(?=\\s|$)(.*)(?:\\n+|$)/;\nvar bullet = /(?:[*+-]|\\d{1,9}[.)])/;\nvar lheadingCore = /^(?!bull |blockCode|fences|blockquote|heading|html|table)((?:.|\\n(?!\\s*?\\n|bull |blockCode|fences|blockquote|heading|html|table))+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/;\nvar lheading = edit(lheadingCore).replace(/bull/g, bullet).replace(/blockCode/g, /(?: {4}| {0,3}\\t)/).replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/).replace(/blockquote/g, / {0,3}>/).replace(/heading/g, / {0,3}#{1,6}/).replace(/html/g, / {0,3}<[^\\n>]+>\\n/).replace(/\\|table/g, \"\").getRegex();\nvar lheadingGfm = edit(lheadingCore).replace(/bull/g, bullet).replace(/blockCode/g, /(?: {4}| {0,3}\\t)/).replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/).replace(/blockquote/g, / {0,3}>/).replace(/heading/g, / {0,3}#{1,6}/).replace(/html/g, / {0,3}<[^\\n>]+>\\n/).replace(/table/g, / {0,3}\\|?(?:[:\\- ]*\\|)+[\\:\\- ]*\\n/).getRegex();\nvar _paragraph = /^([^\\n]+(?:\\n(?!hr|heading|lheading|blockquote|fences|list|html|table| +\\n)[^\\n]+)*)/;\nvar blockText = /^[^\\n]+/;\nvar _blockLabel = /(?!\\s*\\])(?:\\\\.|[^\\[\\]\\\\])+/;\nvar def = edit(/^ {0,3}\\[(label)\\]: *(?:\\n[ \\t]*)?([^<\\s][^\\s]*|<.*?>)(?:(?: +(?:\\n[ \\t]*)?| *\\n[ \\t]*)(title))? *(?:\\n+|$)/).replace(\"label\", _blockLabel).replace(\"title\", /(?:\"(?:\\\\\"?|[^\"\\\\])*\"|'[^'\\n]*(?:\\n[^'\\n]+)*\\n?'|\\([^()]*\\))/).getRegex();\nvar list = edit(/^( {0,3}bull)([ \\t][^\\n]+?)?(?:\\n|$)/).replace(/bull/g, bullet).getRegex();\nvar _tag = \"address|article|aside|base|basefont|blockquote|body|caption|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option|p|param|search|section|summary|table|tbody|td|tfoot|th|thead|title|tr|track|ul\";\nvar _comment = /<!--(?:-?>|[\\s\\S]*?(?:-->|$))/;\nvar html = edit(\"^ {0,3}(?:<(script|pre|style|textarea)[\\\\s>][\\\\s\\\\S]*?(?:</\\\\1>[^\\\\n]*\\\\n+|$)|comment[^\\\\n]*(\\\\n+|$)|<\\\\?[\\\\s\\\\S]*?(?:\\\\?>\\\\n*|$)|<![A-Z][\\\\s\\\\S]*?(?:>\\\\n*|$)|<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?(?:\\\\]\\\\]>\\\\n*|$)|</?(tag)(?: +|\\\\n|/?>)[\\\\s\\\\S]*?(?:(?:\\\\n[ \t]*)+\\\\n|$)|<(?!script|pre|style|textarea)([a-z][\\\\w-]*)(?:attribute)*? */?>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \t]*)+\\\\n|$)|</(?!script|pre|style|textarea)[a-z][\\\\w-]*\\\\s*>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \t]*)+\\\\n|$))\", \"i\").replace(\"comment\", _comment).replace(\"tag\", _tag).replace(\"attribute\", / +[a-zA-Z:_][\\w.:-]*(?: *= *\"[^\"\\n]*\"| *= *'[^'\\n]*'| *= *[^\\s\"'=<>`]+)?/).getRegex();\nvar paragraph = edit(_paragraph).replace(\"hr\", hr).replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\").replace(\"|lheading\", \"\").replace(\"|table\", \"\").replace(\"blockquote\", \" {0,3}>\").replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\").replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \").replace(\"html\", \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\").replace(\"tag\", _tag).getRegex();\nvar blockquote = edit(/^( {0,3}> ?(paragraph|[^\\n]*)(?:\\n|$))+/).replace(\"paragraph\", paragraph).getRegex();\nvar blockNormal = {\n  blockquote,\n  code: blockCode,\n  def,\n  fences,\n  heading,\n  hr,\n  html,\n  lheading,\n  list,\n  newline,\n  paragraph,\n  table: noopTest,\n  text: blockText\n};\nvar gfmTable = edit(\"^ *([^\\\\n ].*)\\\\n {0,3}((?:\\\\| *)?:?-+:? *(?:\\\\| *:?-+:? *)*(?:\\\\| *)?)(?:\\\\n((?:(?! *\\\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\\\n|$))*)\\\\n*|$)\").replace(\"hr\", hr).replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\").replace(\"blockquote\", \" {0,3}>\").replace(\"code\", \"(?: {4}| {0,3}\t)[^\\\\n]\").replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\").replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \").replace(\"html\", \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\").replace(\"tag\", _tag).getRegex();\nvar blockGfm = {\n  ...blockNormal,\n  lheading: lheadingGfm,\n  table: gfmTable,\n  paragraph: edit(_paragraph).replace(\"hr\", hr).replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\").replace(\"|lheading\", \"\").replace(\"table\", gfmTable).replace(\"blockquote\", \" {0,3}>\").replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\").replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \").replace(\"html\", \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\").replace(\"tag\", _tag).getRegex()\n};\nvar blockPedantic = {\n  ...blockNormal,\n  html: edit(`^ *(?:comment *(?:\\\\n|\\\\s*$)|<(tag)[\\\\s\\\\S]+?</\\\\1> *(?:\\\\n{2,}|\\\\s*$)|<tag(?:\"[^\"]*\"|'[^']*'|\\\\s[^'\"/>\\\\s]*)*?/?> *(?:\\\\n{2,}|\\\\s*$))`).replace(\"comment\", _comment).replace(/tag/g, \"(?!(?:a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)\\\\b)\\\\w+(?!:|[^\\\\w\\\\s@]*@)\\\\b\").getRegex(),\n  def: /^ *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +([\"(][^\\n]+[\")]))? *(?:\\n+|$)/,\n  heading: /^(#{1,6})(.*)(?:\\n+|$)/,\n  fences: noopTest,\n  // fences not supported\n  lheading: /^(.+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/,\n  paragraph: edit(_paragraph).replace(\"hr\", hr).replace(\"heading\", \" *#{1,6} *[^\\n]\").replace(\"lheading\", lheading).replace(\"|table\", \"\").replace(\"blockquote\", \" {0,3}>\").replace(\"|fences\", \"\").replace(\"|list\", \"\").replace(\"|html\", \"\").replace(\"|tag\", \"\").getRegex()\n};\nvar escape = /^\\\\([!\"#$%&'()*+,\\-./:;<=>?@\\[\\]\\\\^_`{|}~])/;\nvar inlineCode = /^(`+)([^`]|[^`][\\s\\S]*?[^`])\\1(?!`)/;\nvar br = /^( {2,}|\\\\)\\n(?!\\s*$)/;\nvar inlineText = /^(`+|[^`])(?:(?= {2,}\\n)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*_]|\\b_|$)|[^ ](?= {2,}\\n)))/;\nvar _punctuation = /[\\p{P}\\p{S}]/u;\nvar _punctuationOrSpace = /[\\s\\p{P}\\p{S}]/u;\nvar _notPunctuationOrSpace = /[^\\s\\p{P}\\p{S}]/u;\nvar punctuation = edit(/^((?![*_])punctSpace)/, \"u\").replace(/punctSpace/g, _punctuationOrSpace).getRegex();\nvar _punctuationGfmStrongEm = /(?!~)[\\p{P}\\p{S}]/u;\nvar _punctuationOrSpaceGfmStrongEm = /(?!~)[\\s\\p{P}\\p{S}]/u;\nvar _notPunctuationOrSpaceGfmStrongEm = /(?:[^\\s\\p{P}\\p{S}]|~)/u;\nvar blockSkip = /\\[[^[\\]]*?\\]\\((?:\\\\.|[^\\\\\\(\\)]|\\((?:\\\\.|[^\\\\\\(\\)])*\\))*\\)|`[^`]*?`|<[^<>]*?>/g;\nvar emStrongLDelimCore = /^(?:\\*+(?:((?!\\*)punct)|[^\\s*]))|^_+(?:((?!_)punct)|([^\\s_]))/;\nvar emStrongLDelim = edit(emStrongLDelimCore, \"u\").replace(/punct/g, _punctuation).getRegex();\nvar emStrongLDelimGfm = edit(emStrongLDelimCore, \"u\").replace(/punct/g, _punctuationGfmStrongEm).getRegex();\nvar emStrongRDelimAstCore = \"^[^_*]*?__[^_*]*?\\\\*[^_*]*?(?=__)|[^*]+(?=[^*])|(?!\\\\*)punct(\\\\*+)(?=[\\\\s]|$)|notPunctSpace(\\\\*+)(?!\\\\*)(?=punctSpace|$)|(?!\\\\*)punctSpace(\\\\*+)(?=notPunctSpace)|[\\\\s](\\\\*+)(?!\\\\*)(?=punct)|(?!\\\\*)punct(\\\\*+)(?!\\\\*)(?=punct)|notPunctSpace(\\\\*+)(?=notPunctSpace)\";\nvar emStrongRDelimAst = edit(emStrongRDelimAstCore, \"gu\").replace(/notPunctSpace/g, _notPunctuationOrSpace).replace(/punctSpace/g, _punctuationOrSpace).replace(/punct/g, _punctuation).getRegex();\nvar emStrongRDelimAstGfm = edit(emStrongRDelimAstCore, \"gu\").replace(/notPunctSpace/g, _notPunctuationOrSpaceGfmStrongEm).replace(/punctSpace/g, _punctuationOrSpaceGfmStrongEm).replace(/punct/g, _punctuationGfmStrongEm).getRegex();\nvar emStrongRDelimUnd = edit(\"^[^_*]*?\\\\*\\\\*[^_*]*?_[^_*]*?(?=\\\\*\\\\*)|[^_]+(?=[^_])|(?!_)punct(_+)(?=[\\\\s]|$)|notPunctSpace(_+)(?!_)(?=punctSpace|$)|(?!_)punctSpace(_+)(?=notPunctSpace)|[\\\\s](_+)(?!_)(?=punct)|(?!_)punct(_+)(?!_)(?=punct)\", \"gu\").replace(/notPunctSpace/g, _notPunctuationOrSpace).replace(/punctSpace/g, _punctuationOrSpace).replace(/punct/g, _punctuation).getRegex();\nvar anyPunctuation = edit(/\\\\(punct)/, \"gu\").replace(/punct/g, _punctuation).getRegex();\nvar autolink = edit(/^<(scheme:[^\\s\\x00-\\x1f<>]*|email)>/).replace(\"scheme\", /[a-zA-Z][a-zA-Z0-9+.-]{1,31}/).replace(\"email\", /[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/).getRegex();\nvar _inlineComment = edit(_comment).replace(\"(?:-->|$)\", \"-->\").getRegex();\nvar tag = edit(\"^comment|^</[a-zA-Z][\\\\w:-]*\\\\s*>|^<[a-zA-Z][\\\\w-]*(?:attribute)*?\\\\s*/?>|^<\\\\?[\\\\s\\\\S]*?\\\\?>|^<![a-zA-Z]+\\\\s[\\\\s\\\\S]*?>|^<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?\\\\]\\\\]>\").replace(\"comment\", _inlineComment).replace(\"attribute\", /\\s+[a-zA-Z:_][\\w.:-]*(?:\\s*=\\s*\"[^\"]*\"|\\s*=\\s*'[^']*'|\\s*=\\s*[^\\s\"'=<>`]+)?/).getRegex();\nvar _inlineLabel = /(?:\\[(?:\\\\.|[^\\[\\]\\\\])*\\]|\\\\.|`[^`]*`|[^\\[\\]\\\\`])*?/;\nvar link = edit(/^!?\\[(label)\\]\\(\\s*(href)(?:(?:[ \\t]*(?:\\n[ \\t]*)?)(title))?\\s*\\)/).replace(\"label\", _inlineLabel).replace(\"href\", /<(?:\\\\.|[^\\n<>\\\\])+>|[^ \\t\\n\\x00-\\x1f]*/).replace(\"title\", /\"(?:\\\\\"?|[^\"\\\\])*\"|'(?:\\\\'?|[^'\\\\])*'|\\((?:\\\\\\)?|[^)\\\\])*\\)/).getRegex();\nvar reflink = edit(/^!?\\[(label)\\]\\[(ref)\\]/).replace(\"label\", _inlineLabel).replace(\"ref\", _blockLabel).getRegex();\nvar nolink = edit(/^!?\\[(ref)\\](?:\\[\\])?/).replace(\"ref\", _blockLabel).getRegex();\nvar reflinkSearch = edit(\"reflink|nolink(?!\\\\()\", \"g\").replace(\"reflink\", reflink).replace(\"nolink\", nolink).getRegex();\nvar inlineNormal = {\n  _backpedal: noopTest,\n  // only used for GFM url\n  anyPunctuation,\n  autolink,\n  blockSkip,\n  br,\n  code: inlineCode,\n  del: noopTest,\n  emStrongLDelim,\n  emStrongRDelimAst,\n  emStrongRDelimUnd,\n  escape,\n  link,\n  nolink,\n  punctuation,\n  reflink,\n  reflinkSearch,\n  tag,\n  text: inlineText,\n  url: noopTest\n};\nvar inlinePedantic = {\n  ...inlineNormal,\n  link: edit(/^!?\\[(label)\\]\\((.*?)\\)/).replace(\"label\", _inlineLabel).getRegex(),\n  reflink: edit(/^!?\\[(label)\\]\\s*\\[([^\\]]*)\\]/).replace(\"label\", _inlineLabel).getRegex()\n};\nvar inlineGfm = {\n  ...inlineNormal,\n  emStrongRDelimAst: emStrongRDelimAstGfm,\n  emStrongLDelim: emStrongLDelimGfm,\n  url: edit(/^((?:ftp|https?):\\/\\/|www\\.)(?:[a-zA-Z0-9\\-]+\\.?)+[^\\s<]*|^email/, \"i\").replace(\"email\", /[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/).getRegex(),\n  _backpedal: /(?:[^?!.,:;*_'\"~()&]+|\\([^)]*\\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_'\"~)]+(?!$))+/,\n  del: /^(~~?)(?=[^\\s~])((?:\\\\.|[^\\\\])*?(?:\\\\.|[^\\s~\\\\]))\\1(?=[^~]|$)/,\n  text: /^([`~]+|[^`~])(?:(?= {2,}\\n)|(?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*~_]|\\b_|https?:\\/\\/|ftp:\\/\\/|www\\.|$)|[^ ](?= {2,}\\n)|[^a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-](?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)))/\n};\nvar inlineBreaks = {\n  ...inlineGfm,\n  br: edit(br).replace(\"{2,}\", \"*\").getRegex(),\n  text: edit(inlineGfm.text).replace(\"\\\\b_\", \"\\\\b_| {2,}\\\\n\").replace(/\\{2,\\}/g, \"*\").getRegex()\n};\nvar block = {\n  normal: blockNormal,\n  gfm: blockGfm,\n  pedantic: blockPedantic\n};\nvar inline = {\n  normal: inlineNormal,\n  gfm: inlineGfm,\n  breaks: inlineBreaks,\n  pedantic: inlinePedantic\n};\n\n// src/helpers.ts\nvar escapeReplacements = {\n  \"&\": \"&amp;\",\n  \"<\": \"&lt;\",\n  \">\": \"&gt;\",\n  '\"': \"&quot;\",\n  \"'\": \"&#39;\"\n};\nvar getEscapeReplacement = ch => escapeReplacements[ch];\nfunction escape2(html2, encode) {\n  if (encode) {\n    if (other.escapeTest.test(html2)) {\n      return html2.replace(other.escapeReplace, getEscapeReplacement);\n    }\n  } else {\n    if (other.escapeTestNoEncode.test(html2)) {\n      return html2.replace(other.escapeReplaceNoEncode, getEscapeReplacement);\n    }\n  }\n  return html2;\n}\nfunction cleanUrl(href) {\n  try {\n    href = encodeURI(href).replace(other.percentDecode, \"%\");\n  } catch {\n    return null;\n  }\n  return href;\n}\nfunction splitCells(tableRow, count) {\n  const row = tableRow.replace(other.findPipe, (match, offset, str) => {\n      let escaped = false;\n      let curr = offset;\n      while (--curr >= 0 && str[curr] === \"\\\\\") escaped = !escaped;\n      if (escaped) {\n        return \"|\";\n      } else {\n        return \" |\";\n      }\n    }),\n    cells = row.split(other.splitPipe);\n  let i = 0;\n  if (!cells[0].trim()) {\n    cells.shift();\n  }\n  if (cells.length > 0 && !cells.at(-1)?.trim()) {\n    cells.pop();\n  }\n  if (count) {\n    if (cells.length > count) {\n      cells.splice(count);\n    } else {\n      while (cells.length < count) cells.push(\"\");\n    }\n  }\n  for (; i < cells.length; i++) {\n    cells[i] = cells[i].trim().replace(other.slashPipe, \"|\");\n  }\n  return cells;\n}\nfunction rtrim(str, c, invert) {\n  const l = str.length;\n  if (l === 0) {\n    return \"\";\n  }\n  let suffLen = 0;\n  while (suffLen < l) {\n    const currChar = str.charAt(l - suffLen - 1);\n    if (currChar === c && !invert) {\n      suffLen++;\n    } else if (currChar !== c && invert) {\n      suffLen++;\n    } else {\n      break;\n    }\n  }\n  return str.slice(0, l - suffLen);\n}\nfunction findClosingBracket(str, b) {\n  if (str.indexOf(b[1]) === -1) {\n    return -1;\n  }\n  let level = 0;\n  for (let i = 0; i < str.length; i++) {\n    if (str[i] === \"\\\\\") {\n      i++;\n    } else if (str[i] === b[0]) {\n      level++;\n    } else if (str[i] === b[1]) {\n      level--;\n      if (level < 0) {\n        return i;\n      }\n    }\n  }\n  if (level > 0) {\n    return -2;\n  }\n  return -1;\n}\n\n// src/Tokenizer.ts\nfunction outputLink(cap, link2, raw, lexer2, rules) {\n  const href = link2.href;\n  const title = link2.title || null;\n  const text = cap[1].replace(rules.other.outputLinkReplace, \"$1\");\n  lexer2.state.inLink = true;\n  const token = {\n    type: cap[0].charAt(0) === \"!\" ? \"image\" : \"link\",\n    raw,\n    href,\n    title,\n    text,\n    tokens: lexer2.inlineTokens(text)\n  };\n  lexer2.state.inLink = false;\n  return token;\n}\nfunction indentCodeCompensation(raw, text, rules) {\n  const matchIndentToCode = raw.match(rules.other.indentCodeCompensation);\n  if (matchIndentToCode === null) {\n    return text;\n  }\n  const indentToCode = matchIndentToCode[1];\n  return text.split(\"\\n\").map(node => {\n    const matchIndentInNode = node.match(rules.other.beginningSpace);\n    if (matchIndentInNode === null) {\n      return node;\n    }\n    const [indentInNode] = matchIndentInNode;\n    if (indentInNode.length >= indentToCode.length) {\n      return node.slice(indentToCode.length);\n    }\n    return node;\n  }).join(\"\\n\");\n}\nvar _Tokenizer = class {\n  options;\n  rules;\n  // set by the lexer\n  lexer;\n  // set by the lexer\n  constructor(options2) {\n    this.options = options2 || _defaults;\n  }\n  space(src) {\n    const cap = this.rules.block.newline.exec(src);\n    if (cap && cap[0].length > 0) {\n      return {\n        type: \"space\",\n        raw: cap[0]\n      };\n    }\n  }\n  code(src) {\n    const cap = this.rules.block.code.exec(src);\n    if (cap) {\n      const text = cap[0].replace(this.rules.other.codeRemoveIndent, \"\");\n      return {\n        type: \"code\",\n        raw: cap[0],\n        codeBlockStyle: \"indented\",\n        text: !this.options.pedantic ? rtrim(text, \"\\n\") : text\n      };\n    }\n  }\n  fences(src) {\n    const cap = this.rules.block.fences.exec(src);\n    if (cap) {\n      const raw = cap[0];\n      const text = indentCodeCompensation(raw, cap[3] || \"\", this.rules);\n      return {\n        type: \"code\",\n        raw,\n        lang: cap[2] ? cap[2].trim().replace(this.rules.inline.anyPunctuation, \"$1\") : cap[2],\n        text\n      };\n    }\n  }\n  heading(src) {\n    const cap = this.rules.block.heading.exec(src);\n    if (cap) {\n      let text = cap[2].trim();\n      if (this.rules.other.endingHash.test(text)) {\n        const trimmed = rtrim(text, \"#\");\n        if (this.options.pedantic) {\n          text = trimmed.trim();\n        } else if (!trimmed || this.rules.other.endingSpaceChar.test(trimmed)) {\n          text = trimmed.trim();\n        }\n      }\n      return {\n        type: \"heading\",\n        raw: cap[0],\n        depth: cap[1].length,\n        text,\n        tokens: this.lexer.inline(text)\n      };\n    }\n  }\n  hr(src) {\n    const cap = this.rules.block.hr.exec(src);\n    if (cap) {\n      return {\n        type: \"hr\",\n        raw: rtrim(cap[0], \"\\n\")\n      };\n    }\n  }\n  blockquote(src) {\n    const cap = this.rules.block.blockquote.exec(src);\n    if (cap) {\n      let lines = rtrim(cap[0], \"\\n\").split(\"\\n\");\n      let raw = \"\";\n      let text = \"\";\n      const tokens = [];\n      while (lines.length > 0) {\n        let inBlockquote = false;\n        const currentLines = [];\n        let i;\n        for (i = 0; i < lines.length; i++) {\n          if (this.rules.other.blockquoteStart.test(lines[i])) {\n            currentLines.push(lines[i]);\n            inBlockquote = true;\n          } else if (!inBlockquote) {\n            currentLines.push(lines[i]);\n          } else {\n            break;\n          }\n        }\n        lines = lines.slice(i);\n        const currentRaw = currentLines.join(\"\\n\");\n        const currentText = currentRaw.replace(this.rules.other.blockquoteSetextReplace, \"\\n    $1\").replace(this.rules.other.blockquoteSetextReplace2, \"\");\n        raw = raw ? `${raw}\n${currentRaw}` : currentRaw;\n        text = text ? `${text}\n${currentText}` : currentText;\n        const top = this.lexer.state.top;\n        this.lexer.state.top = true;\n        this.lexer.blockTokens(currentText, tokens, true);\n        this.lexer.state.top = top;\n        if (lines.length === 0) {\n          break;\n        }\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === \"code\") {\n          break;\n        } else if (lastToken?.type === \"blockquote\") {\n          const oldToken = lastToken;\n          const newText = oldToken.raw + \"\\n\" + lines.join(\"\\n\");\n          const newToken = this.blockquote(newText);\n          tokens[tokens.length - 1] = newToken;\n          raw = raw.substring(0, raw.length - oldToken.raw.length) + newToken.raw;\n          text = text.substring(0, text.length - oldToken.text.length) + newToken.text;\n          break;\n        } else if (lastToken?.type === \"list\") {\n          const oldToken = lastToken;\n          const newText = oldToken.raw + \"\\n\" + lines.join(\"\\n\");\n          const newToken = this.list(newText);\n          tokens[tokens.length - 1] = newToken;\n          raw = raw.substring(0, raw.length - lastToken.raw.length) + newToken.raw;\n          text = text.substring(0, text.length - oldToken.raw.length) + newToken.raw;\n          lines = newText.substring(tokens.at(-1).raw.length).split(\"\\n\");\n          continue;\n        }\n      }\n      return {\n        type: \"blockquote\",\n        raw,\n        tokens,\n        text\n      };\n    }\n  }\n  list(src) {\n    let cap = this.rules.block.list.exec(src);\n    if (cap) {\n      let bull = cap[1].trim();\n      const isordered = bull.length > 1;\n      const list2 = {\n        type: \"list\",\n        raw: \"\",\n        ordered: isordered,\n        start: isordered ? +bull.slice(0, -1) : \"\",\n        loose: false,\n        items: []\n      };\n      bull = isordered ? `\\\\d{1,9}\\\\${bull.slice(-1)}` : `\\\\${bull}`;\n      if (this.options.pedantic) {\n        bull = isordered ? bull : \"[*+-]\";\n      }\n      const itemRegex = this.rules.other.listItemRegex(bull);\n      let endsWithBlankLine = false;\n      while (src) {\n        let endEarly = false;\n        let raw = \"\";\n        let itemContents = \"\";\n        if (!(cap = itemRegex.exec(src))) {\n          break;\n        }\n        if (this.rules.block.hr.test(src)) {\n          break;\n        }\n        raw = cap[0];\n        src = src.substring(raw.length);\n        let line = cap[2].split(\"\\n\", 1)[0].replace(this.rules.other.listReplaceTabs, t => \" \".repeat(3 * t.length));\n        let nextLine = src.split(\"\\n\", 1)[0];\n        let blankLine = !line.trim();\n        let indent = 0;\n        if (this.options.pedantic) {\n          indent = 2;\n          itemContents = line.trimStart();\n        } else if (blankLine) {\n          indent = cap[1].length + 1;\n        } else {\n          indent = cap[2].search(this.rules.other.nonSpaceChar);\n          indent = indent > 4 ? 1 : indent;\n          itemContents = line.slice(indent);\n          indent += cap[1].length;\n        }\n        if (blankLine && this.rules.other.blankLine.test(nextLine)) {\n          raw += nextLine + \"\\n\";\n          src = src.substring(nextLine.length + 1);\n          endEarly = true;\n        }\n        if (!endEarly) {\n          const nextBulletRegex = this.rules.other.nextBulletRegex(indent);\n          const hrRegex = this.rules.other.hrRegex(indent);\n          const fencesBeginRegex = this.rules.other.fencesBeginRegex(indent);\n          const headingBeginRegex = this.rules.other.headingBeginRegex(indent);\n          const htmlBeginRegex = this.rules.other.htmlBeginRegex(indent);\n          while (src) {\n            const rawLine = src.split(\"\\n\", 1)[0];\n            let nextLineWithoutTabs;\n            nextLine = rawLine;\n            if (this.options.pedantic) {\n              nextLine = nextLine.replace(this.rules.other.listReplaceNesting, \"  \");\n              nextLineWithoutTabs = nextLine;\n            } else {\n              nextLineWithoutTabs = nextLine.replace(this.rules.other.tabCharGlobal, \"    \");\n            }\n            if (fencesBeginRegex.test(nextLine)) {\n              break;\n            }\n            if (headingBeginRegex.test(nextLine)) {\n              break;\n            }\n            if (htmlBeginRegex.test(nextLine)) {\n              break;\n            }\n            if (nextBulletRegex.test(nextLine)) {\n              break;\n            }\n            if (hrRegex.test(nextLine)) {\n              break;\n            }\n            if (nextLineWithoutTabs.search(this.rules.other.nonSpaceChar) >= indent || !nextLine.trim()) {\n              itemContents += \"\\n\" + nextLineWithoutTabs.slice(indent);\n            } else {\n              if (blankLine) {\n                break;\n              }\n              if (line.replace(this.rules.other.tabCharGlobal, \"    \").search(this.rules.other.nonSpaceChar) >= 4) {\n                break;\n              }\n              if (fencesBeginRegex.test(line)) {\n                break;\n              }\n              if (headingBeginRegex.test(line)) {\n                break;\n              }\n              if (hrRegex.test(line)) {\n                break;\n              }\n              itemContents += \"\\n\" + nextLine;\n            }\n            if (!blankLine && !nextLine.trim()) {\n              blankLine = true;\n            }\n            raw += rawLine + \"\\n\";\n            src = src.substring(rawLine.length + 1);\n            line = nextLineWithoutTabs.slice(indent);\n          }\n        }\n        if (!list2.loose) {\n          if (endsWithBlankLine) {\n            list2.loose = true;\n          } else if (this.rules.other.doubleBlankLine.test(raw)) {\n            endsWithBlankLine = true;\n          }\n        }\n        let istask = null;\n        let ischecked;\n        if (this.options.gfm) {\n          istask = this.rules.other.listIsTask.exec(itemContents);\n          if (istask) {\n            ischecked = istask[0] !== \"[ ] \";\n            itemContents = itemContents.replace(this.rules.other.listReplaceTask, \"\");\n          }\n        }\n        list2.items.push({\n          type: \"list_item\",\n          raw,\n          task: !!istask,\n          checked: ischecked,\n          loose: false,\n          text: itemContents,\n          tokens: []\n        });\n        list2.raw += raw;\n      }\n      const lastItem = list2.items.at(-1);\n      if (lastItem) {\n        lastItem.raw = lastItem.raw.trimEnd();\n        lastItem.text = lastItem.text.trimEnd();\n      } else {\n        return;\n      }\n      list2.raw = list2.raw.trimEnd();\n      for (let i = 0; i < list2.items.length; i++) {\n        this.lexer.state.top = false;\n        list2.items[i].tokens = this.lexer.blockTokens(list2.items[i].text, []);\n        if (!list2.loose) {\n          const spacers = list2.items[i].tokens.filter(t => t.type === \"space\");\n          const hasMultipleLineBreaks = spacers.length > 0 && spacers.some(t => this.rules.other.anyLine.test(t.raw));\n          list2.loose = hasMultipleLineBreaks;\n        }\n      }\n      if (list2.loose) {\n        for (let i = 0; i < list2.items.length; i++) {\n          list2.items[i].loose = true;\n        }\n      }\n      return list2;\n    }\n  }\n  html(src) {\n    const cap = this.rules.block.html.exec(src);\n    if (cap) {\n      const token = {\n        type: \"html\",\n        block: true,\n        raw: cap[0],\n        pre: cap[1] === \"pre\" || cap[1] === \"script\" || cap[1] === \"style\",\n        text: cap[0]\n      };\n      return token;\n    }\n  }\n  def(src) {\n    const cap = this.rules.block.def.exec(src);\n    if (cap) {\n      const tag2 = cap[1].toLowerCase().replace(this.rules.other.multipleSpaceGlobal, \" \");\n      const href = cap[2] ? cap[2].replace(this.rules.other.hrefBrackets, \"$1\").replace(this.rules.inline.anyPunctuation, \"$1\") : \"\";\n      const title = cap[3] ? cap[3].substring(1, cap[3].length - 1).replace(this.rules.inline.anyPunctuation, \"$1\") : cap[3];\n      return {\n        type: \"def\",\n        tag: tag2,\n        raw: cap[0],\n        href,\n        title\n      };\n    }\n  }\n  table(src) {\n    const cap = this.rules.block.table.exec(src);\n    if (!cap) {\n      return;\n    }\n    if (!this.rules.other.tableDelimiter.test(cap[2])) {\n      return;\n    }\n    const headers = splitCells(cap[1]);\n    const aligns = cap[2].replace(this.rules.other.tableAlignChars, \"\").split(\"|\");\n    const rows = cap[3]?.trim() ? cap[3].replace(this.rules.other.tableRowBlankLine, \"\").split(\"\\n\") : [];\n    const item = {\n      type: \"table\",\n      raw: cap[0],\n      header: [],\n      align: [],\n      rows: []\n    };\n    if (headers.length !== aligns.length) {\n      return;\n    }\n    for (const align of aligns) {\n      if (this.rules.other.tableAlignRight.test(align)) {\n        item.align.push(\"right\");\n      } else if (this.rules.other.tableAlignCenter.test(align)) {\n        item.align.push(\"center\");\n      } else if (this.rules.other.tableAlignLeft.test(align)) {\n        item.align.push(\"left\");\n      } else {\n        item.align.push(null);\n      }\n    }\n    for (let i = 0; i < headers.length; i++) {\n      item.header.push({\n        text: headers[i],\n        tokens: this.lexer.inline(headers[i]),\n        header: true,\n        align: item.align[i]\n      });\n    }\n    for (const row of rows) {\n      item.rows.push(splitCells(row, item.header.length).map((cell, i) => {\n        return {\n          text: cell,\n          tokens: this.lexer.inline(cell),\n          header: false,\n          align: item.align[i]\n        };\n      }));\n    }\n    return item;\n  }\n  lheading(src) {\n    const cap = this.rules.block.lheading.exec(src);\n    if (cap) {\n      return {\n        type: \"heading\",\n        raw: cap[0],\n        depth: cap[2].charAt(0) === \"=\" ? 1 : 2,\n        text: cap[1],\n        tokens: this.lexer.inline(cap[1])\n      };\n    }\n  }\n  paragraph(src) {\n    const cap = this.rules.block.paragraph.exec(src);\n    if (cap) {\n      const text = cap[1].charAt(cap[1].length - 1) === \"\\n\" ? cap[1].slice(0, -1) : cap[1];\n      return {\n        type: \"paragraph\",\n        raw: cap[0],\n        text,\n        tokens: this.lexer.inline(text)\n      };\n    }\n  }\n  text(src) {\n    const cap = this.rules.block.text.exec(src);\n    if (cap) {\n      return {\n        type: \"text\",\n        raw: cap[0],\n        text: cap[0],\n        tokens: this.lexer.inline(cap[0])\n      };\n    }\n  }\n  escape(src) {\n    const cap = this.rules.inline.escape.exec(src);\n    if (cap) {\n      return {\n        type: \"escape\",\n        raw: cap[0],\n        text: cap[1]\n      };\n    }\n  }\n  tag(src) {\n    const cap = this.rules.inline.tag.exec(src);\n    if (cap) {\n      if (!this.lexer.state.inLink && this.rules.other.startATag.test(cap[0])) {\n        this.lexer.state.inLink = true;\n      } else if (this.lexer.state.inLink && this.rules.other.endATag.test(cap[0])) {\n        this.lexer.state.inLink = false;\n      }\n      if (!this.lexer.state.inRawBlock && this.rules.other.startPreScriptTag.test(cap[0])) {\n        this.lexer.state.inRawBlock = true;\n      } else if (this.lexer.state.inRawBlock && this.rules.other.endPreScriptTag.test(cap[0])) {\n        this.lexer.state.inRawBlock = false;\n      }\n      return {\n        type: \"html\",\n        raw: cap[0],\n        inLink: this.lexer.state.inLink,\n        inRawBlock: this.lexer.state.inRawBlock,\n        block: false,\n        text: cap[0]\n      };\n    }\n  }\n  link(src) {\n    const cap = this.rules.inline.link.exec(src);\n    if (cap) {\n      const trimmedUrl = cap[2].trim();\n      if (!this.options.pedantic && this.rules.other.startAngleBracket.test(trimmedUrl)) {\n        if (!this.rules.other.endAngleBracket.test(trimmedUrl)) {\n          return;\n        }\n        const rtrimSlash = rtrim(trimmedUrl.slice(0, -1), \"\\\\\");\n        if ((trimmedUrl.length - rtrimSlash.length) % 2 === 0) {\n          return;\n        }\n      } else {\n        const lastParenIndex = findClosingBracket(cap[2], \"()\");\n        if (lastParenIndex === -2) {\n          return;\n        }\n        if (lastParenIndex > -1) {\n          const start = cap[0].indexOf(\"!\") === 0 ? 5 : 4;\n          const linkLen = start + cap[1].length + lastParenIndex;\n          cap[2] = cap[2].substring(0, lastParenIndex);\n          cap[0] = cap[0].substring(0, linkLen).trim();\n          cap[3] = \"\";\n        }\n      }\n      let href = cap[2];\n      let title = \"\";\n      if (this.options.pedantic) {\n        const link2 = this.rules.other.pedanticHrefTitle.exec(href);\n        if (link2) {\n          href = link2[1];\n          title = link2[3];\n        }\n      } else {\n        title = cap[3] ? cap[3].slice(1, -1) : \"\";\n      }\n      href = href.trim();\n      if (this.rules.other.startAngleBracket.test(href)) {\n        if (this.options.pedantic && !this.rules.other.endAngleBracket.test(trimmedUrl)) {\n          href = href.slice(1);\n        } else {\n          href = href.slice(1, -1);\n        }\n      }\n      return outputLink(cap, {\n        href: href ? href.replace(this.rules.inline.anyPunctuation, \"$1\") : href,\n        title: title ? title.replace(this.rules.inline.anyPunctuation, \"$1\") : title\n      }, cap[0], this.lexer, this.rules);\n    }\n  }\n  reflink(src, links) {\n    let cap;\n    if ((cap = this.rules.inline.reflink.exec(src)) || (cap = this.rules.inline.nolink.exec(src))) {\n      const linkString = (cap[2] || cap[1]).replace(this.rules.other.multipleSpaceGlobal, \" \");\n      const link2 = links[linkString.toLowerCase()];\n      if (!link2) {\n        const text = cap[0].charAt(0);\n        return {\n          type: \"text\",\n          raw: text,\n          text\n        };\n      }\n      return outputLink(cap, link2, cap[0], this.lexer, this.rules);\n    }\n  }\n  emStrong(src, maskedSrc, prevChar = \"\") {\n    let match = this.rules.inline.emStrongLDelim.exec(src);\n    if (!match) return;\n    if (match[3] && prevChar.match(this.rules.other.unicodeAlphaNumeric)) return;\n    const nextChar = match[1] || match[2] || \"\";\n    if (!nextChar || !prevChar || this.rules.inline.punctuation.exec(prevChar)) {\n      const lLength = [...match[0]].length - 1;\n      let rDelim,\n        rLength,\n        delimTotal = lLength,\n        midDelimTotal = 0;\n      const endReg = match[0][0] === \"*\" ? this.rules.inline.emStrongRDelimAst : this.rules.inline.emStrongRDelimUnd;\n      endReg.lastIndex = 0;\n      maskedSrc = maskedSrc.slice(-1 * src.length + lLength);\n      while ((match = endReg.exec(maskedSrc)) != null) {\n        rDelim = match[1] || match[2] || match[3] || match[4] || match[5] || match[6];\n        if (!rDelim) continue;\n        rLength = [...rDelim].length;\n        if (match[3] || match[4]) {\n          delimTotal += rLength;\n          continue;\n        } else if (match[5] || match[6]) {\n          if (lLength % 3 && !((lLength + rLength) % 3)) {\n            midDelimTotal += rLength;\n            continue;\n          }\n        }\n        delimTotal -= rLength;\n        if (delimTotal > 0) continue;\n        rLength = Math.min(rLength, rLength + delimTotal + midDelimTotal);\n        const lastCharLength = [...match[0]][0].length;\n        const raw = src.slice(0, lLength + match.index + lastCharLength + rLength);\n        if (Math.min(lLength, rLength) % 2) {\n          const text2 = raw.slice(1, -1);\n          return {\n            type: \"em\",\n            raw,\n            text: text2,\n            tokens: this.lexer.inlineTokens(text2)\n          };\n        }\n        const text = raw.slice(2, -2);\n        return {\n          type: \"strong\",\n          raw,\n          text,\n          tokens: this.lexer.inlineTokens(text)\n        };\n      }\n    }\n  }\n  codespan(src) {\n    const cap = this.rules.inline.code.exec(src);\n    if (cap) {\n      let text = cap[2].replace(this.rules.other.newLineCharGlobal, \" \");\n      const hasNonSpaceChars = this.rules.other.nonSpaceChar.test(text);\n      const hasSpaceCharsOnBothEnds = this.rules.other.startingSpaceChar.test(text) && this.rules.other.endingSpaceChar.test(text);\n      if (hasNonSpaceChars && hasSpaceCharsOnBothEnds) {\n        text = text.substring(1, text.length - 1);\n      }\n      return {\n        type: \"codespan\",\n        raw: cap[0],\n        text\n      };\n    }\n  }\n  br(src) {\n    const cap = this.rules.inline.br.exec(src);\n    if (cap) {\n      return {\n        type: \"br\",\n        raw: cap[0]\n      };\n    }\n  }\n  del(src) {\n    const cap = this.rules.inline.del.exec(src);\n    if (cap) {\n      return {\n        type: \"del\",\n        raw: cap[0],\n        text: cap[2],\n        tokens: this.lexer.inlineTokens(cap[2])\n      };\n    }\n  }\n  autolink(src) {\n    const cap = this.rules.inline.autolink.exec(src);\n    if (cap) {\n      let text, href;\n      if (cap[2] === \"@\") {\n        text = cap[1];\n        href = \"mailto:\" + text;\n      } else {\n        text = cap[1];\n        href = text;\n      }\n      return {\n        type: \"link\",\n        raw: cap[0],\n        text,\n        href,\n        tokens: [{\n          type: \"text\",\n          raw: text,\n          text\n        }]\n      };\n    }\n  }\n  url(src) {\n    let cap;\n    if (cap = this.rules.inline.url.exec(src)) {\n      let text, href;\n      if (cap[2] === \"@\") {\n        text = cap[0];\n        href = \"mailto:\" + text;\n      } else {\n        let prevCapZero;\n        do {\n          prevCapZero = cap[0];\n          cap[0] = this.rules.inline._backpedal.exec(cap[0])?.[0] ?? \"\";\n        } while (prevCapZero !== cap[0]);\n        text = cap[0];\n        if (cap[1] === \"www.\") {\n          href = \"http://\" + cap[0];\n        } else {\n          href = cap[0];\n        }\n      }\n      return {\n        type: \"link\",\n        raw: cap[0],\n        text,\n        href,\n        tokens: [{\n          type: \"text\",\n          raw: text,\n          text\n        }]\n      };\n    }\n  }\n  inlineText(src) {\n    const cap = this.rules.inline.text.exec(src);\n    if (cap) {\n      const escaped = this.lexer.state.inRawBlock;\n      return {\n        type: \"text\",\n        raw: cap[0],\n        text: cap[0],\n        escaped\n      };\n    }\n  }\n};\n\n// src/Lexer.ts\nvar _Lexer = class __Lexer {\n  tokens;\n  options;\n  state;\n  tokenizer;\n  inlineQueue;\n  constructor(options2) {\n    this.tokens = [];\n    this.tokens.links = /* @__PURE__ */Object.create(null);\n    this.options = options2 || _defaults;\n    this.options.tokenizer = this.options.tokenizer || new _Tokenizer();\n    this.tokenizer = this.options.tokenizer;\n    this.tokenizer.options = this.options;\n    this.tokenizer.lexer = this;\n    this.inlineQueue = [];\n    this.state = {\n      inLink: false,\n      inRawBlock: false,\n      top: true\n    };\n    const rules = {\n      other,\n      block: block.normal,\n      inline: inline.normal\n    };\n    if (this.options.pedantic) {\n      rules.block = block.pedantic;\n      rules.inline = inline.pedantic;\n    } else if (this.options.gfm) {\n      rules.block = block.gfm;\n      if (this.options.breaks) {\n        rules.inline = inline.breaks;\n      } else {\n        rules.inline = inline.gfm;\n      }\n    }\n    this.tokenizer.rules = rules;\n  }\n  /**\n   * Expose Rules\n   */\n  static get rules() {\n    return {\n      block,\n      inline\n    };\n  }\n  /**\n   * Static Lex Method\n   */\n  static lex(src, options2) {\n    const lexer2 = new __Lexer(options2);\n    return lexer2.lex(src);\n  }\n  /**\n   * Static Lex Inline Method\n   */\n  static lexInline(src, options2) {\n    const lexer2 = new __Lexer(options2);\n    return lexer2.inlineTokens(src);\n  }\n  /**\n   * Preprocessing\n   */\n  lex(src) {\n    src = src.replace(other.carriageReturn, \"\\n\");\n    this.blockTokens(src, this.tokens);\n    for (let i = 0; i < this.inlineQueue.length; i++) {\n      const next = this.inlineQueue[i];\n      this.inlineTokens(next.src, next.tokens);\n    }\n    this.inlineQueue = [];\n    return this.tokens;\n  }\n  blockTokens(src, tokens = [], lastParagraphClipped = false) {\n    if (this.options.pedantic) {\n      src = src.replace(other.tabCharGlobal, \"    \").replace(other.spaceLine, \"\");\n    }\n    while (src) {\n      let token;\n      if (this.options.extensions?.block?.some(extTokenizer => {\n        if (token = extTokenizer.call({\n          lexer: this\n        }, src, tokens)) {\n          src = src.substring(token.raw.length);\n          tokens.push(token);\n          return true;\n        }\n        return false;\n      })) {\n        continue;\n      }\n      if (token = this.tokenizer.space(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (token.raw.length === 1 && lastToken !== void 0) {\n          lastToken.raw += \"\\n\";\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (token = this.tokenizer.code(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === \"paragraph\" || lastToken?.type === \"text\") {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue.at(-1).src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (token = this.tokenizer.fences(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.heading(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.hr(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.blockquote(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.list(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.html(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.def(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === \"paragraph\" || lastToken?.type === \"text\") {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.raw;\n          this.inlineQueue.at(-1).src = lastToken.text;\n        } else if (!this.tokens.links[token.tag]) {\n          this.tokens.links[token.tag] = {\n            href: token.href,\n            title: token.title\n          };\n        }\n        continue;\n      }\n      if (token = this.tokenizer.table(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.lheading(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      let cutSrc = src;\n      if (this.options.extensions?.startBlock) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startBlock.forEach(getStartIndex => {\n          tempStart = getStartIndex.call({\n            lexer: this\n          }, tempSrc);\n          if (typeof tempStart === \"number\" && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if (this.state.top && (token = this.tokenizer.paragraph(cutSrc))) {\n        const lastToken = tokens.at(-1);\n        if (lastParagraphClipped && lastToken?.type === \"paragraph\") {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue.at(-1).src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        lastParagraphClipped = cutSrc.length !== src.length;\n        src = src.substring(token.raw.length);\n        continue;\n      }\n      if (token = this.tokenizer.text(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === \"text\") {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue.at(-1).src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (src) {\n        const errMsg = \"Infinite loop on byte: \" + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n    this.state.top = true;\n    return tokens;\n  }\n  inline(src, tokens = []) {\n    this.inlineQueue.push({\n      src,\n      tokens\n    });\n    return tokens;\n  }\n  /**\n   * Lexing/Compiling\n   */\n  inlineTokens(src, tokens = []) {\n    let maskedSrc = src;\n    let match = null;\n    if (this.tokens.links) {\n      const links = Object.keys(this.tokens.links);\n      if (links.length > 0) {\n        while ((match = this.tokenizer.rules.inline.reflinkSearch.exec(maskedSrc)) != null) {\n          if (links.includes(match[0].slice(match[0].lastIndexOf(\"[\") + 1, -1))) {\n            maskedSrc = maskedSrc.slice(0, match.index) + \"[\" + \"a\".repeat(match[0].length - 2) + \"]\" + maskedSrc.slice(this.tokenizer.rules.inline.reflinkSearch.lastIndex);\n          }\n        }\n      }\n    }\n    while ((match = this.tokenizer.rules.inline.anyPunctuation.exec(maskedSrc)) != null) {\n      maskedSrc = maskedSrc.slice(0, match.index) + \"++\" + maskedSrc.slice(this.tokenizer.rules.inline.anyPunctuation.lastIndex);\n    }\n    while ((match = this.tokenizer.rules.inline.blockSkip.exec(maskedSrc)) != null) {\n      maskedSrc = maskedSrc.slice(0, match.index) + \"[\" + \"a\".repeat(match[0].length - 2) + \"]\" + maskedSrc.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);\n    }\n    let keepPrevChar = false;\n    let prevChar = \"\";\n    while (src) {\n      if (!keepPrevChar) {\n        prevChar = \"\";\n      }\n      keepPrevChar = false;\n      let token;\n      if (this.options.extensions?.inline?.some(extTokenizer => {\n        if (token = extTokenizer.call({\n          lexer: this\n        }, src, tokens)) {\n          src = src.substring(token.raw.length);\n          tokens.push(token);\n          return true;\n        }\n        return false;\n      })) {\n        continue;\n      }\n      if (token = this.tokenizer.escape(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.tag(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.link(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.reflink(src, this.tokens.links)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (token.type === \"text\" && lastToken?.type === \"text\") {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (token = this.tokenizer.emStrong(src, maskedSrc, prevChar)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.codespan(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.br(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.del(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.autolink(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (!this.state.inLink && (token = this.tokenizer.url(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      let cutSrc = src;\n      if (this.options.extensions?.startInline) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startInline.forEach(getStartIndex => {\n          tempStart = getStartIndex.call({\n            lexer: this\n          }, tempSrc);\n          if (typeof tempStart === \"number\" && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if (token = this.tokenizer.inlineText(cutSrc)) {\n        src = src.substring(token.raw.length);\n        if (token.raw.slice(-1) !== \"_\") {\n          prevChar = token.raw.slice(-1);\n        }\n        keepPrevChar = true;\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === \"text\") {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (src) {\n        const errMsg = \"Infinite loop on byte: \" + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n    return tokens;\n  }\n};\n\n// src/Renderer.ts\nvar _Renderer = class {\n  options;\n  parser;\n  // set by the parser\n  constructor(options2) {\n    this.options = options2 || _defaults;\n  }\n  space(token) {\n    return \"\";\n  }\n  code({\n    text,\n    lang,\n    escaped\n  }) {\n    const langString = (lang || \"\").match(other.notSpaceStart)?.[0];\n    const code = text.replace(other.endingNewline, \"\") + \"\\n\";\n    if (!langString) {\n      return \"<pre><code>\" + (escaped ? code : escape2(code, true)) + \"</code></pre>\\n\";\n    }\n    return '<pre><code class=\"language-' + escape2(langString) + '\">' + (escaped ? code : escape2(code, true)) + \"</code></pre>\\n\";\n  }\n  blockquote({\n    tokens\n  }) {\n    const body = this.parser.parse(tokens);\n    return `<blockquote>\n${body}</blockquote>\n`;\n  }\n  html({\n    text\n  }) {\n    return text;\n  }\n  heading({\n    tokens,\n    depth\n  }) {\n    return `<h${depth}>${this.parser.parseInline(tokens)}</h${depth}>\n`;\n  }\n  hr(token) {\n    return \"<hr>\\n\";\n  }\n  list(token) {\n    const ordered = token.ordered;\n    const start = token.start;\n    let body = \"\";\n    for (let j = 0; j < token.items.length; j++) {\n      const item = token.items[j];\n      body += this.listitem(item);\n    }\n    const type = ordered ? \"ol\" : \"ul\";\n    const startAttr = ordered && start !== 1 ? ' start=\"' + start + '\"' : \"\";\n    return \"<\" + type + startAttr + \">\\n\" + body + \"</\" + type + \">\\n\";\n  }\n  listitem(item) {\n    let itemBody = \"\";\n    if (item.task) {\n      const checkbox = this.checkbox({\n        checked: !!item.checked\n      });\n      if (item.loose) {\n        if (item.tokens[0]?.type === \"paragraph\") {\n          item.tokens[0].text = checkbox + \" \" + item.tokens[0].text;\n          if (item.tokens[0].tokens && item.tokens[0].tokens.length > 0 && item.tokens[0].tokens[0].type === \"text\") {\n            item.tokens[0].tokens[0].text = checkbox + \" \" + escape2(item.tokens[0].tokens[0].text);\n            item.tokens[0].tokens[0].escaped = true;\n          }\n        } else {\n          item.tokens.unshift({\n            type: \"text\",\n            raw: checkbox + \" \",\n            text: checkbox + \" \",\n            escaped: true\n          });\n        }\n      } else {\n        itemBody += checkbox + \" \";\n      }\n    }\n    itemBody += this.parser.parse(item.tokens, !!item.loose);\n    return `<li>${itemBody}</li>\n`;\n  }\n  checkbox({\n    checked\n  }) {\n    return \"<input \" + (checked ? 'checked=\"\" ' : \"\") + 'disabled=\"\" type=\"checkbox\">';\n  }\n  paragraph({\n    tokens\n  }) {\n    return `<p>${this.parser.parseInline(tokens)}</p>\n`;\n  }\n  table(token) {\n    let header = \"\";\n    let cell = \"\";\n    for (let j = 0; j < token.header.length; j++) {\n      cell += this.tablecell(token.header[j]);\n    }\n    header += this.tablerow({\n      text: cell\n    });\n    let body = \"\";\n    for (let j = 0; j < token.rows.length; j++) {\n      const row = token.rows[j];\n      cell = \"\";\n      for (let k = 0; k < row.length; k++) {\n        cell += this.tablecell(row[k]);\n      }\n      body += this.tablerow({\n        text: cell\n      });\n    }\n    if (body) body = `<tbody>${body}</tbody>`;\n    return \"<table>\\n<thead>\\n\" + header + \"</thead>\\n\" + body + \"</table>\\n\";\n  }\n  tablerow({\n    text\n  }) {\n    return `<tr>\n${text}</tr>\n`;\n  }\n  tablecell(token) {\n    const content = this.parser.parseInline(token.tokens);\n    const type = token.header ? \"th\" : \"td\";\n    const tag2 = token.align ? `<${type} align=\"${token.align}\">` : `<${type}>`;\n    return tag2 + content + `</${type}>\n`;\n  }\n  /**\n   * span level renderer\n   */\n  strong({\n    tokens\n  }) {\n    return `<strong>${this.parser.parseInline(tokens)}</strong>`;\n  }\n  em({\n    tokens\n  }) {\n    return `<em>${this.parser.parseInline(tokens)}</em>`;\n  }\n  codespan({\n    text\n  }) {\n    return `<code>${escape2(text, true)}</code>`;\n  }\n  br(token) {\n    return \"<br>\";\n  }\n  del({\n    tokens\n  }) {\n    return `<del>${this.parser.parseInline(tokens)}</del>`;\n  }\n  link({\n    href,\n    title,\n    tokens\n  }) {\n    const text = this.parser.parseInline(tokens);\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return text;\n    }\n    href = cleanHref;\n    let out = '<a href=\"' + href + '\"';\n    if (title) {\n      out += ' title=\"' + escape2(title) + '\"';\n    }\n    out += \">\" + text + \"</a>\";\n    return out;\n  }\n  image({\n    href,\n    title,\n    text,\n    tokens\n  }) {\n    if (tokens) {\n      text = this.parser.parseInline(tokens, this.parser.textRenderer);\n    }\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return escape2(text);\n    }\n    href = cleanHref;\n    let out = `<img src=\"${href}\" alt=\"${text}\"`;\n    if (title) {\n      out += ` title=\"${escape2(title)}\"`;\n    }\n    out += \">\";\n    return out;\n  }\n  text(token) {\n    return \"tokens\" in token && token.tokens ? this.parser.parseInline(token.tokens) : \"escaped\" in token && token.escaped ? token.text : escape2(token.text);\n  }\n};\n\n// src/TextRenderer.ts\nvar _TextRenderer = class {\n  // no need for block level renderers\n  strong({\n    text\n  }) {\n    return text;\n  }\n  em({\n    text\n  }) {\n    return text;\n  }\n  codespan({\n    text\n  }) {\n    return text;\n  }\n  del({\n    text\n  }) {\n    return text;\n  }\n  html({\n    text\n  }) {\n    return text;\n  }\n  text({\n    text\n  }) {\n    return text;\n  }\n  link({\n    text\n  }) {\n    return \"\" + text;\n  }\n  image({\n    text\n  }) {\n    return \"\" + text;\n  }\n  br() {\n    return \"\";\n  }\n};\n\n// src/Parser.ts\nvar _Parser = class __Parser {\n  options;\n  renderer;\n  textRenderer;\n  constructor(options2) {\n    this.options = options2 || _defaults;\n    this.options.renderer = this.options.renderer || new _Renderer();\n    this.renderer = this.options.renderer;\n    this.renderer.options = this.options;\n    this.renderer.parser = this;\n    this.textRenderer = new _TextRenderer();\n  }\n  /**\n   * Static Parse Method\n   */\n  static parse(tokens, options2) {\n    const parser2 = new __Parser(options2);\n    return parser2.parse(tokens);\n  }\n  /**\n   * Static Parse Inline Method\n   */\n  static parseInline(tokens, options2) {\n    const parser2 = new __Parser(options2);\n    return parser2.parseInline(tokens);\n  }\n  /**\n   * Parse Loop\n   */\n  parse(tokens, top = true) {\n    let out = \"\";\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n      if (this.options.extensions?.renderers?.[anyToken.type]) {\n        const genericToken = anyToken;\n        const ret = this.options.extensions.renderers[genericToken.type].call({\n          parser: this\n        }, genericToken);\n        if (ret !== false || ![\"space\", \"hr\", \"heading\", \"code\", \"table\", \"blockquote\", \"list\", \"html\", \"paragraph\", \"text\"].includes(genericToken.type)) {\n          out += ret || \"\";\n          continue;\n        }\n      }\n      const token = anyToken;\n      switch (token.type) {\n        case \"space\":\n          {\n            out += this.renderer.space(token);\n            continue;\n          }\n        case \"hr\":\n          {\n            out += this.renderer.hr(token);\n            continue;\n          }\n        case \"heading\":\n          {\n            out += this.renderer.heading(token);\n            continue;\n          }\n        case \"code\":\n          {\n            out += this.renderer.code(token);\n            continue;\n          }\n        case \"table\":\n          {\n            out += this.renderer.table(token);\n            continue;\n          }\n        case \"blockquote\":\n          {\n            out += this.renderer.blockquote(token);\n            continue;\n          }\n        case \"list\":\n          {\n            out += this.renderer.list(token);\n            continue;\n          }\n        case \"html\":\n          {\n            out += this.renderer.html(token);\n            continue;\n          }\n        case \"paragraph\":\n          {\n            out += this.renderer.paragraph(token);\n            continue;\n          }\n        case \"text\":\n          {\n            let textToken = token;\n            let body = this.renderer.text(textToken);\n            while (i + 1 < tokens.length && tokens[i + 1].type === \"text\") {\n              textToken = tokens[++i];\n              body += \"\\n\" + this.renderer.text(textToken);\n            }\n            if (top) {\n              out += this.renderer.paragraph({\n                type: \"paragraph\",\n                raw: body,\n                text: body,\n                tokens: [{\n                  type: \"text\",\n                  raw: body,\n                  text: body,\n                  escaped: true\n                }]\n              });\n            } else {\n              out += body;\n            }\n            continue;\n          }\n        default:\n          {\n            const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n            if (this.options.silent) {\n              console.error(errMsg);\n              return \"\";\n            } else {\n              throw new Error(errMsg);\n            }\n          }\n      }\n    }\n    return out;\n  }\n  /**\n   * Parse Inline Tokens\n   */\n  parseInline(tokens, renderer = this.renderer) {\n    let out = \"\";\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n      if (this.options.extensions?.renderers?.[anyToken.type]) {\n        const ret = this.options.extensions.renderers[anyToken.type].call({\n          parser: this\n        }, anyToken);\n        if (ret !== false || ![\"escape\", \"html\", \"link\", \"image\", \"strong\", \"em\", \"codespan\", \"br\", \"del\", \"text\"].includes(anyToken.type)) {\n          out += ret || \"\";\n          continue;\n        }\n      }\n      const token = anyToken;\n      switch (token.type) {\n        case \"escape\":\n          {\n            out += renderer.text(token);\n            break;\n          }\n        case \"html\":\n          {\n            out += renderer.html(token);\n            break;\n          }\n        case \"link\":\n          {\n            out += renderer.link(token);\n            break;\n          }\n        case \"image\":\n          {\n            out += renderer.image(token);\n            break;\n          }\n        case \"strong\":\n          {\n            out += renderer.strong(token);\n            break;\n          }\n        case \"em\":\n          {\n            out += renderer.em(token);\n            break;\n          }\n        case \"codespan\":\n          {\n            out += renderer.codespan(token);\n            break;\n          }\n        case \"br\":\n          {\n            out += renderer.br(token);\n            break;\n          }\n        case \"del\":\n          {\n            out += renderer.del(token);\n            break;\n          }\n        case \"text\":\n          {\n            out += renderer.text(token);\n            break;\n          }\n        default:\n          {\n            const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n            if (this.options.silent) {\n              console.error(errMsg);\n              return \"\";\n            } else {\n              throw new Error(errMsg);\n            }\n          }\n      }\n    }\n    return out;\n  }\n};\n\n// src/Hooks.ts\nvar _Hooks = class {\n  options;\n  block;\n  constructor(options2) {\n    this.options = options2 || _defaults;\n  }\n  static passThroughHooks = /* @__PURE__ */new Set([\"preprocess\", \"postprocess\", \"processAllTokens\"]);\n  /**\n   * Process markdown before marked\n   */\n  preprocess(markdown) {\n    return markdown;\n  }\n  /**\n   * Process HTML after marked is finished\n   */\n  postprocess(html2) {\n    return html2;\n  }\n  /**\n   * Process all tokens before walk tokens\n   */\n  processAllTokens(tokens) {\n    return tokens;\n  }\n  /**\n   * Provide function to tokenize markdown\n   */\n  provideLexer() {\n    return this.block ? _Lexer.lex : _Lexer.lexInline;\n  }\n  /**\n   * Provide function to parse tokens\n   */\n  provideParser() {\n    return this.block ? _Parser.parse : _Parser.parseInline;\n  }\n};\n\n// src/Instance.ts\nvar Marked = class {\n  defaults = _getDefaults();\n  options = this.setOptions;\n  parse = this.parseMarkdown(true);\n  parseInline = this.parseMarkdown(false);\n  Parser = _Parser;\n  Renderer = _Renderer;\n  TextRenderer = _TextRenderer;\n  Lexer = _Lexer;\n  Tokenizer = _Tokenizer;\n  Hooks = _Hooks;\n  constructor(...args) {\n    this.use(...args);\n  }\n  /**\n   * Run callback for every token\n   */\n  walkTokens(tokens, callback) {\n    let values = [];\n    for (const token of tokens) {\n      values = values.concat(callback.call(this, token));\n      switch (token.type) {\n        case \"table\":\n          {\n            const tableToken = token;\n            for (const cell of tableToken.header) {\n              values = values.concat(this.walkTokens(cell.tokens, callback));\n            }\n            for (const row of tableToken.rows) {\n              for (const cell of row) {\n                values = values.concat(this.walkTokens(cell.tokens, callback));\n              }\n            }\n            break;\n          }\n        case \"list\":\n          {\n            const listToken = token;\n            values = values.concat(this.walkTokens(listToken.items, callback));\n            break;\n          }\n        default:\n          {\n            const genericToken = token;\n            if (this.defaults.extensions?.childTokens?.[genericToken.type]) {\n              this.defaults.extensions.childTokens[genericToken.type].forEach(childTokens => {\n                const tokens2 = genericToken[childTokens].flat(Infinity);\n                values = values.concat(this.walkTokens(tokens2, callback));\n              });\n            } else if (genericToken.tokens) {\n              values = values.concat(this.walkTokens(genericToken.tokens, callback));\n            }\n          }\n      }\n    }\n    return values;\n  }\n  use(...args) {\n    const extensions = this.defaults.extensions || {\n      renderers: {},\n      childTokens: {}\n    };\n    args.forEach(pack => {\n      const opts = {\n        ...pack\n      };\n      opts.async = this.defaults.async || opts.async || false;\n      if (pack.extensions) {\n        pack.extensions.forEach(ext => {\n          if (!ext.name) {\n            throw new Error(\"extension name required\");\n          }\n          if (\"renderer\" in ext) {\n            const prevRenderer = extensions.renderers[ext.name];\n            if (prevRenderer) {\n              extensions.renderers[ext.name] = function (...args2) {\n                let ret = ext.renderer.apply(this, args2);\n                if (ret === false) {\n                  ret = prevRenderer.apply(this, args2);\n                }\n                return ret;\n              };\n            } else {\n              extensions.renderers[ext.name] = ext.renderer;\n            }\n          }\n          if (\"tokenizer\" in ext) {\n            if (!ext.level || ext.level !== \"block\" && ext.level !== \"inline\") {\n              throw new Error(\"extension level must be 'block' or 'inline'\");\n            }\n            const extLevel = extensions[ext.level];\n            if (extLevel) {\n              extLevel.unshift(ext.tokenizer);\n            } else {\n              extensions[ext.level] = [ext.tokenizer];\n            }\n            if (ext.start) {\n              if (ext.level === \"block\") {\n                if (extensions.startBlock) {\n                  extensions.startBlock.push(ext.start);\n                } else {\n                  extensions.startBlock = [ext.start];\n                }\n              } else if (ext.level === \"inline\") {\n                if (extensions.startInline) {\n                  extensions.startInline.push(ext.start);\n                } else {\n                  extensions.startInline = [ext.start];\n                }\n              }\n            }\n          }\n          if (\"childTokens\" in ext && ext.childTokens) {\n            extensions.childTokens[ext.name] = ext.childTokens;\n          }\n        });\n        opts.extensions = extensions;\n      }\n      if (pack.renderer) {\n        const renderer = this.defaults.renderer || new _Renderer(this.defaults);\n        for (const prop in pack.renderer) {\n          if (!(prop in renderer)) {\n            throw new Error(`renderer '${prop}' does not exist`);\n          }\n          if ([\"options\", \"parser\"].includes(prop)) {\n            continue;\n          }\n          const rendererProp = prop;\n          const rendererFunc = pack.renderer[rendererProp];\n          const prevRenderer = renderer[rendererProp];\n          renderer[rendererProp] = (...args2) => {\n            let ret = rendererFunc.apply(renderer, args2);\n            if (ret === false) {\n              ret = prevRenderer.apply(renderer, args2);\n            }\n            return ret || \"\";\n          };\n        }\n        opts.renderer = renderer;\n      }\n      if (pack.tokenizer) {\n        const tokenizer = this.defaults.tokenizer || new _Tokenizer(this.defaults);\n        for (const prop in pack.tokenizer) {\n          if (!(prop in tokenizer)) {\n            throw new Error(`tokenizer '${prop}' does not exist`);\n          }\n          if ([\"options\", \"rules\", \"lexer\"].includes(prop)) {\n            continue;\n          }\n          const tokenizerProp = prop;\n          const tokenizerFunc = pack.tokenizer[tokenizerProp];\n          const prevTokenizer = tokenizer[tokenizerProp];\n          tokenizer[tokenizerProp] = (...args2) => {\n            let ret = tokenizerFunc.apply(tokenizer, args2);\n            if (ret === false) {\n              ret = prevTokenizer.apply(tokenizer, args2);\n            }\n            return ret;\n          };\n        }\n        opts.tokenizer = tokenizer;\n      }\n      if (pack.hooks) {\n        const hooks = this.defaults.hooks || new _Hooks();\n        for (const prop in pack.hooks) {\n          if (!(prop in hooks)) {\n            throw new Error(`hook '${prop}' does not exist`);\n          }\n          if ([\"options\", \"block\"].includes(prop)) {\n            continue;\n          }\n          const hooksProp = prop;\n          const hooksFunc = pack.hooks[hooksProp];\n          const prevHook = hooks[hooksProp];\n          if (_Hooks.passThroughHooks.has(prop)) {\n            hooks[hooksProp] = arg => {\n              if (this.defaults.async) {\n                return Promise.resolve(hooksFunc.call(hooks, arg)).then(ret2 => {\n                  return prevHook.call(hooks, ret2);\n                });\n              }\n              const ret = hooksFunc.call(hooks, arg);\n              return prevHook.call(hooks, ret);\n            };\n          } else {\n            hooks[hooksProp] = (...args2) => {\n              let ret = hooksFunc.apply(hooks, args2);\n              if (ret === false) {\n                ret = prevHook.apply(hooks, args2);\n              }\n              return ret;\n            };\n          }\n        }\n        opts.hooks = hooks;\n      }\n      if (pack.walkTokens) {\n        const walkTokens2 = this.defaults.walkTokens;\n        const packWalktokens = pack.walkTokens;\n        opts.walkTokens = function (token) {\n          let values = [];\n          values.push(packWalktokens.call(this, token));\n          if (walkTokens2) {\n            values = values.concat(walkTokens2.call(this, token));\n          }\n          return values;\n        };\n      }\n      this.defaults = {\n        ...this.defaults,\n        ...opts\n      };\n    });\n    return this;\n  }\n  setOptions(opt) {\n    this.defaults = {\n      ...this.defaults,\n      ...opt\n    };\n    return this;\n  }\n  lexer(src, options2) {\n    return _Lexer.lex(src, options2 ?? this.defaults);\n  }\n  parser(tokens, options2) {\n    return _Parser.parse(tokens, options2 ?? this.defaults);\n  }\n  parseMarkdown(blockType) {\n    const parse2 = (src, options2) => {\n      const origOpt = {\n        ...options2\n      };\n      const opt = {\n        ...this.defaults,\n        ...origOpt\n      };\n      const throwError = this.onError(!!opt.silent, !!opt.async);\n      if (this.defaults.async === true && origOpt.async === false) {\n        return throwError(new Error(\"marked(): The async option was set to true by an extension. Remove async: false from the parse options object to return a Promise.\"));\n      }\n      if (typeof src === \"undefined\" || src === null) {\n        return throwError(new Error(\"marked(): input parameter is undefined or null\"));\n      }\n      if (typeof src !== \"string\") {\n        return throwError(new Error(\"marked(): input parameter is of type \" + Object.prototype.toString.call(src) + \", string expected\"));\n      }\n      if (opt.hooks) {\n        opt.hooks.options = opt;\n        opt.hooks.block = blockType;\n      }\n      const lexer2 = opt.hooks ? opt.hooks.provideLexer() : blockType ? _Lexer.lex : _Lexer.lexInline;\n      const parser2 = opt.hooks ? opt.hooks.provideParser() : blockType ? _Parser.parse : _Parser.parseInline;\n      if (opt.async) {\n        return Promise.resolve(opt.hooks ? opt.hooks.preprocess(src) : src).then(src2 => lexer2(src2, opt)).then(tokens => opt.hooks ? opt.hooks.processAllTokens(tokens) : tokens).then(tokens => opt.walkTokens ? Promise.all(this.walkTokens(tokens, opt.walkTokens)).then(() => tokens) : tokens).then(tokens => parser2(tokens, opt)).then(html2 => opt.hooks ? opt.hooks.postprocess(html2) : html2).catch(throwError);\n      }\n      try {\n        if (opt.hooks) {\n          src = opt.hooks.preprocess(src);\n        }\n        let tokens = lexer2(src, opt);\n        if (opt.hooks) {\n          tokens = opt.hooks.processAllTokens(tokens);\n        }\n        if (opt.walkTokens) {\n          this.walkTokens(tokens, opt.walkTokens);\n        }\n        let html2 = parser2(tokens, opt);\n        if (opt.hooks) {\n          html2 = opt.hooks.postprocess(html2);\n        }\n        return html2;\n      } catch (e) {\n        return throwError(e);\n      }\n    };\n    return parse2;\n  }\n  onError(silent, async) {\n    return e => {\n      e.message += \"\\nPlease report this to https://github.com/markedjs/marked.\";\n      if (silent) {\n        const msg = \"<p>An error occurred:</p><pre>\" + escape2(e.message + \"\", true) + \"</pre>\";\n        if (async) {\n          return Promise.resolve(msg);\n        }\n        return msg;\n      }\n      if (async) {\n        return Promise.reject(e);\n      }\n      throw e;\n    };\n  }\n};\n\n// src/marked.ts\nvar markedInstance = new Marked();\nfunction marked(src, opt) {\n  return markedInstance.parse(src, opt);\n}\nmarked.options = marked.setOptions = function (options2) {\n  markedInstance.setOptions(options2);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\nmarked.getDefaults = _getDefaults;\nmarked.defaults = _defaults;\nmarked.use = function (...args) {\n  markedInstance.use(...args);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\nmarked.walkTokens = function (tokens, callback) {\n  return markedInstance.walkTokens(tokens, callback);\n};\nmarked.parseInline = markedInstance.parseInline;\nmarked.Parser = _Parser;\nmarked.parser = _Parser.parse;\nmarked.Renderer = _Renderer;\nmarked.TextRenderer = _TextRenderer;\nmarked.Lexer = _Lexer;\nmarked.lexer = _Lexer.lex;\nmarked.Tokenizer = _Tokenizer;\nmarked.Hooks = _Hooks;\nmarked.parse = marked;\nvar options = marked.options;\nvar setOptions = marked.setOptions;\nvar use = marked.use;\nvar walkTokens = marked.walkTokens;\nvar parseInline = marked.parseInline;\nvar parse = marked;\nvar parser = _Parser.parse;\nvar lexer = _Lexer.lex;\nexport { _Hooks as Hooks, _Lexer as Lexer, Marked, _Parser as Parser, _Renderer as Renderer, _TextRenderer as TextRenderer, _Tokenizer as Tokenizer, _defaults as defaults, _getDefaults as getDefaults, lexer, marked, options, parse, parseInline, parser, setOptions, use, walkTokens };","map":{"version":3,"names":["_getDefaults","async","breaks","extensions","gfm","hooks","pedantic","renderer","silent","tokenizer","walkTokens","_defaults","changeDefaults","newDefaults","noopTest","exec","edit","regex","opt","source","obj","replace","name","val","valSource","other","caret","getRegex","RegExp","codeRemoveIndent","outputLinkReplace","indentCodeCompensation","beginningSpace","endingHash","startingSpaceChar","endingSpaceChar","nonSpaceChar","newLineCharGlobal","tabCharGlobal","multipleSpaceGlobal","blankLine","doubleBlankLine","blockquoteStart","blockquoteSetextReplace","blockquoteSetextReplace2","listReplaceTabs","listReplaceNesting","listIsTask","listReplaceTask","anyLine","hrefBrackets","tableDelimiter","tableAlignChars","tableRowBlankLine","tableAlignRight","tableAlignCenter","tableAlignLeft","startATag","endATag","startPreScriptTag","endPreScriptTag","startAngleBracket","endAngleBracket","pedanticHrefTitle","unicodeAlphaNumeric","escapeTest","escapeReplace","escapeTestNoEncode","escapeReplaceNoEncode","unescapeTest","percentDecode","findPipe","splitPipe","slashPipe","carriageReturn","spaceLine","notSpaceStart","endingNewline","listItemRegex","bull","nextBulletRegex","indent","Math","min","hrRegex","fencesBeginRegex","headingBeginRegex","htmlBeginRegex","newline","blockCode","fences","hr","heading","bullet","lheadingCore","lheading","lheadingGfm","_paragraph","blockText","_blockLabel","def","list","_tag","_comment","html","paragraph","blockquote","blockNormal","code","table","text","gfmTable","blockGfm","blockPedantic","escape","inlineCode","br","inlineText","_punctuation","_punctuationOrSpace","_notPunctuationOrSpace","punctuation","_punctuationGfmStrongEm","_punctuationOrSpaceGfmStrongEm","_notPunctuationOrSpaceGfmStrongEm","blockSkip","emStrongLDelimCore","emStrongLDelim","emStrongLDelimGfm","emStrongRDelimAstCore","emStrongRDelimAst","emStrongRDelimAstGfm","emStrongRDelimUnd","anyPunctuation","autolink","_inlineComment","tag","_inlineLabel","link","reflink","nolink","reflinkSearch","inlineNormal","_backpedal","del","url","inlinePedantic","inlineGfm","inlineBreaks","block","normal","inline","escapeReplacements","getEscapeReplacement","ch","escape2","html2","encode","test","cleanUrl","href","encodeURI","splitCells","tableRow","count","row","match","offset","str","escaped","curr","cells","split","i","trim","shift","length","at","pop","splice","push","rtrim","c","invert","l","suffLen","currChar","charAt","slice","findClosingBracket","b","indexOf","level","outputLink","cap","link2","raw","lexer2","rules","title","state","inLink","token","type","tokens","inlineTokens","matchIndentToCode","indentToCode","map","node","matchIndentInNode","indentInNode","join","_Tokenizer","options","lexer","constructor","options2","space","src","codeBlockStyle","lang","trimmed","depth","lines","inBlockquote","currentLines","currentRaw","currentText","top","blockTokens","lastToken","oldToken","newText","newToken","substring","isordered","list2","ordered","start","loose","items","itemRegex","endsWithBlankLine","endEarly","itemContents","line","t","repeat","nextLine","trimStart","search","rawLine","nextLineWithoutTabs","istask","ischecked","task","checked","lastItem","trimEnd","spacers","filter","hasMultipleLineBreaks","some","pre","tag2","toLowerCase","headers","aligns","rows","item","header","align","cell","inRawBlock","trimmedUrl","rtrimSlash","lastParenIndex","linkLen","links","linkString","emStrong","maskedSrc","prevChar","nextChar","lLength","rDelim","rLength","delimTotal","midDelimTotal","endReg","lastIndex","lastCharLength","index","text2","codespan","hasNonSpaceChars","hasSpaceCharsOnBothEnds","prevCapZero","_Lexer","__Lexer","inlineQueue","Object","create","lex","lexInline","next","lastParagraphClipped","extTokenizer","call","cutSrc","startBlock","startIndex","Infinity","tempSrc","tempStart","forEach","getStartIndex","errMsg","charCodeAt","console","error","Error","keys","includes","lastIndexOf","keepPrevChar","startInline","_Renderer","parser","langString","body","parse","parseInline","j","listitem","startAttr","itemBody","checkbox","unshift","tablecell","tablerow","k","content","strong","em","cleanHref","out","image","textRenderer","_TextRenderer","_Parser","__Parser","parser2","anyToken","renderers","genericToken","ret","textToken","_Hooks","passThroughHooks","Set","preprocess","markdown","postprocess","processAllTokens","provideLexer","provideParser","Marked","defaults","setOptions","parseMarkdown","Parser","Renderer","TextRenderer","Lexer","Tokenizer","Hooks","args","use","callback","values","concat","tableToken","listToken","childTokens","tokens2","flat","pack","opts","ext","prevRenderer","args2","apply","extLevel","prop","rendererProp","rendererFunc","tokenizerProp","tokenizerFunc","prevTokenizer","hooksProp","hooksFunc","prevHook","has","arg","Promise","resolve","then","ret2","walkTokens2","packWalktokens","blockType","parse2","origOpt","throwError","onError","prototype","toString","src2","all","catch","e","message","msg","reject","markedInstance","marked","getDefaults"],"sources":["C:\\Users\\verma\\Downloads\\Medical Bot\\client\\node_modules\\marked\\src\\defaults.ts","C:\\Users\\verma\\Downloads\\Medical Bot\\client\\node_modules\\marked\\src\\rules.ts","C:\\Users\\verma\\Downloads\\Medical Bot\\client\\node_modules\\marked\\src\\helpers.ts","C:\\Users\\verma\\Downloads\\Medical Bot\\client\\node_modules\\marked\\src\\Tokenizer.ts","C:\\Users\\verma\\Downloads\\Medical Bot\\client\\node_modules\\marked\\src\\Lexer.ts","C:\\Users\\verma\\Downloads\\Medical Bot\\client\\node_modules\\marked\\src\\Renderer.ts","C:\\Users\\verma\\Downloads\\Medical Bot\\client\\node_modules\\marked\\src\\TextRenderer.ts","C:\\Users\\verma\\Downloads\\Medical Bot\\client\\node_modules\\marked\\src\\Parser.ts","C:\\Users\\verma\\Downloads\\Medical Bot\\client\\node_modules\\marked\\src\\Hooks.ts","C:\\Users\\verma\\Downloads\\Medical Bot\\client\\node_modules\\marked\\src\\Instance.ts","C:\\Users\\verma\\Downloads\\Medical Bot\\client\\node_modules\\marked\\src\\marked.ts"],"sourcesContent":["import type { MarkedOptions } from './MarkedOptions.ts';\n\n/**\n * Gets the original marked default options.\n */\nexport function _getDefaults(): MarkedOptions {\n  return {\n    async: false,\n    breaks: false,\n    extensions: null,\n    gfm: true,\n    hooks: null,\n    pedantic: false,\n    renderer: null,\n    silent: false,\n    tokenizer: null,\n    walkTokens: null,\n  };\n}\n\nexport let _defaults = _getDefaults();\n\nexport function changeDefaults(newDefaults: MarkedOptions) {\n  _defaults = newDefaults;\n}\n","const noopTest = { exec: () => null } as unknown as RegExp;\n\nfunction edit(regex: string | RegExp, opt = '') {\n  let source = typeof regex === 'string' ? regex : regex.source;\n  const obj = {\n    replace: (name: string | RegExp, val: string | RegExp) => {\n      let valSource = typeof val === 'string' ? val : val.source;\n      valSource = valSource.replace(other.caret, '$1');\n      source = source.replace(name, valSource);\n      return obj;\n    },\n    getRegex: () => {\n      return new RegExp(source, opt);\n    },\n  };\n  return obj;\n}\n\nexport const other = {\n  codeRemoveIndent: /^(?: {1,4}| {0,3}\\t)/gm,\n  outputLinkReplace: /\\\\([\\[\\]])/g,\n  indentCodeCompensation: /^(\\s+)(?:```)/,\n  beginningSpace: /^\\s+/,\n  endingHash: /#$/,\n  startingSpaceChar: /^ /,\n  endingSpaceChar: / $/,\n  nonSpaceChar: /[^ ]/,\n  newLineCharGlobal: /\\n/g,\n  tabCharGlobal: /\\t/g,\n  multipleSpaceGlobal: /\\s+/g,\n  blankLine: /^[ \\t]*$/,\n  doubleBlankLine: /\\n[ \\t]*\\n[ \\t]*$/,\n  blockquoteStart: /^ {0,3}>/,\n  blockquoteSetextReplace: /\\n {0,3}((?:=+|-+) *)(?=\\n|$)/g,\n  blockquoteSetextReplace2: /^ {0,3}>[ \\t]?/gm,\n  listReplaceTabs: /^\\t+/,\n  listReplaceNesting: /^ {1,4}(?=( {4})*[^ ])/g,\n  listIsTask: /^\\[[ xX]\\] /,\n  listReplaceTask: /^\\[[ xX]\\] +/,\n  anyLine: /\\n.*\\n/,\n  hrefBrackets: /^<(.*)>$/,\n  tableDelimiter: /[:|]/,\n  tableAlignChars: /^\\||\\| *$/g,\n  tableRowBlankLine: /\\n[ \\t]*$/,\n  tableAlignRight: /^ *-+: *$/,\n  tableAlignCenter: /^ *:-+: *$/,\n  tableAlignLeft: /^ *:-+ *$/,\n  startATag: /^<a /i,\n  endATag: /^<\\/a>/i,\n  startPreScriptTag: /^<(pre|code|kbd|script)(\\s|>)/i,\n  endPreScriptTag: /^<\\/(pre|code|kbd|script)(\\s|>)/i,\n  startAngleBracket: /^</,\n  endAngleBracket: />$/,\n  pedanticHrefTitle: /^([^'\"]*[^\\s])\\s+(['\"])(.*)\\2/,\n  unicodeAlphaNumeric: /[\\p{L}\\p{N}]/u,\n  escapeTest: /[&<>\"']/,\n  escapeReplace: /[&<>\"']/g,\n  escapeTestNoEncode: /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/,\n  escapeReplaceNoEncode: /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/g,\n  unescapeTest: /&(#(?:\\d+)|(?:#x[0-9A-Fa-f]+)|(?:\\w+));?/ig,\n  caret: /(^|[^\\[])\\^/g,\n  percentDecode: /%25/g,\n  findPipe: /\\|/g,\n  splitPipe: / \\|/,\n  slashPipe: /\\\\\\|/g,\n  carriageReturn: /\\r\\n|\\r/g,\n  spaceLine: /^ +$/gm,\n  notSpaceStart: /^\\S*/,\n  endingNewline: /\\n$/,\n  listItemRegex: (bull: string) => new RegExp(`^( {0,3}${bull})((?:[\\t ][^\\\\n]*)?(?:\\\\n|$))`),\n  nextBulletRegex: (indent: number) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}(?:[*+-]|\\\\d{1,9}[.)])((?:[ \\t][^\\\\n]*)?(?:\\\\n|$))`),\n  hrRegex: (indent: number) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}((?:- *){3,}|(?:_ *){3,}|(?:\\\\* *){3,})(?:\\\\n+|$)`),\n  fencesBeginRegex: (indent: number) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}(?:\\`\\`\\`|~~~)`),\n  headingBeginRegex: (indent: number) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}#`),\n  htmlBeginRegex: (indent: number) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}<(?:[a-z].*>|!--)`, 'i'),\n};\n\n/**\n * Block-Level Grammar\n */\n\nconst newline = /^(?:[ \\t]*(?:\\n|$))+/;\nconst blockCode = /^((?: {4}| {0,3}\\t)[^\\n]+(?:\\n(?:[ \\t]*(?:\\n|$))*)?)+/;\nconst fences = /^ {0,3}(`{3,}(?=[^`\\n]*(?:\\n|$))|~{3,})([^\\n]*)(?:\\n|$)(?:|([\\s\\S]*?)(?:\\n|$))(?: {0,3}\\1[~`]* *(?=\\n|$)|$)/;\nconst hr = /^ {0,3}((?:-[\\t ]*){3,}|(?:_[ \\t]*){3,}|(?:\\*[ \\t]*){3,})(?:\\n+|$)/;\nconst heading = /^ {0,3}(#{1,6})(?=\\s|$)(.*)(?:\\n+|$)/;\nconst bullet = /(?:[*+-]|\\d{1,9}[.)])/;\nconst lheadingCore = /^(?!bull |blockCode|fences|blockquote|heading|html|table)((?:.|\\n(?!\\s*?\\n|bull |blockCode|fences|blockquote|heading|html|table))+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/;\nconst lheading = edit(lheadingCore)\n  .replace(/bull/g, bullet) // lists can interrupt\n  .replace(/blockCode/g, /(?: {4}| {0,3}\\t)/) // indented code blocks can interrupt\n  .replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/) // fenced code blocks can interrupt\n  .replace(/blockquote/g, / {0,3}>/) // blockquote can interrupt\n  .replace(/heading/g, / {0,3}#{1,6}/) // ATX heading can interrupt\n  .replace(/html/g, / {0,3}<[^\\n>]+>\\n/) // block html can interrupt\n  .replace(/\\|table/g, '') // table not in commonmark\n  .getRegex();\nconst lheadingGfm = edit(lheadingCore)\n  .replace(/bull/g, bullet) // lists can interrupt\n  .replace(/blockCode/g, /(?: {4}| {0,3}\\t)/) // indented code blocks can interrupt\n  .replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/) // fenced code blocks can interrupt\n  .replace(/blockquote/g, / {0,3}>/) // blockquote can interrupt\n  .replace(/heading/g, / {0,3}#{1,6}/) // ATX heading can interrupt\n  .replace(/html/g, / {0,3}<[^\\n>]+>\\n/) // block html can interrupt\n  .replace(/table/g, / {0,3}\\|?(?:[:\\- ]*\\|)+[\\:\\- ]*\\n/) // table can interrupt\n  .getRegex();\nconst _paragraph = /^([^\\n]+(?:\\n(?!hr|heading|lheading|blockquote|fences|list|html|table| +\\n)[^\\n]+)*)/;\nconst blockText = /^[^\\n]+/;\nconst _blockLabel = /(?!\\s*\\])(?:\\\\.|[^\\[\\]\\\\])+/;\nconst def = edit(/^ {0,3}\\[(label)\\]: *(?:\\n[ \\t]*)?([^<\\s][^\\s]*|<.*?>)(?:(?: +(?:\\n[ \\t]*)?| *\\n[ \\t]*)(title))? *(?:\\n+|$)/)\n  .replace('label', _blockLabel)\n  .replace('title', /(?:\"(?:\\\\\"?|[^\"\\\\])*\"|'[^'\\n]*(?:\\n[^'\\n]+)*\\n?'|\\([^()]*\\))/)\n  .getRegex();\n\nconst list = edit(/^( {0,3}bull)([ \\t][^\\n]+?)?(?:\\n|$)/)\n  .replace(/bull/g, bullet)\n  .getRegex();\n\nconst _tag = 'address|article|aside|base|basefont|blockquote|body|caption'\n  + '|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption'\n  + '|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe'\n  + '|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option'\n  + '|p|param|search|section|summary|table|tbody|td|tfoot|th|thead|title'\n  + '|tr|track|ul';\nconst _comment = /<!--(?:-?>|[\\s\\S]*?(?:-->|$))/;\nconst html = edit(\n  '^ {0,3}(?:' // optional indentation\n+ '<(script|pre|style|textarea)[\\\\s>][\\\\s\\\\S]*?(?:</\\\\1>[^\\\\n]*\\\\n+|$)' // (1)\n+ '|comment[^\\\\n]*(\\\\n+|$)' // (2)\n+ '|<\\\\?[\\\\s\\\\S]*?(?:\\\\?>\\\\n*|$)' // (3)\n+ '|<![A-Z][\\\\s\\\\S]*?(?:>\\\\n*|$)' // (4)\n+ '|<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?(?:\\\\]\\\\]>\\\\n*|$)' // (5)\n+ '|</?(tag)(?: +|\\\\n|/?>)[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)' // (6)\n+ '|<(?!script|pre|style|textarea)([a-z][\\\\w-]*)(?:attribute)*? */?>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)' // (7) open tag\n+ '|</(?!script|pre|style|textarea)[a-z][\\\\w-]*\\\\s*>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)' // (7) closing tag\n+ ')', 'i')\n  .replace('comment', _comment)\n  .replace('tag', _tag)\n  .replace('attribute', / +[a-zA-Z:_][\\w.:-]*(?: *= *\"[^\"\\n]*\"| *= *'[^'\\n]*'| *= *[^\\s\"'=<>`]+)?/)\n  .getRegex();\n\nconst paragraph = edit(_paragraph)\n  .replace('hr', hr)\n  .replace('heading', ' {0,3}#{1,6}(?:\\\\s|$)')\n  .replace('|lheading', '') // setext headings don't interrupt commonmark paragraphs\n  .replace('|table', '')\n  .replace('blockquote', ' {0,3}>')\n  .replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n')\n  .replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n  .replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)')\n  .replace('tag', _tag) // pars can be interrupted by type (6) html blocks\n  .getRegex();\n\nconst blockquote = edit(/^( {0,3}> ?(paragraph|[^\\n]*)(?:\\n|$))+/)\n  .replace('paragraph', paragraph)\n  .getRegex();\n\n/**\n * Normal Block Grammar\n */\n\nconst blockNormal = {\n  blockquote,\n  code: blockCode,\n  def,\n  fences,\n  heading,\n  hr,\n  html,\n  lheading,\n  list,\n  newline,\n  paragraph,\n  table: noopTest,\n  text: blockText,\n};\n\ntype BlockKeys = keyof typeof blockNormal;\n\n/**\n * GFM Block Grammar\n */\n\nconst gfmTable = edit(\n  '^ *([^\\\\n ].*)\\\\n' // Header\n+ ' {0,3}((?:\\\\| *)?:?-+:? *(?:\\\\| *:?-+:? *)*(?:\\\\| *)?)' // Align\n+ '(?:\\\\n((?:(?! *\\\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\\\n|$))*)\\\\n*|$)') // Cells\n  .replace('hr', hr)\n  .replace('heading', ' {0,3}#{1,6}(?:\\\\s|$)')\n  .replace('blockquote', ' {0,3}>')\n  .replace('code', '(?: {4}| {0,3}\\t)[^\\\\n]')\n  .replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n')\n  .replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n  .replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)')\n  .replace('tag', _tag) // tables can be interrupted by type (6) html blocks\n  .getRegex();\n\nconst blockGfm: Record<BlockKeys, RegExp> = {\n  ...blockNormal,\n  lheading: lheadingGfm,\n  table: gfmTable,\n  paragraph: edit(_paragraph)\n    .replace('hr', hr)\n    .replace('heading', ' {0,3}#{1,6}(?:\\\\s|$)')\n    .replace('|lheading', '') // setext headings don't interrupt commonmark paragraphs\n    .replace('table', gfmTable) // interrupt paragraphs with table\n    .replace('blockquote', ' {0,3}>')\n    .replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n')\n    .replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n    .replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)')\n    .replace('tag', _tag) // pars can be interrupted by type (6) html blocks\n    .getRegex(),\n};\n\n/**\n * Pedantic grammar (original John Gruber's loose markdown specification)\n */\n\nconst blockPedantic: Record<BlockKeys, RegExp> = {\n  ...blockNormal,\n  html: edit(\n    '^ *(?:comment *(?:\\\\n|\\\\s*$)'\n    + '|<(tag)[\\\\s\\\\S]+?</\\\\1> *(?:\\\\n{2,}|\\\\s*$)' // closed tag\n    + '|<tag(?:\"[^\"]*\"|\\'[^\\']*\\'|\\\\s[^\\'\"/>\\\\s]*)*?/?> *(?:\\\\n{2,}|\\\\s*$))')\n    .replace('comment', _comment)\n    .replace(/tag/g, '(?!(?:'\n      + 'a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub'\n      + '|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)'\n      + '\\\\b)\\\\w+(?!:|[^\\\\w\\\\s@]*@)\\\\b')\n    .getRegex(),\n  def: /^ *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +([\"(][^\\n]+[\")]))? *(?:\\n+|$)/,\n  heading: /^(#{1,6})(.*)(?:\\n+|$)/,\n  fences: noopTest, // fences not supported\n  lheading: /^(.+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/,\n  paragraph: edit(_paragraph)\n    .replace('hr', hr)\n    .replace('heading', ' *#{1,6} *[^\\n]')\n    .replace('lheading', lheading)\n    .replace('|table', '')\n    .replace('blockquote', ' {0,3}>')\n    .replace('|fences', '')\n    .replace('|list', '')\n    .replace('|html', '')\n    .replace('|tag', '')\n    .getRegex(),\n};\n\n/**\n * Inline-Level Grammar\n */\n\nconst escape = /^\\\\([!\"#$%&'()*+,\\-./:;<=>?@\\[\\]\\\\^_`{|}~])/;\nconst inlineCode = /^(`+)([^`]|[^`][\\s\\S]*?[^`])\\1(?!`)/;\nconst br = /^( {2,}|\\\\)\\n(?!\\s*$)/;\nconst inlineText = /^(`+|[^`])(?:(?= {2,}\\n)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*_]|\\b_|$)|[^ ](?= {2,}\\n)))/;\n\n// list of unicode punctuation marks, plus any missing characters from CommonMark spec\nconst _punctuation = /[\\p{P}\\p{S}]/u;\nconst _punctuationOrSpace = /[\\s\\p{P}\\p{S}]/u;\nconst _notPunctuationOrSpace = /[^\\s\\p{P}\\p{S}]/u;\nconst punctuation = edit(/^((?![*_])punctSpace)/, 'u')\n  .replace(/punctSpace/g, _punctuationOrSpace).getRegex();\n\n// GFM allows ~ inside strong and em for strikethrough\nconst _punctuationGfmStrongEm = /(?!~)[\\p{P}\\p{S}]/u;\nconst _punctuationOrSpaceGfmStrongEm = /(?!~)[\\s\\p{P}\\p{S}]/u;\nconst _notPunctuationOrSpaceGfmStrongEm = /(?:[^\\s\\p{P}\\p{S}]|~)/u;\n\n// sequences em should skip over [title](link), `code`, <html>\nconst blockSkip = /\\[[^[\\]]*?\\]\\((?:\\\\.|[^\\\\\\(\\)]|\\((?:\\\\.|[^\\\\\\(\\)])*\\))*\\)|`[^`]*?`|<[^<>]*?>/g;\n\nconst emStrongLDelimCore = /^(?:\\*+(?:((?!\\*)punct)|[^\\s*]))|^_+(?:((?!_)punct)|([^\\s_]))/;\n\nconst emStrongLDelim = edit(emStrongLDelimCore, 'u')\n  .replace(/punct/g, _punctuation)\n  .getRegex();\n\nconst emStrongLDelimGfm = edit(emStrongLDelimCore, 'u')\n  .replace(/punct/g, _punctuationGfmStrongEm)\n  .getRegex();\n\nconst emStrongRDelimAstCore =\n  '^[^_*]*?__[^_*]*?\\\\*[^_*]*?(?=__)' // Skip orphan inside strong\n+ '|[^*]+(?=[^*])' // Consume to delim\n+ '|(?!\\\\*)punct(\\\\*+)(?=[\\\\s]|$)' // (1) #*** can only be a Right Delimiter\n+ '|notPunctSpace(\\\\*+)(?!\\\\*)(?=punctSpace|$)' // (2) a***#, a*** can only be a Right Delimiter\n+ '|(?!\\\\*)punctSpace(\\\\*+)(?=notPunctSpace)' // (3) #***a, ***a can only be Left Delimiter\n+ '|[\\\\s](\\\\*+)(?!\\\\*)(?=punct)' // (4) ***# can only be Left Delimiter\n+ '|(?!\\\\*)punct(\\\\*+)(?!\\\\*)(?=punct)' // (5) #***# can be either Left or Right Delimiter\n+ '|notPunctSpace(\\\\*+)(?=notPunctSpace)'; // (6) a***a can be either Left or Right Delimiter\n\nconst emStrongRDelimAst = edit(emStrongRDelimAstCore, 'gu')\n  .replace(/notPunctSpace/g, _notPunctuationOrSpace)\n  .replace(/punctSpace/g, _punctuationOrSpace)\n  .replace(/punct/g, _punctuation)\n  .getRegex();\n\nconst emStrongRDelimAstGfm = edit(emStrongRDelimAstCore, 'gu')\n  .replace(/notPunctSpace/g, _notPunctuationOrSpaceGfmStrongEm)\n  .replace(/punctSpace/g, _punctuationOrSpaceGfmStrongEm)\n  .replace(/punct/g, _punctuationGfmStrongEm)\n  .getRegex();\n\n// (6) Not allowed for _\nconst emStrongRDelimUnd = edit(\n  '^[^_*]*?\\\\*\\\\*[^_*]*?_[^_*]*?(?=\\\\*\\\\*)' // Skip orphan inside strong\n+ '|[^_]+(?=[^_])' // Consume to delim\n+ '|(?!_)punct(_+)(?=[\\\\s]|$)' // (1) #___ can only be a Right Delimiter\n+ '|notPunctSpace(_+)(?!_)(?=punctSpace|$)' // (2) a___#, a___ can only be a Right Delimiter\n+ '|(?!_)punctSpace(_+)(?=notPunctSpace)' // (3) #___a, ___a can only be Left Delimiter\n+ '|[\\\\s](_+)(?!_)(?=punct)' // (4) ___# can only be Left Delimiter\n+ '|(?!_)punct(_+)(?!_)(?=punct)', 'gu') // (5) #___# can be either Left or Right Delimiter\n  .replace(/notPunctSpace/g, _notPunctuationOrSpace)\n  .replace(/punctSpace/g, _punctuationOrSpace)\n  .replace(/punct/g, _punctuation)\n  .getRegex();\n\nconst anyPunctuation = edit(/\\\\(punct)/, 'gu')\n  .replace(/punct/g, _punctuation)\n  .getRegex();\n\nconst autolink = edit(/^<(scheme:[^\\s\\x00-\\x1f<>]*|email)>/)\n  .replace('scheme', /[a-zA-Z][a-zA-Z0-9+.-]{1,31}/)\n  .replace('email', /[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/)\n  .getRegex();\n\nconst _inlineComment = edit(_comment).replace('(?:-->|$)', '-->').getRegex();\nconst tag = edit(\n  '^comment'\n    + '|^</[a-zA-Z][\\\\w:-]*\\\\s*>' // self-closing tag\n    + '|^<[a-zA-Z][\\\\w-]*(?:attribute)*?\\\\s*/?>' // open tag\n    + '|^<\\\\?[\\\\s\\\\S]*?\\\\?>' // processing instruction, e.g. <?php ?>\n    + '|^<![a-zA-Z]+\\\\s[\\\\s\\\\S]*?>' // declaration, e.g. <!DOCTYPE html>\n    + '|^<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?\\\\]\\\\]>') // CDATA section\n  .replace('comment', _inlineComment)\n  .replace('attribute', /\\s+[a-zA-Z:_][\\w.:-]*(?:\\s*=\\s*\"[^\"]*\"|\\s*=\\s*'[^']*'|\\s*=\\s*[^\\s\"'=<>`]+)?/)\n  .getRegex();\n\nconst _inlineLabel = /(?:\\[(?:\\\\.|[^\\[\\]\\\\])*\\]|\\\\.|`[^`]*`|[^\\[\\]\\\\`])*?/;\n\nconst link = edit(/^!?\\[(label)\\]\\(\\s*(href)(?:(?:[ \\t]*(?:\\n[ \\t]*)?)(title))?\\s*\\)/)\n  .replace('label', _inlineLabel)\n  .replace('href', /<(?:\\\\.|[^\\n<>\\\\])+>|[^ \\t\\n\\x00-\\x1f]*/)\n  .replace('title', /\"(?:\\\\\"?|[^\"\\\\])*\"|'(?:\\\\'?|[^'\\\\])*'|\\((?:\\\\\\)?|[^)\\\\])*\\)/)\n  .getRegex();\n\nconst reflink = edit(/^!?\\[(label)\\]\\[(ref)\\]/)\n  .replace('label', _inlineLabel)\n  .replace('ref', _blockLabel)\n  .getRegex();\n\nconst nolink = edit(/^!?\\[(ref)\\](?:\\[\\])?/)\n  .replace('ref', _blockLabel)\n  .getRegex();\n\nconst reflinkSearch = edit('reflink|nolink(?!\\\\()', 'g')\n  .replace('reflink', reflink)\n  .replace('nolink', nolink)\n  .getRegex();\n\n/**\n * Normal Inline Grammar\n */\n\nconst inlineNormal = {\n  _backpedal: noopTest, // only used for GFM url\n  anyPunctuation,\n  autolink,\n  blockSkip,\n  br,\n  code: inlineCode,\n  del: noopTest,\n  emStrongLDelim,\n  emStrongRDelimAst,\n  emStrongRDelimUnd,\n  escape,\n  link,\n  nolink,\n  punctuation,\n  reflink,\n  reflinkSearch,\n  tag,\n  text: inlineText,\n  url: noopTest,\n};\n\ntype InlineKeys = keyof typeof inlineNormal;\n\n/**\n * Pedantic Inline Grammar\n */\n\nconst inlinePedantic: Record<InlineKeys, RegExp> = {\n  ...inlineNormal,\n  link: edit(/^!?\\[(label)\\]\\((.*?)\\)/)\n    .replace('label', _inlineLabel)\n    .getRegex(),\n  reflink: edit(/^!?\\[(label)\\]\\s*\\[([^\\]]*)\\]/)\n    .replace('label', _inlineLabel)\n    .getRegex(),\n};\n\n/**\n * GFM Inline Grammar\n */\n\nconst inlineGfm: Record<InlineKeys, RegExp> = {\n  ...inlineNormal,\n  emStrongRDelimAst: emStrongRDelimAstGfm,\n  emStrongLDelim: emStrongLDelimGfm,\n  url: edit(/^((?:ftp|https?):\\/\\/|www\\.)(?:[a-zA-Z0-9\\-]+\\.?)+[^\\s<]*|^email/, 'i')\n    .replace('email', /[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/)\n    .getRegex(),\n  _backpedal: /(?:[^?!.,:;*_'\"~()&]+|\\([^)]*\\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_'\"~)]+(?!$))+/,\n  del: /^(~~?)(?=[^\\s~])((?:\\\\.|[^\\\\])*?(?:\\\\.|[^\\s~\\\\]))\\1(?=[^~]|$)/,\n  text: /^([`~]+|[^`~])(?:(?= {2,}\\n)|(?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*~_]|\\b_|https?:\\/\\/|ftp:\\/\\/|www\\.|$)|[^ ](?= {2,}\\n)|[^a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-](?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)))/,\n};\n\n/**\n * GFM + Line Breaks Inline Grammar\n */\n\nconst inlineBreaks: Record<InlineKeys, RegExp> = {\n  ...inlineGfm,\n  br: edit(br).replace('{2,}', '*').getRegex(),\n  text: edit(inlineGfm.text)\n    .replace('\\\\b_', '\\\\b_| {2,}\\\\n')\n    .replace(/\\{2,\\}/g, '*')\n    .getRegex(),\n};\n\n/**\n * exports\n */\n\nexport const block = {\n  normal: blockNormal,\n  gfm: blockGfm,\n  pedantic: blockPedantic,\n};\n\nexport const inline = {\n  normal: inlineNormal,\n  gfm: inlineGfm,\n  breaks: inlineBreaks,\n  pedantic: inlinePedantic,\n};\n\nexport interface Rules {\n  other: typeof other\n  block: Record<BlockKeys, RegExp>\n  inline: Record<InlineKeys, RegExp>\n}\n","import { other } from './rules.ts';\n\n/**\n * Helpers\n */\nconst escapeReplacements: { [index: string]: string } = {\n  '&': '&amp;',\n  '<': '&lt;',\n  '>': '&gt;',\n  '\"': '&quot;',\n  \"'\": '&#39;',\n};\nconst getEscapeReplacement = (ch: string) => escapeReplacements[ch];\n\nexport function escape(html: string, encode?: boolean) {\n  if (encode) {\n    if (other.escapeTest.test(html)) {\n      return html.replace(other.escapeReplace, getEscapeReplacement);\n    }\n  } else {\n    if (other.escapeTestNoEncode.test(html)) {\n      return html.replace(other.escapeReplaceNoEncode, getEscapeReplacement);\n    }\n  }\n\n  return html;\n}\n\nexport function unescape(html: string) {\n  // explicitly match decimal, hex, and named HTML entities\n  return html.replace(other.unescapeTest, (_, n) => {\n    n = n.toLowerCase();\n    if (n === 'colon') return ':';\n    if (n.charAt(0) === '#') {\n      return n.charAt(1) === 'x'\n        ? String.fromCharCode(parseInt(n.substring(2), 16))\n        : String.fromCharCode(+n.substring(1));\n    }\n    return '';\n  });\n}\n\nexport function cleanUrl(href: string) {\n  try {\n    href = encodeURI(href).replace(other.percentDecode, '%');\n  } catch {\n    return null;\n  }\n  return href;\n}\n\nexport function splitCells(tableRow: string, count?: number) {\n  // ensure that every cell-delimiting pipe has a space\n  // before it to distinguish it from an escaped pipe\n  const row = tableRow.replace(other.findPipe, (match, offset, str) => {\n      let escaped = false;\n      let curr = offset;\n      while (--curr >= 0 && str[curr] === '\\\\') escaped = !escaped;\n      if (escaped) {\n        // odd number of slashes means | is escaped\n        // so we leave it alone\n        return '|';\n      } else {\n        // add space before unescaped |\n        return ' |';\n      }\n    }),\n    cells = row.split(other.splitPipe);\n  let i = 0;\n\n  // First/last cell in a row cannot be empty if it has no leading/trailing pipe\n  if (!cells[0].trim()) {\n    cells.shift();\n  }\n  if (cells.length > 0 && !cells.at(-1)?.trim()) {\n    cells.pop();\n  }\n\n  if (count) {\n    if (cells.length > count) {\n      cells.splice(count);\n    } else {\n      while (cells.length < count) cells.push('');\n    }\n  }\n\n  for (; i < cells.length; i++) {\n    // leading or trailing whitespace is ignored per the gfm spec\n    cells[i] = cells[i].trim().replace(other.slashPipe, '|');\n  }\n  return cells;\n}\n\n/**\n * Remove trailing 'c's. Equivalent to str.replace(/c*$/, '').\n * /c*$/ is vulnerable to REDOS.\n *\n * @param str\n * @param c\n * @param invert Remove suffix of non-c chars instead. Default falsey.\n */\nexport function rtrim(str: string, c: string, invert?: boolean) {\n  const l = str.length;\n  if (l === 0) {\n    return '';\n  }\n\n  // Length of suffix matching the invert condition.\n  let suffLen = 0;\n\n  // Step left until we fail to match the invert condition.\n  while (suffLen < l) {\n    const currChar = str.charAt(l - suffLen - 1);\n    if (currChar === c && !invert) {\n      suffLen++;\n    } else if (currChar !== c && invert) {\n      suffLen++;\n    } else {\n      break;\n    }\n  }\n\n  return str.slice(0, l - suffLen);\n}\n\nexport function findClosingBracket(str: string, b: string) {\n  if (str.indexOf(b[1]) === -1) {\n    return -1;\n  }\n\n  let level = 0;\n  for (let i = 0; i < str.length; i++) {\n    if (str[i] === '\\\\') {\n      i++;\n    } else if (str[i] === b[0]) {\n      level++;\n    } else if (str[i] === b[1]) {\n      level--;\n      if (level < 0) {\n        return i;\n      }\n    }\n  }\n  if (level > 0) {\n    return -2;\n  }\n\n  return -1;\n}\n","import { _defaults } from './defaults.ts';\nimport {\n  rtrim,\n  splitCells,\n  findClosingBracket,\n} from './helpers.ts';\nimport type { Rules } from './rules.ts';\nimport type { _Lexer } from './Lexer.ts';\nimport type { Links, Tokens, Token } from './Tokens.ts';\nimport type { MarkedOptions } from './MarkedOptions.ts';\n\nfunction outputLink(cap: string[], link: Pick<Tokens.Link, 'href' | 'title'>, raw: string, lexer: _Lexer, rules: Rules): Tokens.Link | Tokens.Image {\n  const href = link.href;\n  const title = link.title || null;\n  const text = cap[1].replace(rules.other.outputLinkReplace, '$1');\n\n  lexer.state.inLink = true;\n  const token: Tokens.Link | Tokens.Image = {\n    type: cap[0].charAt(0) === '!' ? 'image' : 'link',\n    raw,\n    href,\n    title,\n    text,\n    tokens: lexer.inlineTokens(text),\n  };\n  lexer.state.inLink = false;\n  return token;\n}\n\nfunction indentCodeCompensation(raw: string, text: string, rules: Rules) {\n  const matchIndentToCode = raw.match(rules.other.indentCodeCompensation);\n\n  if (matchIndentToCode === null) {\n    return text;\n  }\n\n  const indentToCode = matchIndentToCode[1];\n\n  return text\n    .split('\\n')\n    .map(node => {\n      const matchIndentInNode = node.match(rules.other.beginningSpace);\n      if (matchIndentInNode === null) {\n        return node;\n      }\n\n      const [indentInNode] = matchIndentInNode;\n\n      if (indentInNode.length >= indentToCode.length) {\n        return node.slice(indentToCode.length);\n      }\n\n      return node;\n    })\n    .join('\\n');\n}\n\n/**\n * Tokenizer\n */\nexport class _Tokenizer {\n  options: MarkedOptions;\n  rules!: Rules; // set by the lexer\n  lexer!: _Lexer; // set by the lexer\n\n  constructor(options?: MarkedOptions) {\n    this.options = options || _defaults;\n  }\n\n  space(src: string): Tokens.Space | undefined {\n    const cap = this.rules.block.newline.exec(src);\n    if (cap && cap[0].length > 0) {\n      return {\n        type: 'space',\n        raw: cap[0],\n      };\n    }\n  }\n\n  code(src: string): Tokens.Code | undefined {\n    const cap = this.rules.block.code.exec(src);\n    if (cap) {\n      const text = cap[0].replace(this.rules.other.codeRemoveIndent, '');\n      return {\n        type: 'code',\n        raw: cap[0],\n        codeBlockStyle: 'indented',\n        text: !this.options.pedantic\n          ? rtrim(text, '\\n')\n          : text,\n      };\n    }\n  }\n\n  fences(src: string): Tokens.Code | undefined {\n    const cap = this.rules.block.fences.exec(src);\n    if (cap) {\n      const raw = cap[0];\n      const text = indentCodeCompensation(raw, cap[3] || '', this.rules);\n\n      return {\n        type: 'code',\n        raw,\n        lang: cap[2] ? cap[2].trim().replace(this.rules.inline.anyPunctuation, '$1') : cap[2],\n        text,\n      };\n    }\n  }\n\n  heading(src: string): Tokens.Heading | undefined {\n    const cap = this.rules.block.heading.exec(src);\n    if (cap) {\n      let text = cap[2].trim();\n\n      // remove trailing #s\n      if (this.rules.other.endingHash.test(text)) {\n        const trimmed = rtrim(text, '#');\n        if (this.options.pedantic) {\n          text = trimmed.trim();\n        } else if (!trimmed || this.rules.other.endingSpaceChar.test(trimmed)) {\n          // CommonMark requires space before trailing #s\n          text = trimmed.trim();\n        }\n      }\n\n      return {\n        type: 'heading',\n        raw: cap[0],\n        depth: cap[1].length,\n        text,\n        tokens: this.lexer.inline(text),\n      };\n    }\n  }\n\n  hr(src: string): Tokens.Hr | undefined {\n    const cap = this.rules.block.hr.exec(src);\n    if (cap) {\n      return {\n        type: 'hr',\n        raw: rtrim(cap[0], '\\n'),\n      };\n    }\n  }\n\n  blockquote(src: string): Tokens.Blockquote | undefined {\n    const cap = this.rules.block.blockquote.exec(src);\n    if (cap) {\n      let lines = rtrim(cap[0], '\\n').split('\\n');\n      let raw = '';\n      let text = '';\n      const tokens: Token[] = [];\n\n      while (lines.length > 0) {\n        let inBlockquote = false;\n        const currentLines = [];\n\n        let i;\n        for (i = 0; i < lines.length; i++) {\n          // get lines up to a continuation\n          if (this.rules.other.blockquoteStart.test(lines[i])) {\n            currentLines.push(lines[i]);\n            inBlockquote = true;\n          } else if (!inBlockquote) {\n            currentLines.push(lines[i]);\n          } else {\n            break;\n          }\n        }\n        lines = lines.slice(i);\n\n        const currentRaw = currentLines.join('\\n');\n        const currentText = currentRaw\n          // precede setext continuation with 4 spaces so it isn't a setext\n          .replace(this.rules.other.blockquoteSetextReplace, '\\n    $1')\n          .replace(this.rules.other.blockquoteSetextReplace2, '');\n        raw = raw ? `${raw}\\n${currentRaw}` : currentRaw;\n        text = text ? `${text}\\n${currentText}` : currentText;\n\n        // parse blockquote lines as top level tokens\n        // merge paragraphs if this is a continuation\n        const top = this.lexer.state.top;\n        this.lexer.state.top = true;\n        this.lexer.blockTokens(currentText, tokens, true);\n        this.lexer.state.top = top;\n\n        // if there is no continuation then we are done\n        if (lines.length === 0) {\n          break;\n        }\n\n        const lastToken = tokens.at(-1);\n\n        if (lastToken?.type === 'code') {\n          // blockquote continuation cannot be preceded by a code block\n          break;\n        } else if (lastToken?.type === 'blockquote') {\n          // include continuation in nested blockquote\n          const oldToken = lastToken as Tokens.Blockquote;\n          const newText = oldToken.raw + '\\n' + lines.join('\\n');\n          const newToken = this.blockquote(newText)!;\n          tokens[tokens.length - 1] = newToken;\n\n          raw = raw.substring(0, raw.length - oldToken.raw.length) + newToken.raw;\n          text = text.substring(0, text.length - oldToken.text.length) + newToken.text;\n          break;\n        } else if (lastToken?.type === 'list') {\n          // include continuation in nested list\n          const oldToken = lastToken as Tokens.List;\n          const newText = oldToken.raw + '\\n' + lines.join('\\n');\n          const newToken = this.list(newText)!;\n          tokens[tokens.length - 1] = newToken;\n\n          raw = raw.substring(0, raw.length - lastToken.raw.length) + newToken.raw;\n          text = text.substring(0, text.length - oldToken.raw.length) + newToken.raw;\n          lines = newText.substring(tokens.at(-1)!.raw.length).split('\\n');\n          continue;\n        }\n      }\n\n      return {\n        type: 'blockquote',\n        raw,\n        tokens,\n        text,\n      };\n    }\n  }\n\n  list(src: string): Tokens.List | undefined {\n    let cap = this.rules.block.list.exec(src);\n    if (cap) {\n      let bull = cap[1].trim();\n      const isordered = bull.length > 1;\n\n      const list: Tokens.List = {\n        type: 'list',\n        raw: '',\n        ordered: isordered,\n        start: isordered ? +bull.slice(0, -1) : '',\n        loose: false,\n        items: [],\n      };\n\n      bull = isordered ? `\\\\d{1,9}\\\\${bull.slice(-1)}` : `\\\\${bull}`;\n\n      if (this.options.pedantic) {\n        bull = isordered ? bull : '[*+-]';\n      }\n\n      // Get next list item\n      const itemRegex = this.rules.other.listItemRegex(bull);\n      let endsWithBlankLine = false;\n      // Check if current bullet point can start a new List Item\n      while (src) {\n        let endEarly = false;\n        let raw = '';\n        let itemContents = '';\n        if (!(cap = itemRegex.exec(src))) {\n          break;\n        }\n\n        if (this.rules.block.hr.test(src)) { // End list if bullet was actually HR (possibly move into itemRegex?)\n          break;\n        }\n\n        raw = cap[0];\n        src = src.substring(raw.length);\n\n        let line = cap[2].split('\\n', 1)[0].replace(this.rules.other.listReplaceTabs, (t: string) => ' '.repeat(3 * t.length));\n        let nextLine = src.split('\\n', 1)[0];\n        let blankLine = !line.trim();\n\n        let indent = 0;\n        if (this.options.pedantic) {\n          indent = 2;\n          itemContents = line.trimStart();\n        } else if (blankLine) {\n          indent = cap[1].length + 1;\n        } else {\n          indent = cap[2].search(this.rules.other.nonSpaceChar); // Find first non-space char\n          indent = indent > 4 ? 1 : indent; // Treat indented code blocks (> 4 spaces) as having only 1 indent\n          itemContents = line.slice(indent);\n          indent += cap[1].length;\n        }\n\n        if (blankLine && this.rules.other.blankLine.test(nextLine)) { // Items begin with at most one blank line\n          raw += nextLine + '\\n';\n          src = src.substring(nextLine.length + 1);\n          endEarly = true;\n        }\n\n        if (!endEarly) {\n          const nextBulletRegex = this.rules.other.nextBulletRegex(indent);\n          const hrRegex = this.rules.other.hrRegex(indent);\n          const fencesBeginRegex = this.rules.other.fencesBeginRegex(indent);\n          const headingBeginRegex = this.rules.other.headingBeginRegex(indent);\n          const htmlBeginRegex = this.rules.other.htmlBeginRegex(indent);\n\n          // Check if following lines should be included in List Item\n          while (src) {\n            const rawLine = src.split('\\n', 1)[0];\n            let nextLineWithoutTabs;\n            nextLine = rawLine;\n\n            // Re-align to follow commonmark nesting rules\n            if (this.options.pedantic) {\n              nextLine = nextLine.replace(this.rules.other.listReplaceNesting, '  ');\n              nextLineWithoutTabs = nextLine;\n            } else {\n              nextLineWithoutTabs = nextLine.replace(this.rules.other.tabCharGlobal, '    ');\n            }\n\n            // End list item if found code fences\n            if (fencesBeginRegex.test(nextLine)) {\n              break;\n            }\n\n            // End list item if found start of new heading\n            if (headingBeginRegex.test(nextLine)) {\n              break;\n            }\n\n            // End list item if found start of html block\n            if (htmlBeginRegex.test(nextLine)) {\n              break;\n            }\n\n            // End list item if found start of new bullet\n            if (nextBulletRegex.test(nextLine)) {\n              break;\n            }\n\n            // Horizontal rule found\n            if (hrRegex.test(nextLine)) {\n              break;\n            }\n\n            if (nextLineWithoutTabs.search(this.rules.other.nonSpaceChar) >= indent || !nextLine.trim()) { // Dedent if possible\n              itemContents += '\\n' + nextLineWithoutTabs.slice(indent);\n            } else {\n              // not enough indentation\n              if (blankLine) {\n                break;\n              }\n\n              // paragraph continuation unless last line was a different block level element\n              if (line.replace(this.rules.other.tabCharGlobal, '    ').search(this.rules.other.nonSpaceChar) >= 4) { // indented code block\n                break;\n              }\n              if (fencesBeginRegex.test(line)) {\n                break;\n              }\n              if (headingBeginRegex.test(line)) {\n                break;\n              }\n              if (hrRegex.test(line)) {\n                break;\n              }\n\n              itemContents += '\\n' + nextLine;\n            }\n\n            if (!blankLine && !nextLine.trim()) { // Check if current line is blank\n              blankLine = true;\n            }\n\n            raw += rawLine + '\\n';\n            src = src.substring(rawLine.length + 1);\n            line = nextLineWithoutTabs.slice(indent);\n          }\n        }\n\n        if (!list.loose) {\n          // If the previous item ended with a blank line, the list is loose\n          if (endsWithBlankLine) {\n            list.loose = true;\n          } else if (this.rules.other.doubleBlankLine.test(raw)) {\n            endsWithBlankLine = true;\n          }\n        }\n\n        let istask: RegExpExecArray | null = null;\n        let ischecked: boolean | undefined;\n        // Check for task list items\n        if (this.options.gfm) {\n          istask = this.rules.other.listIsTask.exec(itemContents);\n          if (istask) {\n            ischecked = istask[0] !== '[ ] ';\n            itemContents = itemContents.replace(this.rules.other.listReplaceTask, '');\n          }\n        }\n\n        list.items.push({\n          type: 'list_item',\n          raw,\n          task: !!istask,\n          checked: ischecked,\n          loose: false,\n          text: itemContents,\n          tokens: [],\n        });\n\n        list.raw += raw;\n      }\n\n      // Do not consume newlines at end of final item. Alternatively, make itemRegex *start* with any newlines to simplify/speed up endsWithBlankLine logic\n      const lastItem = list.items.at(-1);\n      if (lastItem) {\n        lastItem.raw = lastItem.raw.trimEnd();\n        lastItem.text = lastItem.text.trimEnd();\n      } else {\n        // not a list since there were no items\n        return;\n      }\n      list.raw = list.raw.trimEnd();\n\n      // Item child tokens handled here at end because we needed to have the final item to trim it first\n      for (let i = 0; i < list.items.length; i++) {\n        this.lexer.state.top = false;\n        list.items[i].tokens = this.lexer.blockTokens(list.items[i].text, []);\n\n        if (!list.loose) {\n          // Check if list should be loose\n          const spacers = list.items[i].tokens.filter(t => t.type === 'space');\n          const hasMultipleLineBreaks = spacers.length > 0 && spacers.some(t => this.rules.other.anyLine.test(t.raw));\n\n          list.loose = hasMultipleLineBreaks;\n        }\n      }\n\n      // Set all items to loose if list is loose\n      if (list.loose) {\n        for (let i = 0; i < list.items.length; i++) {\n          list.items[i].loose = true;\n        }\n      }\n\n      return list;\n    }\n  }\n\n  html(src: string): Tokens.HTML | undefined {\n    const cap = this.rules.block.html.exec(src);\n    if (cap) {\n      const token: Tokens.HTML = {\n        type: 'html',\n        block: true,\n        raw: cap[0],\n        pre: cap[1] === 'pre' || cap[1] === 'script' || cap[1] === 'style',\n        text: cap[0],\n      };\n      return token;\n    }\n  }\n\n  def(src: string): Tokens.Def | undefined {\n    const cap = this.rules.block.def.exec(src);\n    if (cap) {\n      const tag = cap[1].toLowerCase().replace(this.rules.other.multipleSpaceGlobal, ' ');\n      const href = cap[2] ? cap[2].replace(this.rules.other.hrefBrackets, '$1').replace(this.rules.inline.anyPunctuation, '$1') : '';\n      const title = cap[3] ? cap[3].substring(1, cap[3].length - 1).replace(this.rules.inline.anyPunctuation, '$1') : cap[3];\n      return {\n        type: 'def',\n        tag,\n        raw: cap[0],\n        href,\n        title,\n      };\n    }\n  }\n\n  table(src: string): Tokens.Table | undefined {\n    const cap = this.rules.block.table.exec(src);\n    if (!cap) {\n      return;\n    }\n\n    if (!this.rules.other.tableDelimiter.test(cap[2])) {\n      // delimiter row must have a pipe (|) or colon (:) otherwise it is a setext heading\n      return;\n    }\n\n    const headers = splitCells(cap[1]);\n    const aligns = cap[2].replace(this.rules.other.tableAlignChars, '').split('|');\n    const rows = cap[3]?.trim() ? cap[3].replace(this.rules.other.tableRowBlankLine, '').split('\\n') : [];\n\n    const item: Tokens.Table = {\n      type: 'table',\n      raw: cap[0],\n      header: [],\n      align: [],\n      rows: [],\n    };\n\n    if (headers.length !== aligns.length) {\n      // header and align columns must be equal, rows can be different.\n      return;\n    }\n\n    for (const align of aligns) {\n      if (this.rules.other.tableAlignRight.test(align)) {\n        item.align.push('right');\n      } else if (this.rules.other.tableAlignCenter.test(align)) {\n        item.align.push('center');\n      } else if (this.rules.other.tableAlignLeft.test(align)) {\n        item.align.push('left');\n      } else {\n        item.align.push(null);\n      }\n    }\n\n    for (let i = 0; i < headers.length; i++) {\n      item.header.push({\n        text: headers[i],\n        tokens: this.lexer.inline(headers[i]),\n        header: true,\n        align: item.align[i],\n      });\n    }\n\n    for (const row of rows) {\n      item.rows.push(splitCells(row, item.header.length).map((cell, i) => {\n        return {\n          text: cell,\n          tokens: this.lexer.inline(cell),\n          header: false,\n          align: item.align[i],\n        };\n      }));\n    }\n\n    return item;\n  }\n\n  lheading(src: string): Tokens.Heading | undefined {\n    const cap = this.rules.block.lheading.exec(src);\n    if (cap) {\n      return {\n        type: 'heading',\n        raw: cap[0],\n        depth: cap[2].charAt(0) === '=' ? 1 : 2,\n        text: cap[1],\n        tokens: this.lexer.inline(cap[1]),\n      };\n    }\n  }\n\n  paragraph(src: string): Tokens.Paragraph | undefined {\n    const cap = this.rules.block.paragraph.exec(src);\n    if (cap) {\n      const text = cap[1].charAt(cap[1].length - 1) === '\\n'\n        ? cap[1].slice(0, -1)\n        : cap[1];\n      return {\n        type: 'paragraph',\n        raw: cap[0],\n        text,\n        tokens: this.lexer.inline(text),\n      };\n    }\n  }\n\n  text(src: string): Tokens.Text | undefined {\n    const cap = this.rules.block.text.exec(src);\n    if (cap) {\n      return {\n        type: 'text',\n        raw: cap[0],\n        text: cap[0],\n        tokens: this.lexer.inline(cap[0]),\n      };\n    }\n  }\n\n  escape(src: string): Tokens.Escape | undefined {\n    const cap = this.rules.inline.escape.exec(src);\n    if (cap) {\n      return {\n        type: 'escape',\n        raw: cap[0],\n        text: cap[1],\n      };\n    }\n  }\n\n  tag(src: string): Tokens.Tag | undefined {\n    const cap = this.rules.inline.tag.exec(src);\n    if (cap) {\n      if (!this.lexer.state.inLink && this.rules.other.startATag.test(cap[0])) {\n        this.lexer.state.inLink = true;\n      } else if (this.lexer.state.inLink && this.rules.other.endATag.test(cap[0])) {\n        this.lexer.state.inLink = false;\n      }\n      if (!this.lexer.state.inRawBlock && this.rules.other.startPreScriptTag.test(cap[0])) {\n        this.lexer.state.inRawBlock = true;\n      } else if (this.lexer.state.inRawBlock && this.rules.other.endPreScriptTag.test(cap[0])) {\n        this.lexer.state.inRawBlock = false;\n      }\n\n      return {\n        type: 'html',\n        raw: cap[0],\n        inLink: this.lexer.state.inLink,\n        inRawBlock: this.lexer.state.inRawBlock,\n        block: false,\n        text: cap[0],\n      };\n    }\n  }\n\n  link(src: string): Tokens.Link | Tokens.Image | undefined {\n    const cap = this.rules.inline.link.exec(src);\n    if (cap) {\n      const trimmedUrl = cap[2].trim();\n      if (!this.options.pedantic && this.rules.other.startAngleBracket.test(trimmedUrl)) {\n        // commonmark requires matching angle brackets\n        if (!(this.rules.other.endAngleBracket.test(trimmedUrl))) {\n          return;\n        }\n\n        // ending angle bracket cannot be escaped\n        const rtrimSlash = rtrim(trimmedUrl.slice(0, -1), '\\\\');\n        if ((trimmedUrl.length - rtrimSlash.length) % 2 === 0) {\n          return;\n        }\n      } else {\n        // find closing parenthesis\n        const lastParenIndex = findClosingBracket(cap[2], '()');\n        if (lastParenIndex === -2) {\n          // more open parens than closed\n          return;\n        }\n\n        if (lastParenIndex > -1) {\n          const start = cap[0].indexOf('!') === 0 ? 5 : 4;\n          const linkLen = start + cap[1].length + lastParenIndex;\n          cap[2] = cap[2].substring(0, lastParenIndex);\n          cap[0] = cap[0].substring(0, linkLen).trim();\n          cap[3] = '';\n        }\n      }\n      let href = cap[2];\n      let title = '';\n      if (this.options.pedantic) {\n        // split pedantic href and title\n        const link = this.rules.other.pedanticHrefTitle.exec(href);\n\n        if (link) {\n          href = link[1];\n          title = link[3];\n        }\n      } else {\n        title = cap[3] ? cap[3].slice(1, -1) : '';\n      }\n\n      href = href.trim();\n      if (this.rules.other.startAngleBracket.test(href)) {\n        if (this.options.pedantic && !(this.rules.other.endAngleBracket.test(trimmedUrl))) {\n          // pedantic allows starting angle bracket without ending angle bracket\n          href = href.slice(1);\n        } else {\n          href = href.slice(1, -1);\n        }\n      }\n      return outputLink(cap, {\n        href: href ? href.replace(this.rules.inline.anyPunctuation, '$1') : href,\n        title: title ? title.replace(this.rules.inline.anyPunctuation, '$1') : title,\n      }, cap[0], this.lexer, this.rules);\n    }\n  }\n\n  reflink(src: string, links: Links): Tokens.Link | Tokens.Image | Tokens.Text | undefined {\n    let cap;\n    if ((cap = this.rules.inline.reflink.exec(src))\n      || (cap = this.rules.inline.nolink.exec(src))) {\n      const linkString = (cap[2] || cap[1]).replace(this.rules.other.multipleSpaceGlobal, ' ');\n      const link = links[linkString.toLowerCase()];\n      if (!link) {\n        const text = cap[0].charAt(0);\n        return {\n          type: 'text',\n          raw: text,\n          text,\n        };\n      }\n      return outputLink(cap, link, cap[0], this.lexer, this.rules);\n    }\n  }\n\n  emStrong(src: string, maskedSrc: string, prevChar = ''): Tokens.Em | Tokens.Strong | undefined {\n    let match = this.rules.inline.emStrongLDelim.exec(src);\n    if (!match) return;\n\n    // _ can't be between two alphanumerics. \\p{L}\\p{N} includes non-english alphabet/numbers as well\n    if (match[3] && prevChar.match(this.rules.other.unicodeAlphaNumeric)) return;\n\n    const nextChar = match[1] || match[2] || '';\n\n    if (!nextChar || !prevChar || this.rules.inline.punctuation.exec(prevChar)) {\n      // unicode Regex counts emoji as 1 char; spread into array for proper count (used multiple times below)\n      const lLength = [...match[0]].length - 1;\n      let rDelim, rLength, delimTotal = lLength, midDelimTotal = 0;\n\n      const endReg = match[0][0] === '*' ? this.rules.inline.emStrongRDelimAst : this.rules.inline.emStrongRDelimUnd;\n      endReg.lastIndex = 0;\n\n      // Clip maskedSrc to same section of string as src (move to lexer?)\n      maskedSrc = maskedSrc.slice(-1 * src.length + lLength);\n\n      while ((match = endReg.exec(maskedSrc)) != null) {\n        rDelim = match[1] || match[2] || match[3] || match[4] || match[5] || match[6];\n\n        if (!rDelim) continue; // skip single * in __abc*abc__\n\n        rLength = [...rDelim].length;\n\n        if (match[3] || match[4]) { // found another Left Delim\n          delimTotal += rLength;\n          continue;\n        } else if (match[5] || match[6]) { // either Left or Right Delim\n          if (lLength % 3 && !((lLength + rLength) % 3)) {\n            midDelimTotal += rLength;\n            continue; // CommonMark Emphasis Rules 9-10\n          }\n        }\n\n        delimTotal -= rLength;\n\n        if (delimTotal > 0) continue; // Haven't found enough closing delimiters\n\n        // Remove extra characters. *a*** -> *a*\n        rLength = Math.min(rLength, rLength + delimTotal + midDelimTotal);\n        // char length can be >1 for unicode characters;\n        const lastCharLength = [...match[0]][0].length;\n        const raw = src.slice(0, lLength + match.index + lastCharLength + rLength);\n\n        // Create `em` if smallest delimiter has odd char count. *a***\n        if (Math.min(lLength, rLength) % 2) {\n          const text = raw.slice(1, -1);\n          return {\n            type: 'em',\n            raw,\n            text,\n            tokens: this.lexer.inlineTokens(text),\n          };\n        }\n\n        // Create 'strong' if smallest delimiter has even char count. **a***\n        const text = raw.slice(2, -2);\n        return {\n          type: 'strong',\n          raw,\n          text,\n          tokens: this.lexer.inlineTokens(text),\n        };\n      }\n    }\n  }\n\n  codespan(src: string): Tokens.Codespan | undefined {\n    const cap = this.rules.inline.code.exec(src);\n    if (cap) {\n      let text = cap[2].replace(this.rules.other.newLineCharGlobal, ' ');\n      const hasNonSpaceChars = this.rules.other.nonSpaceChar.test(text);\n      const hasSpaceCharsOnBothEnds = this.rules.other.startingSpaceChar.test(text) && this.rules.other.endingSpaceChar.test(text);\n      if (hasNonSpaceChars && hasSpaceCharsOnBothEnds) {\n        text = text.substring(1, text.length - 1);\n      }\n      return {\n        type: 'codespan',\n        raw: cap[0],\n        text,\n      };\n    }\n  }\n\n  br(src: string): Tokens.Br | undefined {\n    const cap = this.rules.inline.br.exec(src);\n    if (cap) {\n      return {\n        type: 'br',\n        raw: cap[0],\n      };\n    }\n  }\n\n  del(src: string): Tokens.Del | undefined {\n    const cap = this.rules.inline.del.exec(src);\n    if (cap) {\n      return {\n        type: 'del',\n        raw: cap[0],\n        text: cap[2],\n        tokens: this.lexer.inlineTokens(cap[2]),\n      };\n    }\n  }\n\n  autolink(src: string): Tokens.Link | undefined {\n    const cap = this.rules.inline.autolink.exec(src);\n    if (cap) {\n      let text, href;\n      if (cap[2] === '@') {\n        text = cap[1];\n        href = 'mailto:' + text;\n      } else {\n        text = cap[1];\n        href = text;\n      }\n\n      return {\n        type: 'link',\n        raw: cap[0],\n        text,\n        href,\n        tokens: [\n          {\n            type: 'text',\n            raw: text,\n            text,\n          },\n        ],\n      };\n    }\n  }\n\n  url(src: string): Tokens.Link | undefined {\n    let cap;\n    if (cap = this.rules.inline.url.exec(src)) {\n      let text, href;\n      if (cap[2] === '@') {\n        text = cap[0];\n        href = 'mailto:' + text;\n      } else {\n        // do extended autolink path validation\n        let prevCapZero;\n        do {\n          prevCapZero = cap[0];\n          cap[0] = this.rules.inline._backpedal.exec(cap[0])?.[0] ?? '';\n        } while (prevCapZero !== cap[0]);\n        text = cap[0];\n        if (cap[1] === 'www.') {\n          href = 'http://' + cap[0];\n        } else {\n          href = cap[0];\n        }\n      }\n      return {\n        type: 'link',\n        raw: cap[0],\n        text,\n        href,\n        tokens: [\n          {\n            type: 'text',\n            raw: text,\n            text,\n          },\n        ],\n      };\n    }\n  }\n\n  inlineText(src: string): Tokens.Text | undefined {\n    const cap = this.rules.inline.text.exec(src);\n    if (cap) {\n      const escaped = this.lexer.state.inRawBlock;\n      return {\n        type: 'text',\n        raw: cap[0],\n        text: cap[0],\n        escaped,\n      };\n    }\n  }\n}\n","import { _Tokenizer } from './Tokenizer.ts';\nimport { _defaults } from './defaults.ts';\nimport { other, block, inline } from './rules.ts';\nimport type { Token, TokensList, Tokens } from './Tokens.ts';\nimport type { MarkedOptions } from './MarkedOptions.ts';\n\n/**\n * Block Lexer\n */\nexport class _Lexer {\n  tokens: TokensList;\n  options: MarkedOptions;\n  state: {\n    inLink: boolean;\n    inRawBlock: boolean;\n    top: boolean;\n  };\n\n  private tokenizer: _Tokenizer;\n  private inlineQueue: { src: string, tokens: Token[] }[];\n\n  constructor(options?: MarkedOptions) {\n    // TokenList cannot be created in one go\n    this.tokens = [] as unknown as TokensList;\n    this.tokens.links = Object.create(null);\n    this.options = options || _defaults;\n    this.options.tokenizer = this.options.tokenizer || new _Tokenizer();\n    this.tokenizer = this.options.tokenizer;\n    this.tokenizer.options = this.options;\n    this.tokenizer.lexer = this;\n    this.inlineQueue = [];\n    this.state = {\n      inLink: false,\n      inRawBlock: false,\n      top: true,\n    };\n\n    const rules = {\n      other,\n      block: block.normal,\n      inline: inline.normal,\n    };\n\n    if (this.options.pedantic) {\n      rules.block = block.pedantic;\n      rules.inline = inline.pedantic;\n    } else if (this.options.gfm) {\n      rules.block = block.gfm;\n      if (this.options.breaks) {\n        rules.inline = inline.breaks;\n      } else {\n        rules.inline = inline.gfm;\n      }\n    }\n    this.tokenizer.rules = rules;\n  }\n\n  /**\n   * Expose Rules\n   */\n  static get rules() {\n    return {\n      block,\n      inline,\n    };\n  }\n\n  /**\n   * Static Lex Method\n   */\n  static lex(src: string, options?: MarkedOptions) {\n    const lexer = new _Lexer(options);\n    return lexer.lex(src);\n  }\n\n  /**\n   * Static Lex Inline Method\n   */\n  static lexInline(src: string, options?: MarkedOptions) {\n    const lexer = new _Lexer(options);\n    return lexer.inlineTokens(src);\n  }\n\n  /**\n   * Preprocessing\n   */\n  lex(src: string) {\n    src = src.replace(other.carriageReturn, '\\n');\n\n    this.blockTokens(src, this.tokens);\n\n    for (let i = 0; i < this.inlineQueue.length; i++) {\n      const next = this.inlineQueue[i];\n      this.inlineTokens(next.src, next.tokens);\n    }\n    this.inlineQueue = [];\n\n    return this.tokens;\n  }\n\n  /**\n   * Lexing\n   */\n  blockTokens(src: string, tokens?: Token[], lastParagraphClipped?: boolean): Token[];\n  blockTokens(src: string, tokens?: TokensList, lastParagraphClipped?: boolean): TokensList;\n  blockTokens(src: string, tokens: Token[] = [], lastParagraphClipped = false) {\n    if (this.options.pedantic) {\n      src = src.replace(other.tabCharGlobal, '    ').replace(other.spaceLine, '');\n    }\n\n    while (src) {\n      let token: Tokens.Generic | undefined;\n\n      if (this.options.extensions?.block?.some((extTokenizer) => {\n        if (token = extTokenizer.call({ lexer: this }, src, tokens)) {\n          src = src.substring(token.raw.length);\n          tokens.push(token);\n          return true;\n        }\n        return false;\n      })) {\n        continue;\n      }\n\n      // newline\n      if (token = this.tokenizer.space(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (token.raw.length === 1 && lastToken !== undefined) {\n          // if there's a single \\n as a spacer, it's terminating the last line,\n          // so move it there so that we don't get unnecessary paragraph tags\n          lastToken.raw += '\\n';\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n\n      // code\n      if (token = this.tokenizer.code(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        // An indented code block cannot interrupt a paragraph.\n        if (lastToken?.type === 'paragraph' || lastToken?.type === 'text') {\n          lastToken.raw += '\\n' + token.raw;\n          lastToken.text += '\\n' + token.text;\n          this.inlineQueue.at(-1)!.src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n\n      // fences\n      if (token = this.tokenizer.fences(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // heading\n      if (token = this.tokenizer.heading(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // hr\n      if (token = this.tokenizer.hr(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // blockquote\n      if (token = this.tokenizer.blockquote(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // list\n      if (token = this.tokenizer.list(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // html\n      if (token = this.tokenizer.html(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // def\n      if (token = this.tokenizer.def(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === 'paragraph' || lastToken?.type === 'text') {\n          lastToken.raw += '\\n' + token.raw;\n          lastToken.text += '\\n' + token.raw;\n          this.inlineQueue.at(-1)!.src = lastToken.text;\n        } else if (!this.tokens.links[token.tag]) {\n          this.tokens.links[token.tag] = {\n            href: token.href,\n            title: token.title,\n          };\n        }\n        continue;\n      }\n\n      // table (gfm)\n      if (token = this.tokenizer.table(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // lheading\n      if (token = this.tokenizer.lheading(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // top-level paragraph\n      // prevent paragraph consuming extensions by clipping 'src' to extension start\n      let cutSrc = src;\n      if (this.options.extensions?.startBlock) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startBlock.forEach((getStartIndex) => {\n          tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n          if (typeof tempStart === 'number' && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if (this.state.top && (token = this.tokenizer.paragraph(cutSrc))) {\n        const lastToken = tokens.at(-1);\n        if (lastParagraphClipped && lastToken?.type === 'paragraph') {\n          lastToken.raw += '\\n' + token.raw;\n          lastToken.text += '\\n' + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue.at(-1)!.src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        lastParagraphClipped = cutSrc.length !== src.length;\n        src = src.substring(token.raw.length);\n        continue;\n      }\n\n      // text\n      if (token = this.tokenizer.text(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === 'text') {\n          lastToken.raw += '\\n' + token.raw;\n          lastToken.text += '\\n' + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue.at(-1)!.src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n\n      if (src) {\n        const errMsg = 'Infinite loop on byte: ' + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n\n    this.state.top = true;\n    return tokens;\n  }\n\n  inline(src: string, tokens: Token[] = []) {\n    this.inlineQueue.push({ src, tokens });\n    return tokens;\n  }\n\n  /**\n   * Lexing/Compiling\n   */\n  inlineTokens(src: string, tokens: Token[] = []): Token[] {\n    // String with links masked to avoid interference with em and strong\n    let maskedSrc = src;\n    let match: RegExpExecArray | null = null;\n\n    // Mask out reflinks\n    if (this.tokens.links) {\n      const links = Object.keys(this.tokens.links);\n      if (links.length > 0) {\n        while ((match = this.tokenizer.rules.inline.reflinkSearch.exec(maskedSrc)) != null) {\n          if (links.includes(match[0].slice(match[0].lastIndexOf('[') + 1, -1))) {\n            maskedSrc = maskedSrc.slice(0, match.index)\n              + '[' + 'a'.repeat(match[0].length - 2) + ']'\n              + maskedSrc.slice(this.tokenizer.rules.inline.reflinkSearch.lastIndex);\n          }\n        }\n      }\n    }\n\n    // Mask out escaped characters\n    while ((match = this.tokenizer.rules.inline.anyPunctuation.exec(maskedSrc)) != null) {\n      maskedSrc = maskedSrc.slice(0, match.index) + '++' + maskedSrc.slice(this.tokenizer.rules.inline.anyPunctuation.lastIndex);\n    }\n\n    // Mask out other blocks\n    while ((match = this.tokenizer.rules.inline.blockSkip.exec(maskedSrc)) != null) {\n      maskedSrc = maskedSrc.slice(0, match.index) + '[' + 'a'.repeat(match[0].length - 2) + ']' + maskedSrc.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);\n    }\n\n    let keepPrevChar = false;\n    let prevChar = '';\n    while (src) {\n      if (!keepPrevChar) {\n        prevChar = '';\n      }\n      keepPrevChar = false;\n\n      let token: Tokens.Generic | undefined;\n\n      // extensions\n      if (this.options.extensions?.inline?.some((extTokenizer) => {\n        if (token = extTokenizer.call({ lexer: this }, src, tokens)) {\n          src = src.substring(token.raw.length);\n          tokens.push(token);\n          return true;\n        }\n        return false;\n      })) {\n        continue;\n      }\n\n      // escape\n      if (token = this.tokenizer.escape(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // tag\n      if (token = this.tokenizer.tag(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // link\n      if (token = this.tokenizer.link(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // reflink, nolink\n      if (token = this.tokenizer.reflink(src, this.tokens.links)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (token.type === 'text' && lastToken?.type === 'text') {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n\n      // em & strong\n      if (token = this.tokenizer.emStrong(src, maskedSrc, prevChar)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // code\n      if (token = this.tokenizer.codespan(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // br\n      if (token = this.tokenizer.br(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // del (gfm)\n      if (token = this.tokenizer.del(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // autolink\n      if (token = this.tokenizer.autolink(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // url (gfm)\n      if (!this.state.inLink && (token = this.tokenizer.url(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // text\n      // prevent inlineText consuming extensions by clipping 'src' to extension start\n      let cutSrc = src;\n      if (this.options.extensions?.startInline) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startInline.forEach((getStartIndex) => {\n          tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n          if (typeof tempStart === 'number' && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if (token = this.tokenizer.inlineText(cutSrc)) {\n        src = src.substring(token.raw.length);\n        if (token.raw.slice(-1) !== '_') { // Track prevChar before string of ____ started\n          prevChar = token.raw.slice(-1);\n        }\n        keepPrevChar = true;\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === 'text') {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n\n      if (src) {\n        const errMsg = 'Infinite loop on byte: ' + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n\n    return tokens;\n  }\n}\n","import { _defaults } from './defaults.ts';\nimport {\n  cleanUrl,\n  escape,\n} from './helpers.ts';\nimport { other } from './rules.ts';\nimport type { MarkedOptions } from './MarkedOptions.ts';\nimport type { Tokens } from './Tokens.ts';\nimport type { _Parser } from './Parser.ts';\n\n/**\n * Renderer\n */\nexport class _Renderer {\n  options: MarkedOptions;\n  parser!: _Parser; // set by the parser\n  constructor(options?: MarkedOptions) {\n    this.options = options || _defaults;\n  }\n\n  space(token: Tokens.Space): string {\n    return '';\n  }\n\n  code({ text, lang, escaped }: Tokens.Code): string {\n    const langString = (lang || '').match(other.notSpaceStart)?.[0];\n\n    const code = text.replace(other.endingNewline, '') + '\\n';\n\n    if (!langString) {\n      return '<pre><code>'\n        + (escaped ? code : escape(code, true))\n        + '</code></pre>\\n';\n    }\n\n    return '<pre><code class=\"language-'\n      + escape(langString)\n      + '\">'\n      + (escaped ? code : escape(code, true))\n      + '</code></pre>\\n';\n  }\n\n  blockquote({ tokens }: Tokens.Blockquote): string {\n    const body = this.parser.parse(tokens);\n    return `<blockquote>\\n${body}</blockquote>\\n`;\n  }\n\n  html({ text }: Tokens.HTML | Tokens.Tag) : string {\n    return text;\n  }\n\n  heading({ tokens, depth }: Tokens.Heading): string {\n    return `<h${depth}>${this.parser.parseInline(tokens)}</h${depth}>\\n`;\n  }\n\n  hr(token: Tokens.Hr): string {\n    return '<hr>\\n';\n  }\n\n  list(token: Tokens.List): string {\n    const ordered = token.ordered;\n    const start = token.start;\n\n    let body = '';\n    for (let j = 0; j < token.items.length; j++) {\n      const item = token.items[j];\n      body += this.listitem(item);\n    }\n\n    const type = ordered ? 'ol' : 'ul';\n    const startAttr = (ordered && start !== 1) ? (' start=\"' + start + '\"') : '';\n    return '<' + type + startAttr + '>\\n' + body + '</' + type + '>\\n';\n  }\n\n  listitem(item: Tokens.ListItem): string {\n    let itemBody = '';\n    if (item.task) {\n      const checkbox = this.checkbox({ checked: !!item.checked });\n      if (item.loose) {\n        if (item.tokens[0]?.type === 'paragraph') {\n          item.tokens[0].text = checkbox + ' ' + item.tokens[0].text;\n          if (item.tokens[0].tokens && item.tokens[0].tokens.length > 0 && item.tokens[0].tokens[0].type === 'text') {\n            item.tokens[0].tokens[0].text = checkbox + ' ' + escape(item.tokens[0].tokens[0].text);\n            item.tokens[0].tokens[0].escaped = true;\n          }\n        } else {\n          item.tokens.unshift({\n            type: 'text',\n            raw: checkbox + ' ',\n            text: checkbox + ' ',\n            escaped: true,\n          });\n        }\n      } else {\n        itemBody += checkbox + ' ';\n      }\n    }\n\n    itemBody += this.parser.parse(item.tokens, !!item.loose);\n\n    return `<li>${itemBody}</li>\\n`;\n  }\n\n  checkbox({ checked }: Tokens.Checkbox): string {\n    return '<input '\n      + (checked ? 'checked=\"\" ' : '')\n      + 'disabled=\"\" type=\"checkbox\">';\n  }\n\n  paragraph({ tokens }: Tokens.Paragraph): string {\n    return `<p>${this.parser.parseInline(tokens)}</p>\\n`;\n  }\n\n  table(token: Tokens.Table): string {\n    let header = '';\n\n    // header\n    let cell = '';\n    for (let j = 0; j < token.header.length; j++) {\n      cell += this.tablecell(token.header[j]);\n    }\n    header += this.tablerow({ text: cell });\n\n    let body = '';\n    for (let j = 0; j < token.rows.length; j++) {\n      const row = token.rows[j];\n\n      cell = '';\n      for (let k = 0; k < row.length; k++) {\n        cell += this.tablecell(row[k]);\n      }\n\n      body += this.tablerow({ text: cell });\n    }\n    if (body) body = `<tbody>${body}</tbody>`;\n\n    return '<table>\\n'\n      + '<thead>\\n'\n      + header\n      + '</thead>\\n'\n      + body\n      + '</table>\\n';\n  }\n\n  tablerow({ text }: Tokens.TableRow): string {\n    return `<tr>\\n${text}</tr>\\n`;\n  }\n\n  tablecell(token: Tokens.TableCell): string {\n    const content = this.parser.parseInline(token.tokens);\n    const type = token.header ? 'th' : 'td';\n    const tag = token.align\n      ? `<${type} align=\"${token.align}\">`\n      : `<${type}>`;\n    return tag + content + `</${type}>\\n`;\n  }\n\n  /**\n   * span level renderer\n   */\n  strong({ tokens }: Tokens.Strong): string {\n    return `<strong>${this.parser.parseInline(tokens)}</strong>`;\n  }\n\n  em({ tokens }: Tokens.Em): string {\n    return `<em>${this.parser.parseInline(tokens)}</em>`;\n  }\n\n  codespan({ text }: Tokens.Codespan): string {\n    return `<code>${escape(text, true)}</code>`;\n  }\n\n  br(token: Tokens.Br): string {\n    return '<br>';\n  }\n\n  del({ tokens }: Tokens.Del): string {\n    return `<del>${this.parser.parseInline(tokens)}</del>`;\n  }\n\n  link({ href, title, tokens }: Tokens.Link): string {\n    const text = this.parser.parseInline(tokens);\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return text;\n    }\n    href = cleanHref;\n    let out = '<a href=\"' + href + '\"';\n    if (title) {\n      out += ' title=\"' + (escape(title)) + '\"';\n    }\n    out += '>' + text + '</a>';\n    return out;\n  }\n\n  image({ href, title, text, tokens }: Tokens.Image): string {\n    if (tokens) {\n      text = this.parser.parseInline(tokens, this.parser.textRenderer);\n    }\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return escape(text);\n    }\n    href = cleanHref;\n\n    let out = `<img src=\"${href}\" alt=\"${text}\"`;\n    if (title) {\n      out += ` title=\"${escape(title)}\"`;\n    }\n    out += '>';\n    return out;\n  }\n\n  text(token: Tokens.Text | Tokens.Escape) : string {\n    return 'tokens' in token && token.tokens\n      ? this.parser.parseInline(token.tokens)\n      : ('escaped' in token && token.escaped ? token.text : escape(token.text));\n  }\n}\n","import type { Tokens } from './Tokens.ts';\n\n/**\n * TextRenderer\n * returns only the textual part of the token\n */\nexport class _TextRenderer {\n  // no need for block level renderers\n  strong({ text }: Tokens.Strong) {\n    return text;\n  }\n\n  em({ text }: Tokens.Em) {\n    return text;\n  }\n\n  codespan({ text }: Tokens.Codespan) {\n    return text;\n  }\n\n  del({ text }: Tokens.Del) {\n    return text;\n  }\n\n  html({ text }: Tokens.HTML | Tokens.Tag) {\n    return text;\n  }\n\n  text({ text }: Tokens.Text | Tokens.Escape | Tokens.Tag) {\n    return text;\n  }\n\n  link({ text }: Tokens.Link) {\n    return '' + text;\n  }\n\n  image({ text }: Tokens.Image) {\n    return '' + text;\n  }\n\n  br() {\n    return '';\n  }\n}\n","import { _Renderer } from './Renderer.ts';\nimport { _TextRenderer } from './TextRenderer.ts';\nimport { _defaults } from './defaults.ts';\nimport type { MarkedToken, Token, Tokens } from './Tokens.ts';\nimport type { MarkedOptions } from './MarkedOptions.ts';\n\n/**\n * Parsing & Compiling\n */\nexport class _Parser {\n  options: MarkedOptions;\n  renderer: _Renderer;\n  textRenderer: _TextRenderer;\n  constructor(options?: MarkedOptions) {\n    this.options = options || _defaults;\n    this.options.renderer = this.options.renderer || new _Renderer();\n    this.renderer = this.options.renderer;\n    this.renderer.options = this.options;\n    this.renderer.parser = this;\n    this.textRenderer = new _TextRenderer();\n  }\n\n  /**\n   * Static Parse Method\n   */\n  static parse(tokens: Token[], options?: MarkedOptions) {\n    const parser = new _Parser(options);\n    return parser.parse(tokens);\n  }\n\n  /**\n   * Static Parse Inline Method\n   */\n  static parseInline(tokens: Token[], options?: MarkedOptions) {\n    const parser = new _Parser(options);\n    return parser.parseInline(tokens);\n  }\n\n  /**\n   * Parse Loop\n   */\n  parse(tokens: Token[], top = true): string {\n    let out = '';\n\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n\n      // Run any renderer extensions\n      if (this.options.extensions?.renderers?.[anyToken.type]) {\n        const genericToken = anyToken as Tokens.Generic;\n        const ret = this.options.extensions.renderers[genericToken.type].call({ parser: this }, genericToken);\n        if (ret !== false || !['space', 'hr', 'heading', 'code', 'table', 'blockquote', 'list', 'html', 'paragraph', 'text'].includes(genericToken.type)) {\n          out += ret || '';\n          continue;\n        }\n      }\n\n      const token = anyToken as MarkedToken;\n\n      switch (token.type) {\n        case 'space': {\n          out += this.renderer.space(token);\n          continue;\n        }\n        case 'hr': {\n          out += this.renderer.hr(token);\n          continue;\n        }\n        case 'heading': {\n          out += this.renderer.heading(token);\n          continue;\n        }\n        case 'code': {\n          out += this.renderer.code(token);\n          continue;\n        }\n        case 'table': {\n          out += this.renderer.table(token);\n          continue;\n        }\n        case 'blockquote': {\n          out += this.renderer.blockquote(token);\n          continue;\n        }\n        case 'list': {\n          out += this.renderer.list(token);\n          continue;\n        }\n        case 'html': {\n          out += this.renderer.html(token);\n          continue;\n        }\n        case 'paragraph': {\n          out += this.renderer.paragraph(token);\n          continue;\n        }\n        case 'text': {\n          let textToken = token;\n          let body = this.renderer.text(textToken);\n          while (i + 1 < tokens.length && tokens[i + 1].type === 'text') {\n            textToken = tokens[++i] as Tokens.Text;\n            body += '\\n' + this.renderer.text(textToken);\n          }\n          if (top) {\n            out += this.renderer.paragraph({\n              type: 'paragraph',\n              raw: body,\n              text: body,\n              tokens: [{ type: 'text', raw: body, text: body, escaped: true }],\n            });\n          } else {\n            out += body;\n          }\n          continue;\n        }\n\n        default: {\n          const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n          if (this.options.silent) {\n            console.error(errMsg);\n            return '';\n          } else {\n            throw new Error(errMsg);\n          }\n        }\n      }\n    }\n\n    return out;\n  }\n\n  /**\n   * Parse Inline Tokens\n   */\n  parseInline(tokens: Token[], renderer: _Renderer | _TextRenderer = this.renderer): string {\n    let out = '';\n\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n\n      // Run any renderer extensions\n      if (this.options.extensions?.renderers?.[anyToken.type]) {\n        const ret = this.options.extensions.renderers[anyToken.type].call({ parser: this }, anyToken);\n        if (ret !== false || !['escape', 'html', 'link', 'image', 'strong', 'em', 'codespan', 'br', 'del', 'text'].includes(anyToken.type)) {\n          out += ret || '';\n          continue;\n        }\n      }\n\n      const token = anyToken as MarkedToken;\n\n      switch (token.type) {\n        case 'escape': {\n          out += renderer.text(token);\n          break;\n        }\n        case 'html': {\n          out += renderer.html(token);\n          break;\n        }\n        case 'link': {\n          out += renderer.link(token);\n          break;\n        }\n        case 'image': {\n          out += renderer.image(token);\n          break;\n        }\n        case 'strong': {\n          out += renderer.strong(token);\n          break;\n        }\n        case 'em': {\n          out += renderer.em(token);\n          break;\n        }\n        case 'codespan': {\n          out += renderer.codespan(token);\n          break;\n        }\n        case 'br': {\n          out += renderer.br(token);\n          break;\n        }\n        case 'del': {\n          out += renderer.del(token);\n          break;\n        }\n        case 'text': {\n          out += renderer.text(token);\n          break;\n        }\n        default: {\n          const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n          if (this.options.silent) {\n            console.error(errMsg);\n            return '';\n          } else {\n            throw new Error(errMsg);\n          }\n        }\n      }\n    }\n    return out;\n  }\n}\n","import { _defaults } from './defaults.ts';\nimport { _Lexer } from './Lexer.ts';\nimport { _Parser } from './Parser.ts';\nimport type { MarkedOptions } from './MarkedOptions.ts';\nimport type { Token, TokensList } from './Tokens.ts';\n\nexport class _Hooks {\n  options: MarkedOptions;\n  block?: boolean;\n\n  constructor(options?: MarkedOptions) {\n    this.options = options || _defaults;\n  }\n\n  static passThroughHooks = new Set([\n    'preprocess',\n    'postprocess',\n    'processAllTokens',\n  ]);\n\n  /**\n   * Process markdown before marked\n   */\n  preprocess(markdown: string) {\n    return markdown;\n  }\n\n  /**\n   * Process HTML after marked is finished\n   */\n  postprocess(html: string) {\n    return html;\n  }\n\n  /**\n   * Process all tokens before walk tokens\n   */\n  processAllTokens(tokens: Token[] | TokensList) {\n    return tokens;\n  }\n\n  /**\n   * Provide function to tokenize markdown\n   */\n  provideLexer() {\n    return this.block ? _Lexer.lex : _Lexer.lexInline;\n  }\n\n  /**\n   * Provide function to parse tokens\n   */\n  provideParser() {\n    return this.block ? _Parser.parse : _Parser.parseInline;\n  }\n}\n","import { _getDefaults } from './defaults.ts';\nimport { _Lexer } from './Lexer.ts';\nimport { _Parser } from './Parser.ts';\nimport { _Hooks } from './Hooks.ts';\nimport { _Renderer } from './Renderer.ts';\nimport { _Tokenizer } from './Tokenizer.ts';\nimport { _TextRenderer } from './TextRenderer.ts';\nimport { escape } from './helpers.ts';\nimport type { MarkedExtension, MarkedOptions } from './MarkedOptions.ts';\nimport type { Token, Tokens, TokensList } from './Tokens.ts';\n\nexport type MaybePromise = void | Promise<void>;\n\ntype UnknownFunction = (...args: unknown[]) => unknown;\ntype GenericRendererFunction = (...args: unknown[]) => string | false;\n\nexport class Marked {\n  defaults = _getDefaults();\n  options = this.setOptions;\n\n  parse = this.parseMarkdown(true);\n  parseInline = this.parseMarkdown(false);\n\n  Parser = _Parser;\n  Renderer = _Renderer;\n  TextRenderer = _TextRenderer;\n  Lexer = _Lexer;\n  Tokenizer = _Tokenizer;\n  Hooks = _Hooks;\n\n  constructor(...args: MarkedExtension[]) {\n    this.use(...args);\n  }\n\n  /**\n   * Run callback for every token\n   */\n  walkTokens(tokens: Token[] | TokensList, callback: (token: Token) => MaybePromise | MaybePromise[]) {\n    let values: MaybePromise[] = [];\n    for (const token of tokens) {\n      values = values.concat(callback.call(this, token));\n      switch (token.type) {\n        case 'table': {\n          const tableToken = token as Tokens.Table;\n          for (const cell of tableToken.header) {\n            values = values.concat(this.walkTokens(cell.tokens, callback));\n          }\n          for (const row of tableToken.rows) {\n            for (const cell of row) {\n              values = values.concat(this.walkTokens(cell.tokens, callback));\n            }\n          }\n          break;\n        }\n        case 'list': {\n          const listToken = token as Tokens.List;\n          values = values.concat(this.walkTokens(listToken.items, callback));\n          break;\n        }\n        default: {\n          const genericToken = token as Tokens.Generic;\n          if (this.defaults.extensions?.childTokens?.[genericToken.type]) {\n            this.defaults.extensions.childTokens[genericToken.type].forEach((childTokens) => {\n              const tokens = genericToken[childTokens].flat(Infinity) as Token[] | TokensList;\n              values = values.concat(this.walkTokens(tokens, callback));\n            });\n          } else if (genericToken.tokens) {\n            values = values.concat(this.walkTokens(genericToken.tokens, callback));\n          }\n        }\n      }\n    }\n    return values;\n  }\n\n  use(...args: MarkedExtension[]) {\n    const extensions: MarkedOptions['extensions'] = this.defaults.extensions || { renderers: {}, childTokens: {} };\n\n    args.forEach((pack) => {\n      // copy options to new object\n      const opts = { ...pack } as MarkedOptions;\n\n      // set async to true if it was set to true before\n      opts.async = this.defaults.async || opts.async || false;\n\n      // ==-- Parse \"addon\" extensions --== //\n      if (pack.extensions) {\n        pack.extensions.forEach((ext) => {\n          if (!ext.name) {\n            throw new Error('extension name required');\n          }\n          if ('renderer' in ext) { // Renderer extensions\n            const prevRenderer = extensions.renderers[ext.name];\n            if (prevRenderer) {\n              // Replace extension with func to run new extension but fall back if false\n              extensions.renderers[ext.name] = function(...args) {\n                let ret = ext.renderer.apply(this, args);\n                if (ret === false) {\n                  ret = prevRenderer.apply(this, args);\n                }\n                return ret;\n              };\n            } else {\n              extensions.renderers[ext.name] = ext.renderer;\n            }\n          }\n          if ('tokenizer' in ext) { // Tokenizer Extensions\n            if (!ext.level || (ext.level !== 'block' && ext.level !== 'inline')) {\n              throw new Error(\"extension level must be 'block' or 'inline'\");\n            }\n            const extLevel = extensions[ext.level];\n            if (extLevel) {\n              extLevel.unshift(ext.tokenizer);\n            } else {\n              extensions[ext.level] = [ext.tokenizer];\n            }\n            if (ext.start) { // Function to check for start of token\n              if (ext.level === 'block') {\n                if (extensions.startBlock) {\n                  extensions.startBlock.push(ext.start);\n                } else {\n                  extensions.startBlock = [ext.start];\n                }\n              } else if (ext.level === 'inline') {\n                if (extensions.startInline) {\n                  extensions.startInline.push(ext.start);\n                } else {\n                  extensions.startInline = [ext.start];\n                }\n              }\n            }\n          }\n          if ('childTokens' in ext && ext.childTokens) { // Child tokens to be visited by walkTokens\n            extensions.childTokens[ext.name] = ext.childTokens;\n          }\n        });\n        opts.extensions = extensions;\n      }\n\n      // ==-- Parse \"overwrite\" extensions --== //\n      if (pack.renderer) {\n        const renderer = this.defaults.renderer || new _Renderer(this.defaults);\n        for (const prop in pack.renderer) {\n          if (!(prop in renderer)) {\n            throw new Error(`renderer '${prop}' does not exist`);\n          }\n          if (['options', 'parser'].includes(prop)) {\n            // ignore options property\n            continue;\n          }\n          const rendererProp = prop as Exclude<keyof _Renderer, 'options' | 'parser'>;\n          const rendererFunc = pack.renderer[rendererProp] as GenericRendererFunction;\n          const prevRenderer = renderer[rendererProp] as GenericRendererFunction;\n          // Replace renderer with func to run extension, but fall back if false\n          renderer[rendererProp] = (...args: unknown[]) => {\n            let ret = rendererFunc.apply(renderer, args);\n            if (ret === false) {\n              ret = prevRenderer.apply(renderer, args);\n            }\n            return ret || '';\n          };\n        }\n        opts.renderer = renderer;\n      }\n      if (pack.tokenizer) {\n        const tokenizer = this.defaults.tokenizer || new _Tokenizer(this.defaults);\n        for (const prop in pack.tokenizer) {\n          if (!(prop in tokenizer)) {\n            throw new Error(`tokenizer '${prop}' does not exist`);\n          }\n          if (['options', 'rules', 'lexer'].includes(prop)) {\n            // ignore options, rules, and lexer properties\n            continue;\n          }\n          const tokenizerProp = prop as Exclude<keyof _Tokenizer, 'options' | 'rules' | 'lexer'>;\n          const tokenizerFunc = pack.tokenizer[tokenizerProp] as UnknownFunction;\n          const prevTokenizer = tokenizer[tokenizerProp] as UnknownFunction;\n          // Replace tokenizer with func to run extension, but fall back if false\n          // @ts-expect-error cannot type tokenizer function dynamically\n          tokenizer[tokenizerProp] = (...args: unknown[]) => {\n            let ret = tokenizerFunc.apply(tokenizer, args);\n            if (ret === false) {\n              ret = prevTokenizer.apply(tokenizer, args);\n            }\n            return ret;\n          };\n        }\n        opts.tokenizer = tokenizer;\n      }\n\n      // ==-- Parse Hooks extensions --== //\n      if (pack.hooks) {\n        const hooks = this.defaults.hooks || new _Hooks();\n        for (const prop in pack.hooks) {\n          if (!(prop in hooks)) {\n            throw new Error(`hook '${prop}' does not exist`);\n          }\n          if (['options', 'block'].includes(prop)) {\n            // ignore options and block properties\n            continue;\n          }\n          const hooksProp = prop as Exclude<keyof _Hooks, 'options' | 'block'>;\n          const hooksFunc = pack.hooks[hooksProp] as UnknownFunction;\n          const prevHook = hooks[hooksProp] as UnknownFunction;\n          if (_Hooks.passThroughHooks.has(prop)) {\n            // @ts-expect-error cannot type hook function dynamically\n            hooks[hooksProp] = (arg: unknown) => {\n              if (this.defaults.async) {\n                return Promise.resolve(hooksFunc.call(hooks, arg)).then(ret => {\n                  return prevHook.call(hooks, ret);\n                });\n              }\n\n              const ret = hooksFunc.call(hooks, arg);\n              return prevHook.call(hooks, ret);\n            };\n          } else {\n            // @ts-expect-error cannot type hook function dynamically\n            hooks[hooksProp] = (...args: unknown[]) => {\n              let ret = hooksFunc.apply(hooks, args);\n              if (ret === false) {\n                ret = prevHook.apply(hooks, args);\n              }\n              return ret;\n            };\n          }\n        }\n        opts.hooks = hooks;\n      }\n\n      // ==-- Parse WalkTokens extensions --== //\n      if (pack.walkTokens) {\n        const walkTokens = this.defaults.walkTokens;\n        const packWalktokens = pack.walkTokens;\n        opts.walkTokens = function(token) {\n          let values: MaybePromise[] = [];\n          values.push(packWalktokens.call(this, token));\n          if (walkTokens) {\n            values = values.concat(walkTokens.call(this, token));\n          }\n          return values;\n        };\n      }\n\n      this.defaults = { ...this.defaults, ...opts };\n    });\n\n    return this;\n  }\n\n  setOptions(opt: MarkedOptions) {\n    this.defaults = { ...this.defaults, ...opt };\n    return this;\n  }\n\n  lexer(src: string, options?: MarkedOptions) {\n    return _Lexer.lex(src, options ?? this.defaults);\n  }\n\n  parser(tokens: Token[], options?: MarkedOptions) {\n    return _Parser.parse(tokens, options ?? this.defaults);\n  }\n\n  private parseMarkdown(blockType: boolean) {\n    type overloadedParse = {\n      (src: string, options: MarkedOptions & { async: true }): Promise<string>;\n      (src: string, options: MarkedOptions & { async: false }): string;\n      (src: string, options?: MarkedOptions | null): string | Promise<string>;\n    };\n\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    const parse: overloadedParse = (src: string, options?: MarkedOptions | null): any => {\n      const origOpt = { ...options };\n      const opt = { ...this.defaults, ...origOpt };\n\n      const throwError = this.onError(!!opt.silent, !!opt.async);\n\n      // throw error if an extension set async to true but parse was called with async: false\n      if (this.defaults.async === true && origOpt.async === false) {\n        return throwError(new Error('marked(): The async option was set to true by an extension. Remove async: false from the parse options object to return a Promise.'));\n      }\n\n      // throw error in case of non string input\n      if (typeof src === 'undefined' || src === null) {\n        return throwError(new Error('marked(): input parameter is undefined or null'));\n      }\n      if (typeof src !== 'string') {\n        return throwError(new Error('marked(): input parameter is of type '\n          + Object.prototype.toString.call(src) + ', string expected'));\n      }\n\n      if (opt.hooks) {\n        opt.hooks.options = opt;\n        opt.hooks.block = blockType;\n      }\n\n      const lexer = opt.hooks ? opt.hooks.provideLexer() : (blockType ? _Lexer.lex : _Lexer.lexInline);\n      const parser = opt.hooks ? opt.hooks.provideParser() : (blockType ? _Parser.parse : _Parser.parseInline);\n\n      if (opt.async) {\n        return Promise.resolve(opt.hooks ? opt.hooks.preprocess(src) : src)\n          .then(src => lexer(src, opt))\n          .then(tokens => opt.hooks ? opt.hooks.processAllTokens(tokens) : tokens)\n          .then(tokens => opt.walkTokens ? Promise.all(this.walkTokens(tokens, opt.walkTokens)).then(() => tokens) : tokens)\n          .then(tokens => parser(tokens, opt))\n          .then(html => opt.hooks ? opt.hooks.postprocess(html) : html)\n          .catch(throwError);\n      }\n\n      try {\n        if (opt.hooks) {\n          src = opt.hooks.preprocess(src) as string;\n        }\n        let tokens = lexer(src, opt);\n        if (opt.hooks) {\n          tokens = opt.hooks.processAllTokens(tokens);\n        }\n        if (opt.walkTokens) {\n          this.walkTokens(tokens, opt.walkTokens);\n        }\n        let html = parser(tokens, opt);\n        if (opt.hooks) {\n          html = opt.hooks.postprocess(html) as string;\n        }\n        return html;\n      } catch (e) {\n        return throwError(e as Error);\n      }\n    };\n\n    return parse;\n  }\n\n  private onError(silent: boolean, async: boolean) {\n    return (e: Error): string | Promise<string> => {\n      e.message += '\\nPlease report this to https://github.com/markedjs/marked.';\n\n      if (silent) {\n        const msg = '<p>An error occurred:</p><pre>'\n          + escape(e.message + '', true)\n          + '</pre>';\n        if (async) {\n          return Promise.resolve(msg);\n        }\n        return msg;\n      }\n\n      if (async) {\n        return Promise.reject(e);\n      }\n      throw e;\n    };\n  }\n}\n","import { _Lexer } from './Lexer.ts';\nimport { _Parser } from './Parser.ts';\nimport { _Tokenizer } from './Tokenizer.ts';\nimport { _Renderer } from './Renderer.ts';\nimport { _TextRenderer } from './TextRenderer.ts';\nimport { _Hooks } from './Hooks.ts';\nimport { Marked } from './Instance.ts';\nimport {\n  _getDefaults,\n  changeDefaults,\n  _defaults,\n} from './defaults.ts';\nimport type { MarkedExtension, MarkedOptions } from './MarkedOptions.ts';\nimport type { Token, TokensList } from './Tokens.ts';\nimport type { MaybePromise } from './Instance.ts';\n\nconst markedInstance = new Marked();\n\n/**\n * Compiles markdown to HTML asynchronously.\n *\n * @param src String of markdown source to be compiled\n * @param options Hash of options, having async: true\n * @return Promise of string of compiled HTML\n */\nexport function marked(src: string, options: MarkedOptions & { async: true }): Promise<string>;\n\n/**\n * Compiles markdown to HTML.\n *\n * @param src String of markdown source to be compiled\n * @param options Optional hash of options\n * @return String of compiled HTML. Will be a Promise of string if async is set to true by any extensions.\n */\nexport function marked(src: string, options: MarkedOptions & { async: false }): string;\nexport function marked(src: string, options: MarkedOptions & { async: true }): Promise<string>;\nexport function marked(src: string, options?: MarkedOptions | null): string | Promise<string>;\nexport function marked(src: string, opt?: MarkedOptions | null): string | Promise<string> {\n  return markedInstance.parse(src, opt);\n}\n\n/**\n * Sets the default options.\n *\n * @param options Hash of options\n */\nmarked.options =\nmarked.setOptions = function(options: MarkedOptions) {\n  markedInstance.setOptions(options);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\n\n/**\n * Gets the original marked default options.\n */\nmarked.getDefaults = _getDefaults;\n\nmarked.defaults = _defaults;\n\n/**\n * Use Extension\n */\n\nmarked.use = function(...args: MarkedExtension[]) {\n  markedInstance.use(...args);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\n\n/**\n * Run callback for every token\n */\n\nmarked.walkTokens = function(tokens: Token[] | TokensList, callback: (token: Token) => MaybePromise | MaybePromise[]) {\n  return markedInstance.walkTokens(tokens, callback);\n};\n\n/**\n * Compiles markdown to HTML without enclosing `p` tag.\n *\n * @param src String of markdown source to be compiled\n * @param options Hash of options\n * @return String of compiled HTML\n */\nmarked.parseInline = markedInstance.parseInline;\n\n/**\n * Expose\n */\nmarked.Parser = _Parser;\nmarked.parser = _Parser.parse;\nmarked.Renderer = _Renderer;\nmarked.TextRenderer = _TextRenderer;\nmarked.Lexer = _Lexer;\nmarked.lexer = _Lexer.lex;\nmarked.Tokenizer = _Tokenizer;\nmarked.Hooks = _Hooks;\nmarked.parse = marked;\n\nexport const options = marked.options;\nexport const setOptions = marked.setOptions;\nexport const use = marked.use;\nexport const walkTokens = marked.walkTokens;\nexport const parseInline = marked.parseInline;\nexport const parse = marked;\nexport const parser = _Parser.parse;\nexport const lexer = _Lexer.lex;\nexport { _defaults as defaults, _getDefaults as getDefaults } from './defaults.ts';\nexport { _Lexer as Lexer } from './Lexer.ts';\nexport { _Parser as Parser } from './Parser.ts';\nexport { _Tokenizer as Tokenizer } from './Tokenizer.ts';\nexport { _Renderer as Renderer } from './Renderer.ts';\nexport { _TextRenderer as TextRenderer } from './TextRenderer.ts';\nexport { _Hooks as Hooks } from './Hooks.ts';\nexport { Marked } from './Instance.ts';\nexport type * from './MarkedOptions.ts';\nexport type * from './Tokens.ts';\n"],"mappings":";;;;;;;;;;;;AAKO,SAASA,aAAA,EAA8B;EAC5C,OAAO;IACLC,KAAA,EAAO;IACPC,MAAA,EAAQ;IACRC,UAAA,EAAY;IACZC,GAAA,EAAK;IACLC,KAAA,EAAO;IACPC,QAAA,EAAU;IACVC,QAAA,EAAU;IACVC,MAAA,EAAQ;IACRC,SAAA,EAAW;IACXC,UAAA,EAAY;EACd;AACF;AAEO,IAAIC,SAAA,GAAYX,YAAA,CAAa;AAE7B,SAASY,eAAeC,WAAA,EAA4B;EACzDF,SAAA,GAAYE,WAAA;AACd;;;ACxBA,IAAMC,QAAA,GAAW;EAAEC,IAAA,EAAMA,CAAA,KAAM;AAAK;AAEpC,SAASC,KAAKC,KAAA,EAAwBC,GAAA,GAAM,IAAI;EAC9C,IAAIC,MAAA,GAAS,OAAOF,KAAA,KAAU,WAAWA,KAAA,GAAQA,KAAA,CAAME,MAAA;EACvD,MAAMC,GAAA,GAAM;IACVC,OAAA,EAASA,CAACC,IAAA,EAAuBC,GAAA,KAAyB;MACxD,IAAIC,SAAA,GAAY,OAAOD,GAAA,KAAQ,WAAWA,GAAA,GAAMA,GAAA,CAAIJ,MAAA;MACpDK,SAAA,GAAYA,SAAA,CAAUH,OAAA,CAAQI,KAAA,CAAMC,KAAA,EAAO,IAAI;MAC/CP,MAAA,GAASA,MAAA,CAAOE,OAAA,CAAQC,IAAA,EAAME,SAAS;MACvC,OAAOJ,GAAA;IACT;IACAO,QAAA,EAAUA,CAAA,KAAM;MACd,OAAO,IAAIC,MAAA,CAAOT,MAAA,EAAQD,GAAG;IAC/B;EACF;EACA,OAAOE,GAAA;AACT;AAEO,IAAMK,KAAA,GAAQ;EACnBI,gBAAA,EAAkB;EAClBC,iBAAA,EAAmB;EACnBC,sBAAA,EAAwB;EACxBC,cAAA,EAAgB;EAChBC,UAAA,EAAY;EACZC,iBAAA,EAAmB;EACnBC,eAAA,EAAiB;EACjBC,YAAA,EAAc;EACdC,iBAAA,EAAmB;EACnBC,aAAA,EAAe;EACfC,mBAAA,EAAqB;EACrBC,SAAA,EAAW;EACXC,eAAA,EAAiB;EACjBC,eAAA,EAAiB;EACjBC,uBAAA,EAAyB;EACzBC,wBAAA,EAA0B;EAC1BC,eAAA,EAAiB;EACjBC,kBAAA,EAAoB;EACpBC,UAAA,EAAY;EACZC,eAAA,EAAiB;EACjBC,OAAA,EAAS;EACTC,YAAA,EAAc;EACdC,cAAA,EAAgB;EAChBC,eAAA,EAAiB;EACjBC,iBAAA,EAAmB;EACnBC,eAAA,EAAiB;EACjBC,gBAAA,EAAkB;EAClBC,cAAA,EAAgB;EAChBC,SAAA,EAAW;EACXC,OAAA,EAAS;EACTC,iBAAA,EAAmB;EACnBC,eAAA,EAAiB;EACjBC,iBAAA,EAAmB;EACnBC,eAAA,EAAiB;EACjBC,iBAAA,EAAmB;EACnBC,mBAAA,EAAqB;EACrBC,UAAA,EAAY;EACZC,aAAA,EAAe;EACfC,kBAAA,EAAoB;EACpBC,qBAAA,EAAuB;EACvBC,YAAA,EAAc;EACd3C,KAAA,EAAO;EACP4C,aAAA,EAAe;EACfC,QAAA,EAAU;EACVC,SAAA,EAAW;EACXC,SAAA,EAAW;EACXC,cAAA,EAAgB;EAChBC,SAAA,EAAW;EACXC,aAAA,EAAe;EACfC,aAAA,EAAe;EACfC,aAAA,EAAgBC,IAAA,IAAiB,IAAInD,MAAA,CAAO,WAAWmD,IAAI,8BAA+B;EAC1FC,eAAA,EAAkBC,MAAA,IAAmB,IAAIrD,MAAA,CAAO,QAAQsD,IAAA,CAAKC,GAAA,CAAI,GAAGF,MAAA,GAAS,CAAC,CAAC,oDAAqD;EACpIG,OAAA,EAAUH,MAAA,IAAmB,IAAIrD,MAAA,CAAO,QAAQsD,IAAA,CAAKC,GAAA,CAAI,GAAGF,MAAA,GAAS,CAAC,CAAC,oDAAoD;EAC3HI,gBAAA,EAAmBJ,MAAA,IAAmB,IAAIrD,MAAA,CAAO,QAAQsD,IAAA,CAAKC,GAAA,CAAI,GAAGF,MAAA,GAAS,CAAC,CAAC,iBAAiB;EACjGK,iBAAA,EAAoBL,MAAA,IAAmB,IAAIrD,MAAA,CAAO,QAAQsD,IAAA,CAAKC,GAAA,CAAI,GAAGF,MAAA,GAAS,CAAC,CAAC,IAAI;EACrFM,cAAA,EAAiBN,MAAA,IAAmB,IAAIrD,MAAA,CAAO,QAAQsD,IAAA,CAAKC,GAAA,CAAI,GAAGF,MAAA,GAAS,CAAC,CAAC,sBAAsB,GAAG;AACzG;AAMA,IAAMO,OAAA,GAAU;AAChB,IAAMC,SAAA,GAAY;AAClB,IAAMC,MAAA,GAAS;AACf,IAAMC,EAAA,GAAK;AACX,IAAMC,OAAA,GAAU;AAChB,IAAMC,MAAA,GAAS;AACf,IAAMC,YAAA,GAAe;AACrB,IAAMC,QAAA,GAAW/E,IAAA,CAAK8E,YAAY,EAC/BzE,OAAA,CAAQ,SAASwE,MAAM,EACvBxE,OAAA,CAAQ,cAAc,mBAAmB,EACzCA,OAAA,CAAQ,WAAW,uBAAuB,EAC1CA,OAAA,CAAQ,eAAe,SAAS,EAChCA,OAAA,CAAQ,YAAY,cAAc,EAClCA,OAAA,CAAQ,SAAS,mBAAmB,EACpCA,OAAA,CAAQ,YAAY,EAAE,EACtBM,QAAA,CAAS;AACZ,IAAMqE,WAAA,GAAchF,IAAA,CAAK8E,YAAY,EAClCzE,OAAA,CAAQ,SAASwE,MAAM,EACvBxE,OAAA,CAAQ,cAAc,mBAAmB,EACzCA,OAAA,CAAQ,WAAW,uBAAuB,EAC1CA,OAAA,CAAQ,eAAe,SAAS,EAChCA,OAAA,CAAQ,YAAY,cAAc,EAClCA,OAAA,CAAQ,SAAS,mBAAmB,EACpCA,OAAA,CAAQ,UAAU,mCAAmC,EACrDM,QAAA,CAAS;AACZ,IAAMsE,UAAA,GAAa;AACnB,IAAMC,SAAA,GAAY;AAClB,IAAMC,WAAA,GAAc;AACpB,IAAMC,GAAA,GAAMpF,IAAA,CAAK,6GAA6G,EAC3HK,OAAA,CAAQ,SAAS8E,WAAW,EAC5B9E,OAAA,CAAQ,SAAS,8DAA8D,EAC/EM,QAAA,CAAS;AAEZ,IAAM0E,IAAA,GAAOrF,IAAA,CAAK,sCAAsC,EACrDK,OAAA,CAAQ,SAASwE,MAAM,EACvBlE,QAAA,CAAS;AAEZ,IAAM2E,IAAA,GAAO;AAMb,IAAMC,QAAA,GAAW;AACjB,IAAMC,IAAA,GAAOxF,IAAA,CACX,6dASK,GAAG,EACPK,OAAA,CAAQ,WAAWkF,QAAQ,EAC3BlF,OAAA,CAAQ,OAAOiF,IAAI,EACnBjF,OAAA,CAAQ,aAAa,0EAA0E,EAC/FM,QAAA,CAAS;AAEZ,IAAM8E,SAAA,GAAYzF,IAAA,CAAKiF,UAAU,EAC9B5E,OAAA,CAAQ,MAAMsE,EAAE,EAChBtE,OAAA,CAAQ,WAAW,uBAAuB,EAC1CA,OAAA,CAAQ,aAAa,EAAE,EACvBA,OAAA,CAAQ,UAAU,EAAE,EACpBA,OAAA,CAAQ,cAAc,SAAS,EAC/BA,OAAA,CAAQ,UAAU,gDAAgD,EAClEA,OAAA,CAAQ,QAAQ,wBAAwB,EACxCA,OAAA,CAAQ,QAAQ,6DAA6D,EAC7EA,OAAA,CAAQ,OAAOiF,IAAI,EACnB3E,QAAA,CAAS;AAEZ,IAAM+E,UAAA,GAAa1F,IAAA,CAAK,yCAAyC,EAC9DK,OAAA,CAAQ,aAAaoF,SAAS,EAC9B9E,QAAA,CAAS;AAMZ,IAAMgF,WAAA,GAAc;EAClBD,UAAA;EACAE,IAAA,EAAMnB,SAAA;EACNW,GAAA;EACAV,MAAA;EACAE,OAAA;EACAD,EAAA;EACAa,IAAA;EACAT,QAAA;EACAM,IAAA;EACAb,OAAA;EACAiB,SAAA;EACAI,KAAA,EAAO/F,QAAA;EACPgG,IAAA,EAAMZ;AACR;AAQA,IAAMa,QAAA,GAAW/F,IAAA,CACf,6JAEsF,EACrFK,OAAA,CAAQ,MAAMsE,EAAE,EAChBtE,OAAA,CAAQ,WAAW,uBAAuB,EAC1CA,OAAA,CAAQ,cAAc,SAAS,EAC/BA,OAAA,CAAQ,QAAQ,wBAAyB,EACzCA,OAAA,CAAQ,UAAU,gDAAgD,EAClEA,OAAA,CAAQ,QAAQ,wBAAwB,EACxCA,OAAA,CAAQ,QAAQ,6DAA6D,EAC7EA,OAAA,CAAQ,OAAOiF,IAAI,EACnB3E,QAAA,CAAS;AAEZ,IAAMqF,QAAA,GAAsC;EAC1C,GAAGL,WAAA;EACHZ,QAAA,EAAUC,WAAA;EACVa,KAAA,EAAOE,QAAA;EACPN,SAAA,EAAWzF,IAAA,CAAKiF,UAAU,EACvB5E,OAAA,CAAQ,MAAMsE,EAAE,EAChBtE,OAAA,CAAQ,WAAW,uBAAuB,EAC1CA,OAAA,CAAQ,aAAa,EAAE,EACvBA,OAAA,CAAQ,SAAS0F,QAAQ,EACzB1F,OAAA,CAAQ,cAAc,SAAS,EAC/BA,OAAA,CAAQ,UAAU,gDAAgD,EAClEA,OAAA,CAAQ,QAAQ,wBAAwB,EACxCA,OAAA,CAAQ,QAAQ,6DAA6D,EAC7EA,OAAA,CAAQ,OAAOiF,IAAI,EACnB3E,QAAA,CAAS;AACd;AAMA,IAAMsF,aAAA,GAA2C;EAC/C,GAAGN,WAAA;EACHH,IAAA,EAAMxF,IAAA,CACJ,wIAEwE,EACvEK,OAAA,CAAQ,WAAWkF,QAAQ,EAC3BlF,OAAA,CAAQ,QAAQ,mKAGkB,EAClCM,QAAA,CAAS;EACZyE,GAAA,EAAK;EACLR,OAAA,EAAS;EACTF,MAAA,EAAQ5E,QAAA;EAAA;EACRiF,QAAA,EAAU;EACVU,SAAA,EAAWzF,IAAA,CAAKiF,UAAU,EACvB5E,OAAA,CAAQ,MAAMsE,EAAE,EAChBtE,OAAA,CAAQ,WAAW,iBAAiB,EACpCA,OAAA,CAAQ,YAAY0E,QAAQ,EAC5B1E,OAAA,CAAQ,UAAU,EAAE,EACpBA,OAAA,CAAQ,cAAc,SAAS,EAC/BA,OAAA,CAAQ,WAAW,EAAE,EACrBA,OAAA,CAAQ,SAAS,EAAE,EACnBA,OAAA,CAAQ,SAAS,EAAE,EACnBA,OAAA,CAAQ,QAAQ,EAAE,EAClBM,QAAA,CAAS;AACd;AAMA,IAAMuF,MAAA,GAAS;AACf,IAAMC,UAAA,GAAa;AACnB,IAAMC,EAAA,GAAK;AACX,IAAMC,UAAA,GAAa;AAGnB,IAAMC,YAAA,GAAe;AACrB,IAAMC,mBAAA,GAAsB;AAC5B,IAAMC,sBAAA,GAAyB;AAC/B,IAAMC,WAAA,GAAczG,IAAA,CAAK,yBAAyB,GAAG,EAClDK,OAAA,CAAQ,eAAekG,mBAAmB,EAAE5F,QAAA,CAAS;AAGxD,IAAM+F,uBAAA,GAA0B;AAChC,IAAMC,8BAAA,GAAiC;AACvC,IAAMC,iCAAA,GAAoC;AAG1C,IAAMC,SAAA,GAAY;AAElB,IAAMC,kBAAA,GAAqB;AAE3B,IAAMC,cAAA,GAAiB/G,IAAA,CAAK8G,kBAAA,EAAoB,GAAG,EAChDzG,OAAA,CAAQ,UAAUiG,YAAY,EAC9B3F,QAAA,CAAS;AAEZ,IAAMqG,iBAAA,GAAoBhH,IAAA,CAAK8G,kBAAA,EAAoB,GAAG,EACnDzG,OAAA,CAAQ,UAAUqG,uBAAuB,EACzC/F,QAAA,CAAS;AAEZ,IAAMsG,qBAAA,GACJ;AASF,IAAMC,iBAAA,GAAoBlH,IAAA,CAAKiH,qBAAA,EAAuB,IAAI,EACvD5G,OAAA,CAAQ,kBAAkBmG,sBAAsB,EAChDnG,OAAA,CAAQ,eAAekG,mBAAmB,EAC1ClG,OAAA,CAAQ,UAAUiG,YAAY,EAC9B3F,QAAA,CAAS;AAEZ,IAAMwG,oBAAA,GAAuBnH,IAAA,CAAKiH,qBAAA,EAAuB,IAAI,EAC1D5G,OAAA,CAAQ,kBAAkBuG,iCAAiC,EAC3DvG,OAAA,CAAQ,eAAesG,8BAA8B,EACrDtG,OAAA,CAAQ,UAAUqG,uBAAuB,EACzC/F,QAAA,CAAS;AAGZ,IAAMyG,iBAAA,GAAoBpH,IAAA,CACxB,oNAMiC,IAAI,EACpCK,OAAA,CAAQ,kBAAkBmG,sBAAsB,EAChDnG,OAAA,CAAQ,eAAekG,mBAAmB,EAC1ClG,OAAA,CAAQ,UAAUiG,YAAY,EAC9B3F,QAAA,CAAS;AAEZ,IAAM0G,cAAA,GAAiBrH,IAAA,CAAK,aAAa,IAAI,EAC1CK,OAAA,CAAQ,UAAUiG,YAAY,EAC9B3F,QAAA,CAAS;AAEZ,IAAM2G,QAAA,GAAWtH,IAAA,CAAK,qCAAqC,EACxDK,OAAA,CAAQ,UAAU,8BAA8B,EAChDA,OAAA,CAAQ,SAAS,8IAA8I,EAC/JM,QAAA,CAAS;AAEZ,IAAM4G,cAAA,GAAiBvH,IAAA,CAAKuF,QAAQ,EAAElF,OAAA,CAAQ,aAAa,KAAK,EAAEM,QAAA,CAAS;AAC3E,IAAM6G,GAAA,GAAMxH,IAAA,CACV,0JAKsC,EACrCK,OAAA,CAAQ,WAAWkH,cAAc,EACjClH,OAAA,CAAQ,aAAa,6EAA6E,EAClGM,QAAA,CAAS;AAEZ,IAAM8G,YAAA,GAAe;AAErB,IAAMC,IAAA,GAAO1H,IAAA,CAAK,mEAAmE,EAClFK,OAAA,CAAQ,SAASoH,YAAY,EAC7BpH,OAAA,CAAQ,QAAQ,yCAAyC,EACzDA,OAAA,CAAQ,SAAS,6DAA6D,EAC9EM,QAAA,CAAS;AAEZ,IAAMgH,OAAA,GAAU3H,IAAA,CAAK,yBAAyB,EAC3CK,OAAA,CAAQ,SAASoH,YAAY,EAC7BpH,OAAA,CAAQ,OAAO8E,WAAW,EAC1BxE,QAAA,CAAS;AAEZ,IAAMiH,MAAA,GAAS5H,IAAA,CAAK,uBAAuB,EACxCK,OAAA,CAAQ,OAAO8E,WAAW,EAC1BxE,QAAA,CAAS;AAEZ,IAAMkH,aAAA,GAAgB7H,IAAA,CAAK,yBAAyB,GAAG,EACpDK,OAAA,CAAQ,WAAWsH,OAAO,EAC1BtH,OAAA,CAAQ,UAAUuH,MAAM,EACxBjH,QAAA,CAAS;AAMZ,IAAMmH,YAAA,GAAe;EACnBC,UAAA,EAAYjI,QAAA;EAAA;EACZuH,cAAA;EACAC,QAAA;EACAT,SAAA;EACAT,EAAA;EACAR,IAAA,EAAMO,UAAA;EACN6B,GAAA,EAAKlI,QAAA;EACLiH,cAAA;EACAG,iBAAA;EACAE,iBAAA;EACAlB,MAAA;EACAwB,IAAA;EACAE,MAAA;EACAnB,WAAA;EACAkB,OAAA;EACAE,aAAA;EACAL,GAAA;EACA1B,IAAA,EAAMO,UAAA;EACN4B,GAAA,EAAKnI;AACP;AAQA,IAAMoI,cAAA,GAA6C;EACjD,GAAGJ,YAAA;EACHJ,IAAA,EAAM1H,IAAA,CAAK,yBAAyB,EACjCK,OAAA,CAAQ,SAASoH,YAAY,EAC7B9G,QAAA,CAAS;EACZgH,OAAA,EAAS3H,IAAA,CAAK,+BAA+B,EAC1CK,OAAA,CAAQ,SAASoH,YAAY,EAC7B9G,QAAA,CAAS;AACd;AAMA,IAAMwH,SAAA,GAAwC;EAC5C,GAAGL,YAAA;EACHZ,iBAAA,EAAmBC,oBAAA;EACnBJ,cAAA,EAAgBC,iBAAA;EAChBiB,GAAA,EAAKjI,IAAA,CAAK,oEAAoE,GAAG,EAC9EK,OAAA,CAAQ,SAAS,2EAA2E,EAC5FM,QAAA,CAAS;EACZoH,UAAA,EAAY;EACZC,GAAA,EAAK;EACLlC,IAAA,EAAM;AACR;AAMA,IAAMsC,YAAA,GAA2C;EAC/C,GAAGD,SAAA;EACH/B,EAAA,EAAIpG,IAAA,CAAKoG,EAAE,EAAE/F,OAAA,CAAQ,QAAQ,GAAG,EAAEM,QAAA,CAAS;EAC3CmF,IAAA,EAAM9F,IAAA,CAAKmI,SAAA,CAAUrC,IAAI,EACtBzF,OAAA,CAAQ,QAAQ,eAAe,EAC/BA,OAAA,CAAQ,WAAW,GAAG,EACtBM,QAAA,CAAS;AACd;AAMO,IAAM0H,KAAA,GAAQ;EACnBC,MAAA,EAAQ3C,WAAA;EACRvG,GAAA,EAAK4G,QAAA;EACL1G,QAAA,EAAU2G;AACZ;AAEO,IAAMsC,MAAA,GAAS;EACpBD,MAAA,EAAQR,YAAA;EACR1I,GAAA,EAAK+I,SAAA;EACLjJ,MAAA,EAAQkJ,YAAA;EACR9I,QAAA,EAAU4I;AACZ;;;ACzbA,IAAMM,kBAAA,GAAkD;EACtD,KAAK;EACL,KAAK;EACL,KAAK;EACL,KAAK;EACL,KAAK;AACP;AACA,IAAMC,oBAAA,GAAwBC,EAAA,IAAeF,kBAAA,CAAmBE,EAAE;AAE3D,SAASC,QAAOC,KAAA,EAAcC,MAAA,EAAkB;EACrD,IAAIA,MAAA,EAAQ;IACV,IAAIpI,KAAA,CAAMwC,UAAA,CAAW6F,IAAA,CAAKF,KAAI,GAAG;MAC/B,OAAOA,KAAA,CAAKvI,OAAA,CAAQI,KAAA,CAAMyC,aAAA,EAAeuF,oBAAoB;IAC/D;EACF,OAAO;IACL,IAAIhI,KAAA,CAAM0C,kBAAA,CAAmB2F,IAAA,CAAKF,KAAI,GAAG;MACvC,OAAOA,KAAA,CAAKvI,OAAA,CAAQI,KAAA,CAAM2C,qBAAA,EAAuBqF,oBAAoB;IACvE;EACF;EAEA,OAAOG,KAAA;AACT;AAgBO,SAASG,SAASC,IAAA,EAAc;EACrC,IAAI;IACFA,IAAA,GAAOC,SAAA,CAAUD,IAAI,EAAE3I,OAAA,CAAQI,KAAA,CAAM6C,aAAA,EAAe,GAAG;EACzD,QAAQ;IACN,OAAO;EACT;EACA,OAAO0F,IAAA;AACT;AAEO,SAASE,WAAWC,QAAA,EAAkBC,KAAA,EAAgB;EAG3D,MAAMC,GAAA,GAAMF,QAAA,CAAS9I,OAAA,CAAQI,KAAA,CAAM8C,QAAA,EAAU,CAAC+F,KAAA,EAAOC,MAAA,EAAQC,GAAA,KAAQ;MACjE,IAAIC,OAAA,GAAU;MACd,IAAIC,IAAA,GAAOH,MAAA;MACX,OAAO,EAAEG,IAAA,IAAQ,KAAKF,GAAA,CAAIE,IAAI,MAAM,MAAMD,OAAA,GAAU,CAACA,OAAA;MACrD,IAAIA,OAAA,EAAS;QAGX,OAAO;MACT,OAAO;QAEL,OAAO;MACT;IACF,CAAC;IACDE,KAAA,GAAQN,GAAA,CAAIO,KAAA,CAAMnJ,KAAA,CAAM+C,SAAS;EACnC,IAAIqG,CAAA,GAAI;EAGR,IAAI,CAACF,KAAA,CAAM,CAAC,EAAEG,IAAA,CAAK,GAAG;IACpBH,KAAA,CAAMI,KAAA,CAAM;EACd;EACA,IAAIJ,KAAA,CAAMK,MAAA,GAAS,KAAK,CAACL,KAAA,CAAMM,EAAA,CAAG,EAAE,GAAGH,IAAA,CAAK,GAAG;IAC7CH,KAAA,CAAMO,GAAA,CAAI;EACZ;EAEA,IAAId,KAAA,EAAO;IACT,IAAIO,KAAA,CAAMK,MAAA,GAASZ,KAAA,EAAO;MACxBO,KAAA,CAAMQ,MAAA,CAAOf,KAAK;IACpB,OAAO;MACL,OAAOO,KAAA,CAAMK,MAAA,GAASZ,KAAA,EAAOO,KAAA,CAAMS,IAAA,CAAK,EAAE;IAC5C;EACF;EAEA,OAAOP,CAAA,GAAIF,KAAA,CAAMK,MAAA,EAAQH,CAAA,IAAK;IAE5BF,KAAA,CAAME,CAAC,IAAIF,KAAA,CAAME,CAAC,EAAEC,IAAA,CAAK,EAAEzJ,OAAA,CAAQI,KAAA,CAAMgD,SAAA,EAAW,GAAG;EACzD;EACA,OAAOkG,KAAA;AACT;AAUO,SAASU,MAAMb,GAAA,EAAac,CAAA,EAAWC,MAAA,EAAkB;EAC9D,MAAMC,CAAA,GAAIhB,GAAA,CAAIQ,MAAA;EACd,IAAIQ,CAAA,KAAM,GAAG;IACX,OAAO;EACT;EAGA,IAAIC,OAAA,GAAU;EAGd,OAAOA,OAAA,GAAUD,CAAA,EAAG;IAClB,MAAME,QAAA,GAAWlB,GAAA,CAAImB,MAAA,CAAOH,CAAA,GAAIC,OAAA,GAAU,CAAC;IAC3C,IAAIC,QAAA,KAAaJ,CAAA,IAAK,CAACC,MAAA,EAAQ;MAC7BE,OAAA;IACF,WAAWC,QAAA,KAAaJ,CAAA,IAAKC,MAAA,EAAQ;MACnCE,OAAA;IACF,OAAO;MACL;IACF;EACF;EAEA,OAAOjB,GAAA,CAAIoB,KAAA,CAAM,GAAGJ,CAAA,GAAIC,OAAO;AACjC;AAEO,SAASI,mBAAmBrB,GAAA,EAAasB,CAAA,EAAW;EACzD,IAAItB,GAAA,CAAIuB,OAAA,CAAQD,CAAA,CAAE,CAAC,CAAC,MAAM,IAAI;IAC5B,OAAO;EACT;EAEA,IAAIE,KAAA,GAAQ;EACZ,SAASnB,CAAA,GAAI,GAAGA,CAAA,GAAIL,GAAA,CAAIQ,MAAA,EAAQH,CAAA,IAAK;IACnC,IAAIL,GAAA,CAAIK,CAAC,MAAM,MAAM;MACnBA,CAAA;IACF,WAAWL,GAAA,CAAIK,CAAC,MAAMiB,CAAA,CAAE,CAAC,GAAG;MAC1BE,KAAA;IACF,WAAWxB,GAAA,CAAIK,CAAC,MAAMiB,CAAA,CAAE,CAAC,GAAG;MAC1BE,KAAA;MACA,IAAIA,KAAA,GAAQ,GAAG;QACb,OAAOnB,CAAA;MACT;IACF;EACF;EACA,IAAImB,KAAA,GAAQ,GAAG;IACb,OAAO;EACT;EAEA,OAAO;AACT;;;ACzIA,SAASC,WAAWC,GAAA,EAAeC,KAAA,EAA2CC,GAAA,EAAaC,MAAA,EAAeC,KAAA,EAA0C;EAClJ,MAAMtC,IAAA,GAAOmC,KAAA,CAAKnC,IAAA;EAClB,MAAMuC,KAAA,GAAQJ,KAAA,CAAKI,KAAA,IAAS;EAC5B,MAAMzF,IAAA,GAAOoF,GAAA,CAAI,CAAC,EAAE7K,OAAA,CAAQiL,KAAA,CAAM7K,KAAA,CAAMK,iBAAA,EAAmB,IAAI;EAE/DuK,MAAA,CAAMG,KAAA,CAAMC,MAAA,GAAS;EACrB,MAAMC,KAAA,GAAoC;IACxCC,IAAA,EAAMT,GAAA,CAAI,CAAC,EAAEP,MAAA,CAAO,CAAC,MAAM,MAAM,UAAU;IAC3CS,GAAA;IACApC,IAAA;IACAuC,KAAA;IACAzF,IAAA;IACA8F,MAAA,EAAQP,MAAA,CAAMQ,YAAA,CAAa/F,IAAI;EACjC;EACAuF,MAAA,CAAMG,KAAA,CAAMC,MAAA,GAAS;EACrB,OAAOC,KAAA;AACT;AAEA,SAAS3K,uBAAuBqK,GAAA,EAAatF,IAAA,EAAcwF,KAAA,EAAc;EACvE,MAAMQ,iBAAA,GAAoBV,GAAA,CAAI9B,KAAA,CAAMgC,KAAA,CAAM7K,KAAA,CAAMM,sBAAsB;EAEtE,IAAI+K,iBAAA,KAAsB,MAAM;IAC9B,OAAOhG,IAAA;EACT;EAEA,MAAMiG,YAAA,GAAeD,iBAAA,CAAkB,CAAC;EAExC,OAAOhG,IAAA,CACJ8D,KAAA,CAAM,IAAI,EACVoC,GAAA,CAAIC,IAAA,IAAQ;IACX,MAAMC,iBAAA,GAAoBD,IAAA,CAAK3C,KAAA,CAAMgC,KAAA,CAAM7K,KAAA,CAAMO,cAAc;IAC/D,IAAIkL,iBAAA,KAAsB,MAAM;MAC9B,OAAOD,IAAA;IACT;IAEA,MAAM,CAACE,YAAY,IAAID,iBAAA;IAEvB,IAAIC,YAAA,CAAanC,MAAA,IAAU+B,YAAA,CAAa/B,MAAA,EAAQ;MAC9C,OAAOiC,IAAA,CAAKrB,KAAA,CAAMmB,YAAA,CAAa/B,MAAM;IACvC;IAEA,OAAOiC,IAAA;EACT,CAAC,EACAG,IAAA,CAAK,IAAI;AACd;AAKO,IAAMC,UAAA,GAAN,MAAiB;EACtBC,OAAA;EACAhB,KAAA;EAAA;EACAiB,KAAA;EAAA;EAEAC,YAAYC,QAAA,EAAyB;IACnC,KAAKH,OAAA,GAAUG,QAAA,IAAW9M,SAAA;EAC5B;EAEA+M,MAAMC,GAAA,EAAuC;IAC3C,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAM7D,OAAA,CAAQzE,IAAA,CAAK4M,GAAG;IAC7C,IAAIzB,GAAA,IAAOA,GAAA,CAAI,CAAC,EAAElB,MAAA,GAAS,GAAG;MAC5B,OAAO;QACL2B,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;MACZ;IACF;EACF;EAEAtF,KAAK+G,GAAA,EAAsC;IACzC,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAMzC,IAAA,CAAK7F,IAAA,CAAK4M,GAAG;IAC1C,IAAIzB,GAAA,EAAK;MACP,MAAMpF,IAAA,GAAOoF,GAAA,CAAI,CAAC,EAAE7K,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMI,gBAAA,EAAkB,EAAE;MACjE,OAAO;QACL8K,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACV0B,cAAA,EAAgB;QAChB9G,IAAA,EAAM,CAAC,KAAKwG,OAAA,CAAQhN,QAAA,GAChB+K,KAAA,CAAMvE,IAAA,EAAM,IAAI,IAChBA;MACN;IACF;EACF;EAEApB,OAAOiI,GAAA,EAAsC;IAC3C,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAM3D,MAAA,CAAO3E,IAAA,CAAK4M,GAAG;IAC5C,IAAIzB,GAAA,EAAK;MACP,MAAME,GAAA,GAAMF,GAAA,CAAI,CAAC;MACjB,MAAMpF,IAAA,GAAO/E,sBAAA,CAAuBqK,GAAA,EAAKF,GAAA,CAAI,CAAC,KAAK,IAAI,KAAKI,KAAK;MAEjE,OAAO;QACLK,IAAA,EAAM;QACNP,GAAA;QACAyB,IAAA,EAAM3B,GAAA,CAAI,CAAC,IAAIA,GAAA,CAAI,CAAC,EAAEpB,IAAA,CAAK,EAAEzJ,OAAA,CAAQ,KAAKiL,KAAA,CAAM/C,MAAA,CAAOlB,cAAA,EAAgB,IAAI,IAAI6D,GAAA,CAAI,CAAC;QACpFpF;MACF;IACF;EACF;EAEAlB,QAAQ+H,GAAA,EAAyC;IAC/C,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAMzD,OAAA,CAAQ7E,IAAA,CAAK4M,GAAG;IAC7C,IAAIzB,GAAA,EAAK;MACP,IAAIpF,IAAA,GAAOoF,GAAA,CAAI,CAAC,EAAEpB,IAAA,CAAK;MAGvB,IAAI,KAAKwB,KAAA,CAAM7K,KAAA,CAAMQ,UAAA,CAAW6H,IAAA,CAAKhD,IAAI,GAAG;QAC1C,MAAMgH,OAAA,GAAUzC,KAAA,CAAMvE,IAAA,EAAM,GAAG;QAC/B,IAAI,KAAKwG,OAAA,CAAQhN,QAAA,EAAU;UACzBwG,IAAA,GAAOgH,OAAA,CAAQhD,IAAA,CAAK;QACtB,WAAW,CAACgD,OAAA,IAAW,KAAKxB,KAAA,CAAM7K,KAAA,CAAMU,eAAA,CAAgB2H,IAAA,CAAKgE,OAAO,GAAG;UAErEhH,IAAA,GAAOgH,OAAA,CAAQhD,IAAA,CAAK;QACtB;MACF;MAEA,OAAO;QACL6B,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACV6B,KAAA,EAAO7B,GAAA,CAAI,CAAC,EAAElB,MAAA;QACdlE,IAAA;QACA8F,MAAA,EAAQ,KAAKW,KAAA,CAAMhE,MAAA,CAAOzC,IAAI;MAChC;IACF;EACF;EAEAnB,GAAGgI,GAAA,EAAoC;IACrC,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAM1D,EAAA,CAAG5E,IAAA,CAAK4M,GAAG;IACxC,IAAIzB,GAAA,EAAK;MACP,OAAO;QACLS,IAAA,EAAM;QACNP,GAAA,EAAKf,KAAA,CAAMa,GAAA,CAAI,CAAC,GAAG,IAAI;MACzB;IACF;EACF;EAEAxF,WAAWiH,GAAA,EAA4C;IACrD,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAM3C,UAAA,CAAW3F,IAAA,CAAK4M,GAAG;IAChD,IAAIzB,GAAA,EAAK;MACP,IAAI8B,KAAA,GAAQ3C,KAAA,CAAMa,GAAA,CAAI,CAAC,GAAG,IAAI,EAAEtB,KAAA,CAAM,IAAI;MAC1C,IAAIwB,GAAA,GAAM;MACV,IAAItF,IAAA,GAAO;MACX,MAAM8F,MAAA,GAAkB,EAAC;MAEzB,OAAOoB,KAAA,CAAMhD,MAAA,GAAS,GAAG;QACvB,IAAIiD,YAAA,GAAe;QACnB,MAAMC,YAAA,GAAe,EAAC;QAEtB,IAAIrD,CAAA;QACJ,KAAKA,CAAA,GAAI,GAAGA,CAAA,GAAImD,KAAA,CAAMhD,MAAA,EAAQH,CAAA,IAAK;UAEjC,IAAI,KAAKyB,KAAA,CAAM7K,KAAA,CAAMiB,eAAA,CAAgBoH,IAAA,CAAKkE,KAAA,CAAMnD,CAAC,CAAC,GAAG;YACnDqD,YAAA,CAAa9C,IAAA,CAAK4C,KAAA,CAAMnD,CAAC,CAAC;YAC1BoD,YAAA,GAAe;UACjB,WAAW,CAACA,YAAA,EAAc;YACxBC,YAAA,CAAa9C,IAAA,CAAK4C,KAAA,CAAMnD,CAAC,CAAC;UAC5B,OAAO;YACL;UACF;QACF;QACAmD,KAAA,GAAQA,KAAA,CAAMpC,KAAA,CAAMf,CAAC;QAErB,MAAMsD,UAAA,GAAaD,YAAA,CAAad,IAAA,CAAK,IAAI;QACzC,MAAMgB,WAAA,GAAcD,UAAA,CAEjB9M,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMkB,uBAAA,EAAyB,UAAU,EAC5DtB,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMmB,wBAAA,EAA0B,EAAE;QACxDwJ,GAAA,GAAMA,GAAA,GAAM,GAAGA,GAAG;AAAA,EAAK+B,UAAU,KAAKA,UAAA;QACtCrH,IAAA,GAAOA,IAAA,GAAO,GAAGA,IAAI;AAAA,EAAKsH,WAAW,KAAKA,WAAA;QAI1C,MAAMC,GAAA,GAAM,KAAKd,KAAA,CAAMf,KAAA,CAAM6B,GAAA;QAC7B,KAAKd,KAAA,CAAMf,KAAA,CAAM6B,GAAA,GAAM;QACvB,KAAKd,KAAA,CAAMe,WAAA,CAAYF,WAAA,EAAaxB,MAAA,EAAQ,IAAI;QAChD,KAAKW,KAAA,CAAMf,KAAA,CAAM6B,GAAA,GAAMA,GAAA;QAGvB,IAAIL,KAAA,CAAMhD,MAAA,KAAW,GAAG;UACtB;QACF;QAEA,MAAMuD,SAAA,GAAY3B,MAAA,CAAO3B,EAAA,CAAG,EAAE;QAE9B,IAAIsD,SAAA,EAAW5B,IAAA,KAAS,QAAQ;UAE9B;QACF,WAAW4B,SAAA,EAAW5B,IAAA,KAAS,cAAc;UAE3C,MAAM6B,QAAA,GAAWD,SAAA;UACjB,MAAME,OAAA,GAAUD,QAAA,CAASpC,GAAA,GAAM,OAAO4B,KAAA,CAAMZ,IAAA,CAAK,IAAI;UACrD,MAAMsB,QAAA,GAAW,KAAKhI,UAAA,CAAW+H,OAAO;UACxC7B,MAAA,CAAOA,MAAA,CAAO5B,MAAA,GAAS,CAAC,IAAI0D,QAAA;UAE5BtC,GAAA,GAAMA,GAAA,CAAIuC,SAAA,CAAU,GAAGvC,GAAA,CAAIpB,MAAA,GAASwD,QAAA,CAASpC,GAAA,CAAIpB,MAAM,IAAI0D,QAAA,CAAStC,GAAA;UACpEtF,IAAA,GAAOA,IAAA,CAAK6H,SAAA,CAAU,GAAG7H,IAAA,CAAKkE,MAAA,GAASwD,QAAA,CAAS1H,IAAA,CAAKkE,MAAM,IAAI0D,QAAA,CAAS5H,IAAA;UACxE;QACF,WAAWyH,SAAA,EAAW5B,IAAA,KAAS,QAAQ;UAErC,MAAM6B,QAAA,GAAWD,SAAA;UACjB,MAAME,OAAA,GAAUD,QAAA,CAASpC,GAAA,GAAM,OAAO4B,KAAA,CAAMZ,IAAA,CAAK,IAAI;UACrD,MAAMsB,QAAA,GAAW,KAAKrI,IAAA,CAAKoI,OAAO;UAClC7B,MAAA,CAAOA,MAAA,CAAO5B,MAAA,GAAS,CAAC,IAAI0D,QAAA;UAE5BtC,GAAA,GAAMA,GAAA,CAAIuC,SAAA,CAAU,GAAGvC,GAAA,CAAIpB,MAAA,GAASuD,SAAA,CAAUnC,GAAA,CAAIpB,MAAM,IAAI0D,QAAA,CAAStC,GAAA;UACrEtF,IAAA,GAAOA,IAAA,CAAK6H,SAAA,CAAU,GAAG7H,IAAA,CAAKkE,MAAA,GAASwD,QAAA,CAASpC,GAAA,CAAIpB,MAAM,IAAI0D,QAAA,CAAStC,GAAA;UACvE4B,KAAA,GAAQS,OAAA,CAAQE,SAAA,CAAU/B,MAAA,CAAO3B,EAAA,CAAG,EAAE,EAAGmB,GAAA,CAAIpB,MAAM,EAAEJ,KAAA,CAAM,IAAI;UAC/D;QACF;MACF;MAEA,OAAO;QACL+B,IAAA,EAAM;QACNP,GAAA;QACAQ,MAAA;QACA9F;MACF;IACF;EACF;EAEAT,KAAKsH,GAAA,EAAsC;IACzC,IAAIzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAMhD,IAAA,CAAKtF,IAAA,CAAK4M,GAAG;IACxC,IAAIzB,GAAA,EAAK;MACP,IAAInH,IAAA,GAAOmH,GAAA,CAAI,CAAC,EAAEpB,IAAA,CAAK;MACvB,MAAM8D,SAAA,GAAY7J,IAAA,CAAKiG,MAAA,GAAS;MAEhC,MAAM6D,KAAA,GAAoB;QACxBlC,IAAA,EAAM;QACNP,GAAA,EAAK;QACL0C,OAAA,EAASF,SAAA;QACTG,KAAA,EAAOH,SAAA,GAAY,CAAC7J,IAAA,CAAK6G,KAAA,CAAM,GAAG,EAAE,IAAI;QACxCoD,KAAA,EAAO;QACPC,KAAA,EAAO;MACT;MAEAlK,IAAA,GAAO6J,SAAA,GAAY,aAAa7J,IAAA,CAAK6G,KAAA,CAAM,EAAE,CAAC,KAAK,KAAK7G,IAAI;MAE5D,IAAI,KAAKuI,OAAA,CAAQhN,QAAA,EAAU;QACzByE,IAAA,GAAO6J,SAAA,GAAY7J,IAAA,GAAO;MAC5B;MAGA,MAAMmK,SAAA,GAAY,KAAK5C,KAAA,CAAM7K,KAAA,CAAMqD,aAAA,CAAcC,IAAI;MACrD,IAAIoK,iBAAA,GAAoB;MAExB,OAAOxB,GAAA,EAAK;QACV,IAAIyB,QAAA,GAAW;QACf,IAAIhD,GAAA,GAAM;QACV,IAAIiD,YAAA,GAAe;QACnB,IAAI,EAAEnD,GAAA,GAAMgD,SAAA,CAAUnO,IAAA,CAAK4M,GAAG,IAAI;UAChC;QACF;QAEA,IAAI,KAAKrB,KAAA,CAAMjD,KAAA,CAAM1D,EAAA,CAAGmE,IAAA,CAAK6D,GAAG,GAAG;UACjC;QACF;QAEAvB,GAAA,GAAMF,GAAA,CAAI,CAAC;QACXyB,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUvC,GAAA,CAAIpB,MAAM;QAE9B,IAAIsE,IAAA,GAAOpD,GAAA,CAAI,CAAC,EAAEtB,KAAA,CAAM,MAAM,CAAC,EAAE,CAAC,EAAEvJ,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMoB,eAAA,EAAkB0M,CAAA,IAAc,IAAIC,MAAA,CAAO,IAAID,CAAA,CAAEvE,MAAM,CAAC;QACrH,IAAIyE,QAAA,GAAW9B,GAAA,CAAI/C,KAAA,CAAM,MAAM,CAAC,EAAE,CAAC;QACnC,IAAIpI,SAAA,GAAY,CAAC8M,IAAA,CAAKxE,IAAA,CAAK;QAE3B,IAAI7F,MAAA,GAAS;QACb,IAAI,KAAKqI,OAAA,CAAQhN,QAAA,EAAU;UACzB2E,MAAA,GAAS;UACToK,YAAA,GAAeC,IAAA,CAAKI,SAAA,CAAU;QAChC,WAAWlN,SAAA,EAAW;UACpByC,MAAA,GAASiH,GAAA,CAAI,CAAC,EAAElB,MAAA,GAAS;QAC3B,OAAO;UACL/F,MAAA,GAASiH,GAAA,CAAI,CAAC,EAAEyD,MAAA,CAAO,KAAKrD,KAAA,CAAM7K,KAAA,CAAMW,YAAY;UACpD6C,MAAA,GAASA,MAAA,GAAS,IAAI,IAAIA,MAAA;UAC1BoK,YAAA,GAAeC,IAAA,CAAK1D,KAAA,CAAM3G,MAAM;UAChCA,MAAA,IAAUiH,GAAA,CAAI,CAAC,EAAElB,MAAA;QACnB;QAEA,IAAIxI,SAAA,IAAa,KAAK8J,KAAA,CAAM7K,KAAA,CAAMe,SAAA,CAAUsH,IAAA,CAAK2F,QAAQ,GAAG;UAC1DrD,GAAA,IAAOqD,QAAA,GAAW;UAClB9B,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUc,QAAA,CAASzE,MAAA,GAAS,CAAC;UACvCoE,QAAA,GAAW;QACb;QAEA,IAAI,CAACA,QAAA,EAAU;UACb,MAAMpK,eAAA,GAAkB,KAAKsH,KAAA,CAAM7K,KAAA,CAAMuD,eAAA,CAAgBC,MAAM;UAC/D,MAAMG,OAAA,GAAU,KAAKkH,KAAA,CAAM7K,KAAA,CAAM2D,OAAA,CAAQH,MAAM;UAC/C,MAAMI,gBAAA,GAAmB,KAAKiH,KAAA,CAAM7K,KAAA,CAAM4D,gBAAA,CAAiBJ,MAAM;UACjE,MAAMK,iBAAA,GAAoB,KAAKgH,KAAA,CAAM7K,KAAA,CAAM6D,iBAAA,CAAkBL,MAAM;UACnE,MAAMM,cAAA,GAAiB,KAAK+G,KAAA,CAAM7K,KAAA,CAAM8D,cAAA,CAAeN,MAAM;UAG7D,OAAO0I,GAAA,EAAK;YACV,MAAMiC,OAAA,GAAUjC,GAAA,CAAI/C,KAAA,CAAM,MAAM,CAAC,EAAE,CAAC;YACpC,IAAIiF,mBAAA;YACJJ,QAAA,GAAWG,OAAA;YAGX,IAAI,KAAKtC,OAAA,CAAQhN,QAAA,EAAU;cACzBmP,QAAA,GAAWA,QAAA,CAASpO,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMqB,kBAAA,EAAoB,IAAI;cACrE+M,mBAAA,GAAsBJ,QAAA;YACxB,OAAO;cACLI,mBAAA,GAAsBJ,QAAA,CAASpO,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMa,aAAA,EAAe,MAAM;YAC/E;YAGA,IAAI+C,gBAAA,CAAiByE,IAAA,CAAK2F,QAAQ,GAAG;cACnC;YACF;YAGA,IAAInK,iBAAA,CAAkBwE,IAAA,CAAK2F,QAAQ,GAAG;cACpC;YACF;YAGA,IAAIlK,cAAA,CAAeuE,IAAA,CAAK2F,QAAQ,GAAG;cACjC;YACF;YAGA,IAAIzK,eAAA,CAAgB8E,IAAA,CAAK2F,QAAQ,GAAG;cAClC;YACF;YAGA,IAAIrK,OAAA,CAAQ0E,IAAA,CAAK2F,QAAQ,GAAG;cAC1B;YACF;YAEA,IAAII,mBAAA,CAAoBF,MAAA,CAAO,KAAKrD,KAAA,CAAM7K,KAAA,CAAMW,YAAY,KAAK6C,MAAA,IAAU,CAACwK,QAAA,CAAS3E,IAAA,CAAK,GAAG;cAC3FuE,YAAA,IAAgB,OAAOQ,mBAAA,CAAoBjE,KAAA,CAAM3G,MAAM;YACzD,OAAO;cAEL,IAAIzC,SAAA,EAAW;gBACb;cACF;cAGA,IAAI8M,IAAA,CAAKjO,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMa,aAAA,EAAe,MAAM,EAAEqN,MAAA,CAAO,KAAKrD,KAAA,CAAM7K,KAAA,CAAMW,YAAY,KAAK,GAAG;gBACnG;cACF;cACA,IAAIiD,gBAAA,CAAiByE,IAAA,CAAKwF,IAAI,GAAG;gBAC/B;cACF;cACA,IAAIhK,iBAAA,CAAkBwE,IAAA,CAAKwF,IAAI,GAAG;gBAChC;cACF;cACA,IAAIlK,OAAA,CAAQ0E,IAAA,CAAKwF,IAAI,GAAG;gBACtB;cACF;cAEAD,YAAA,IAAgB,OAAOI,QAAA;YACzB;YAEA,IAAI,CAACjN,SAAA,IAAa,CAACiN,QAAA,CAAS3E,IAAA,CAAK,GAAG;cAClCtI,SAAA,GAAY;YACd;YAEA4J,GAAA,IAAOwD,OAAA,GAAU;YACjBjC,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUiB,OAAA,CAAQ5E,MAAA,GAAS,CAAC;YACtCsE,IAAA,GAAOO,mBAAA,CAAoBjE,KAAA,CAAM3G,MAAM;UACzC;QACF;QAEA,IAAI,CAAC4J,KAAA,CAAKG,KAAA,EAAO;UAEf,IAAIG,iBAAA,EAAmB;YACrBN,KAAA,CAAKG,KAAA,GAAQ;UACf,WAAW,KAAK1C,KAAA,CAAM7K,KAAA,CAAMgB,eAAA,CAAgBqH,IAAA,CAAKsC,GAAG,GAAG;YACrD+C,iBAAA,GAAoB;UACtB;QACF;QAEA,IAAIW,MAAA,GAAiC;QACrC,IAAIC,SAAA;QAEJ,IAAI,KAAKzC,OAAA,CAAQlN,GAAA,EAAK;UACpB0P,MAAA,GAAS,KAAKxD,KAAA,CAAM7K,KAAA,CAAMsB,UAAA,CAAWhC,IAAA,CAAKsO,YAAY;UACtD,IAAIS,MAAA,EAAQ;YACVC,SAAA,GAAYD,MAAA,CAAO,CAAC,MAAM;YAC1BT,YAAA,GAAeA,YAAA,CAAahO,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMuB,eAAA,EAAiB,EAAE;UAC1E;QACF;QAEA6L,KAAA,CAAKI,KAAA,CAAM7D,IAAA,CAAK;UACduB,IAAA,EAAM;UACNP,GAAA;UACA4D,IAAA,EAAM,CAAC,CAACF,MAAA;UACRG,OAAA,EAASF,SAAA;UACTf,KAAA,EAAO;UACPlI,IAAA,EAAMuI,YAAA;UACNzC,MAAA,EAAQ;QACV,CAAC;QAEDiC,KAAA,CAAKzC,GAAA,IAAOA,GAAA;MACd;MAGA,MAAM8D,QAAA,GAAWrB,KAAA,CAAKI,KAAA,CAAMhE,EAAA,CAAG,EAAE;MACjC,IAAIiF,QAAA,EAAU;QACZA,QAAA,CAAS9D,GAAA,GAAM8D,QAAA,CAAS9D,GAAA,CAAI+D,OAAA,CAAQ;QACpCD,QAAA,CAASpJ,IAAA,GAAOoJ,QAAA,CAASpJ,IAAA,CAAKqJ,OAAA,CAAQ;MACxC,OAAO;QAEL;MACF;MACAtB,KAAA,CAAKzC,GAAA,GAAMyC,KAAA,CAAKzC,GAAA,CAAI+D,OAAA,CAAQ;MAG5B,SAAStF,CAAA,GAAI,GAAGA,CAAA,GAAIgE,KAAA,CAAKI,KAAA,CAAMjE,MAAA,EAAQH,CAAA,IAAK;QAC1C,KAAK0C,KAAA,CAAMf,KAAA,CAAM6B,GAAA,GAAM;QACvBQ,KAAA,CAAKI,KAAA,CAAMpE,CAAC,EAAE+B,MAAA,GAAS,KAAKW,KAAA,CAAMe,WAAA,CAAYO,KAAA,CAAKI,KAAA,CAAMpE,CAAC,EAAE/D,IAAA,EAAM,EAAE;QAEpE,IAAI,CAAC+H,KAAA,CAAKG,KAAA,EAAO;UAEf,MAAMoB,OAAA,GAAUvB,KAAA,CAAKI,KAAA,CAAMpE,CAAC,EAAE+B,MAAA,CAAOyD,MAAA,CAAOd,CAAA,IAAKA,CAAA,CAAE5C,IAAA,KAAS,OAAO;UACnE,MAAM2D,qBAAA,GAAwBF,OAAA,CAAQpF,MAAA,GAAS,KAAKoF,OAAA,CAAQG,IAAA,CAAKhB,CAAA,IAAK,KAAKjD,KAAA,CAAM7K,KAAA,CAAMwB,OAAA,CAAQ6G,IAAA,CAAKyF,CAAA,CAAEnD,GAAG,CAAC;UAE1GyC,KAAA,CAAKG,KAAA,GAAQsB,qBAAA;QACf;MACF;MAGA,IAAIzB,KAAA,CAAKG,KAAA,EAAO;QACd,SAASnE,CAAA,GAAI,GAAGA,CAAA,GAAIgE,KAAA,CAAKI,KAAA,CAAMjE,MAAA,EAAQH,CAAA,IAAK;UAC1CgE,KAAA,CAAKI,KAAA,CAAMpE,CAAC,EAAEmE,KAAA,GAAQ;QACxB;MACF;MAEA,OAAOH,KAAA;IACT;EACF;EAEArI,KAAKmH,GAAA,EAAsC;IACzC,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAM7C,IAAA,CAAKzF,IAAA,CAAK4M,GAAG;IAC1C,IAAIzB,GAAA,EAAK;MACP,MAAMQ,KAAA,GAAqB;QACzBC,IAAA,EAAM;QACNtD,KAAA,EAAO;QACP+C,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVsE,GAAA,EAAKtE,GAAA,CAAI,CAAC,MAAM,SAASA,GAAA,CAAI,CAAC,MAAM,YAAYA,GAAA,CAAI,CAAC,MAAM;QAC3DpF,IAAA,EAAMoF,GAAA,CAAI,CAAC;MACb;MACA,OAAOQ,KAAA;IACT;EACF;EAEAtG,IAAIuH,GAAA,EAAqC;IACvC,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAMjD,GAAA,CAAIrF,IAAA,CAAK4M,GAAG;IACzC,IAAIzB,GAAA,EAAK;MACP,MAAMuE,IAAA,GAAMvE,GAAA,CAAI,CAAC,EAAEwE,WAAA,CAAY,EAAErP,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMc,mBAAA,EAAqB,GAAG;MAClF,MAAMyH,IAAA,GAAOkC,GAAA,CAAI,CAAC,IAAIA,GAAA,CAAI,CAAC,EAAE7K,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMyB,YAAA,EAAc,IAAI,EAAE7B,OAAA,CAAQ,KAAKiL,KAAA,CAAM/C,MAAA,CAAOlB,cAAA,EAAgB,IAAI,IAAI;MAC5H,MAAMkE,KAAA,GAAQL,GAAA,CAAI,CAAC,IAAIA,GAAA,CAAI,CAAC,EAAEyC,SAAA,CAAU,GAAGzC,GAAA,CAAI,CAAC,EAAElB,MAAA,GAAS,CAAC,EAAE3J,OAAA,CAAQ,KAAKiL,KAAA,CAAM/C,MAAA,CAAOlB,cAAA,EAAgB,IAAI,IAAI6D,GAAA,CAAI,CAAC;MACrH,OAAO;QACLS,IAAA,EAAM;QACNnE,GAAA,EAAAiI,IAAA;QACArE,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVlC,IAAA;QACAuC;MACF;IACF;EACF;EAEA1F,MAAM8G,GAAA,EAAuC;IAC3C,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAMxC,KAAA,CAAM9F,IAAA,CAAK4M,GAAG;IAC3C,IAAI,CAACzB,GAAA,EAAK;MACR;IACF;IAEA,IAAI,CAAC,KAAKI,KAAA,CAAM7K,KAAA,CAAM0B,cAAA,CAAe2G,IAAA,CAAKoC,GAAA,CAAI,CAAC,CAAC,GAAG;MAEjD;IACF;IAEA,MAAMyE,OAAA,GAAUzG,UAAA,CAAWgC,GAAA,CAAI,CAAC,CAAC;IACjC,MAAM0E,MAAA,GAAS1E,GAAA,CAAI,CAAC,EAAE7K,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAM2B,eAAA,EAAiB,EAAE,EAAEwH,KAAA,CAAM,GAAG;IAC7E,MAAMiG,IAAA,GAAO3E,GAAA,CAAI,CAAC,GAAGpB,IAAA,CAAK,IAAIoB,GAAA,CAAI,CAAC,EAAE7K,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAM4B,iBAAA,EAAmB,EAAE,EAAEuH,KAAA,CAAM,IAAI,IAAI,EAAC;IAEpG,MAAMkG,IAAA,GAAqB;MACzBnE,IAAA,EAAM;MACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;MACV6E,MAAA,EAAQ,EAAC;MACTC,KAAA,EAAO,EAAC;MACRH,IAAA,EAAM;IACR;IAEA,IAAIF,OAAA,CAAQ3F,MAAA,KAAW4F,MAAA,CAAO5F,MAAA,EAAQ;MAEpC;IACF;IAEA,WAAWgG,KAAA,IAASJ,MAAA,EAAQ;MAC1B,IAAI,KAAKtE,KAAA,CAAM7K,KAAA,CAAM6B,eAAA,CAAgBwG,IAAA,CAAKkH,KAAK,GAAG;QAChDF,IAAA,CAAKE,KAAA,CAAM5F,IAAA,CAAK,OAAO;MACzB,WAAW,KAAKkB,KAAA,CAAM7K,KAAA,CAAM8B,gBAAA,CAAiBuG,IAAA,CAAKkH,KAAK,GAAG;QACxDF,IAAA,CAAKE,KAAA,CAAM5F,IAAA,CAAK,QAAQ;MAC1B,WAAW,KAAKkB,KAAA,CAAM7K,KAAA,CAAM+B,cAAA,CAAesG,IAAA,CAAKkH,KAAK,GAAG;QACtDF,IAAA,CAAKE,KAAA,CAAM5F,IAAA,CAAK,MAAM;MACxB,OAAO;QACL0F,IAAA,CAAKE,KAAA,CAAM5F,IAAA,CAAK,IAAI;MACtB;IACF;IAEA,SAASP,CAAA,GAAI,GAAGA,CAAA,GAAI8F,OAAA,CAAQ3F,MAAA,EAAQH,CAAA,IAAK;MACvCiG,IAAA,CAAKC,MAAA,CAAO3F,IAAA,CAAK;QACftE,IAAA,EAAM6J,OAAA,CAAQ9F,CAAC;QACf+B,MAAA,EAAQ,KAAKW,KAAA,CAAMhE,MAAA,CAAOoH,OAAA,CAAQ9F,CAAC,CAAC;QACpCkG,MAAA,EAAQ;QACRC,KAAA,EAAOF,IAAA,CAAKE,KAAA,CAAMnG,CAAC;MACrB,CAAC;IACH;IAEA,WAAWR,GAAA,IAAOwG,IAAA,EAAM;MACtBC,IAAA,CAAKD,IAAA,CAAKzF,IAAA,CAAKlB,UAAA,CAAWG,GAAA,EAAKyG,IAAA,CAAKC,MAAA,CAAO/F,MAAM,EAAEgC,GAAA,CAAI,CAACiE,IAAA,EAAMpG,CAAA,KAAM;QAClE,OAAO;UACL/D,IAAA,EAAMmK,IAAA;UACNrE,MAAA,EAAQ,KAAKW,KAAA,CAAMhE,MAAA,CAAO0H,IAAI;UAC9BF,MAAA,EAAQ;UACRC,KAAA,EAAOF,IAAA,CAAKE,KAAA,CAAMnG,CAAC;QACrB;MACF,CAAC,CAAC;IACJ;IAEA,OAAOiG,IAAA;EACT;EAEA/K,SAAS4H,GAAA,EAAyC;IAChD,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAMtD,QAAA,CAAShF,IAAA,CAAK4M,GAAG;IAC9C,IAAIzB,GAAA,EAAK;MACP,OAAO;QACLS,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACV6B,KAAA,EAAO7B,GAAA,CAAI,CAAC,EAAEP,MAAA,CAAO,CAAC,MAAM,MAAM,IAAI;QACtC7E,IAAA,EAAMoF,GAAA,CAAI,CAAC;QACXU,MAAA,EAAQ,KAAKW,KAAA,CAAMhE,MAAA,CAAO2C,GAAA,CAAI,CAAC,CAAC;MAClC;IACF;EACF;EAEAzF,UAAUkH,GAAA,EAA2C;IACnD,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAM5C,SAAA,CAAU1F,IAAA,CAAK4M,GAAG;IAC/C,IAAIzB,GAAA,EAAK;MACP,MAAMpF,IAAA,GAAOoF,GAAA,CAAI,CAAC,EAAEP,MAAA,CAAOO,GAAA,CAAI,CAAC,EAAElB,MAAA,GAAS,CAAC,MAAM,OAC9CkB,GAAA,CAAI,CAAC,EAAEN,KAAA,CAAM,GAAG,EAAE,IAClBM,GAAA,CAAI,CAAC;MACT,OAAO;QACLS,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVpF,IAAA;QACA8F,MAAA,EAAQ,KAAKW,KAAA,CAAMhE,MAAA,CAAOzC,IAAI;MAChC;IACF;EACF;EAEAA,KAAK6G,GAAA,EAAsC;IACzC,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAMvC,IAAA,CAAK/F,IAAA,CAAK4M,GAAG;IAC1C,IAAIzB,GAAA,EAAK;MACP,OAAO;QACLS,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVpF,IAAA,EAAMoF,GAAA,CAAI,CAAC;QACXU,MAAA,EAAQ,KAAKW,KAAA,CAAMhE,MAAA,CAAO2C,GAAA,CAAI,CAAC,CAAC;MAClC;IACF;EACF;EAEAhF,OAAOyG,GAAA,EAAwC;IAC7C,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOrC,MAAA,CAAOnG,IAAA,CAAK4M,GAAG;IAC7C,IAAIzB,GAAA,EAAK;MACP,OAAO;QACLS,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVpF,IAAA,EAAMoF,GAAA,CAAI,CAAC;MACb;IACF;EACF;EAEA1D,IAAImF,GAAA,EAAqC;IACvC,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOf,GAAA,CAAIzH,IAAA,CAAK4M,GAAG;IAC1C,IAAIzB,GAAA,EAAK;MACP,IAAI,CAAC,KAAKqB,KAAA,CAAMf,KAAA,CAAMC,MAAA,IAAU,KAAKH,KAAA,CAAM7K,KAAA,CAAMgC,SAAA,CAAUqG,IAAA,CAAKoC,GAAA,CAAI,CAAC,CAAC,GAAG;QACvE,KAAKqB,KAAA,CAAMf,KAAA,CAAMC,MAAA,GAAS;MAC5B,WAAW,KAAKc,KAAA,CAAMf,KAAA,CAAMC,MAAA,IAAU,KAAKH,KAAA,CAAM7K,KAAA,CAAMiC,OAAA,CAAQoG,IAAA,CAAKoC,GAAA,CAAI,CAAC,CAAC,GAAG;QAC3E,KAAKqB,KAAA,CAAMf,KAAA,CAAMC,MAAA,GAAS;MAC5B;MACA,IAAI,CAAC,KAAKc,KAAA,CAAMf,KAAA,CAAM0E,UAAA,IAAc,KAAK5E,KAAA,CAAM7K,KAAA,CAAMkC,iBAAA,CAAkBmG,IAAA,CAAKoC,GAAA,CAAI,CAAC,CAAC,GAAG;QACnF,KAAKqB,KAAA,CAAMf,KAAA,CAAM0E,UAAA,GAAa;MAChC,WAAW,KAAK3D,KAAA,CAAMf,KAAA,CAAM0E,UAAA,IAAc,KAAK5E,KAAA,CAAM7K,KAAA,CAAMmC,eAAA,CAAgBkG,IAAA,CAAKoC,GAAA,CAAI,CAAC,CAAC,GAAG;QACvF,KAAKqB,KAAA,CAAMf,KAAA,CAAM0E,UAAA,GAAa;MAChC;MAEA,OAAO;QACLvE,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVO,MAAA,EAAQ,KAAKc,KAAA,CAAMf,KAAA,CAAMC,MAAA;QACzByE,UAAA,EAAY,KAAK3D,KAAA,CAAMf,KAAA,CAAM0E,UAAA;QAC7B7H,KAAA,EAAO;QACPvC,IAAA,EAAMoF,GAAA,CAAI,CAAC;MACb;IACF;EACF;EAEAxD,KAAKiF,GAAA,EAAqD;IACxD,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOb,IAAA,CAAK3H,IAAA,CAAK4M,GAAG;IAC3C,IAAIzB,GAAA,EAAK;MACP,MAAMiF,UAAA,GAAajF,GAAA,CAAI,CAAC,EAAEpB,IAAA,CAAK;MAC/B,IAAI,CAAC,KAAKwC,OAAA,CAAQhN,QAAA,IAAY,KAAKgM,KAAA,CAAM7K,KAAA,CAAMoC,iBAAA,CAAkBiG,IAAA,CAAKqH,UAAU,GAAG;QAEjF,IAAI,CAAE,KAAK7E,KAAA,CAAM7K,KAAA,CAAMqC,eAAA,CAAgBgG,IAAA,CAAKqH,UAAU,GAAI;UACxD;QACF;QAGA,MAAMC,UAAA,GAAa/F,KAAA,CAAM8F,UAAA,CAAWvF,KAAA,CAAM,GAAG,EAAE,GAAG,IAAI;QACtD,KAAKuF,UAAA,CAAWnG,MAAA,GAASoG,UAAA,CAAWpG,MAAA,IAAU,MAAM,GAAG;UACrD;QACF;MACF,OAAO;QAEL,MAAMqG,cAAA,GAAiBxF,kBAAA,CAAmBK,GAAA,CAAI,CAAC,GAAG,IAAI;QACtD,IAAImF,cAAA,KAAmB,IAAI;UAEzB;QACF;QAEA,IAAIA,cAAA,GAAiB,IAAI;UACvB,MAAMtC,KAAA,GAAQ7C,GAAA,CAAI,CAAC,EAAEH,OAAA,CAAQ,GAAG,MAAM,IAAI,IAAI;UAC9C,MAAMuF,OAAA,GAAUvC,KAAA,GAAQ7C,GAAA,CAAI,CAAC,EAAElB,MAAA,GAASqG,cAAA;UACxCnF,GAAA,CAAI,CAAC,IAAIA,GAAA,CAAI,CAAC,EAAEyC,SAAA,CAAU,GAAG0C,cAAc;UAC3CnF,GAAA,CAAI,CAAC,IAAIA,GAAA,CAAI,CAAC,EAAEyC,SAAA,CAAU,GAAG2C,OAAO,EAAExG,IAAA,CAAK;UAC3CoB,GAAA,CAAI,CAAC,IAAI;QACX;MACF;MACA,IAAIlC,IAAA,GAAOkC,GAAA,CAAI,CAAC;MAChB,IAAIK,KAAA,GAAQ;MACZ,IAAI,KAAKe,OAAA,CAAQhN,QAAA,EAAU;QAEzB,MAAM6L,KAAA,GAAO,KAAKG,KAAA,CAAM7K,KAAA,CAAMsC,iBAAA,CAAkBhD,IAAA,CAAKiJ,IAAI;QAEzD,IAAImC,KAAA,EAAM;UACRnC,IAAA,GAAOmC,KAAA,CAAK,CAAC;UACbI,KAAA,GAAQJ,KAAA,CAAK,CAAC;QAChB;MACF,OAAO;QACLI,KAAA,GAAQL,GAAA,CAAI,CAAC,IAAIA,GAAA,CAAI,CAAC,EAAEN,KAAA,CAAM,GAAG,EAAE,IAAI;MACzC;MAEA5B,IAAA,GAAOA,IAAA,CAAKc,IAAA,CAAK;MACjB,IAAI,KAAKwB,KAAA,CAAM7K,KAAA,CAAMoC,iBAAA,CAAkBiG,IAAA,CAAKE,IAAI,GAAG;QACjD,IAAI,KAAKsD,OAAA,CAAQhN,QAAA,IAAY,CAAE,KAAKgM,KAAA,CAAM7K,KAAA,CAAMqC,eAAA,CAAgBgG,IAAA,CAAKqH,UAAU,GAAI;UAEjFnH,IAAA,GAAOA,IAAA,CAAK4B,KAAA,CAAM,CAAC;QACrB,OAAO;UACL5B,IAAA,GAAOA,IAAA,CAAK4B,KAAA,CAAM,GAAG,EAAE;QACzB;MACF;MACA,OAAOK,UAAA,CAAWC,GAAA,EAAK;QACrBlC,IAAA,EAAMA,IAAA,GAAOA,IAAA,CAAK3I,OAAA,CAAQ,KAAKiL,KAAA,CAAM/C,MAAA,CAAOlB,cAAA,EAAgB,IAAI,IAAI2B,IAAA;QACpEuC,KAAA,EAAOA,KAAA,GAAQA,KAAA,CAAMlL,OAAA,CAAQ,KAAKiL,KAAA,CAAM/C,MAAA,CAAOlB,cAAA,EAAgB,IAAI,IAAIkE;MACzE,GAAGL,GAAA,CAAI,CAAC,GAAG,KAAKqB,KAAA,EAAO,KAAKjB,KAAK;IACnC;EACF;EAEA3D,QAAQgF,GAAA,EAAa4D,KAAA,EAAoE;IACvF,IAAIrF,GAAA;IACJ,KAAKA,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOZ,OAAA,CAAQ5H,IAAA,CAAK4M,GAAG,OACvCzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOX,MAAA,CAAO7H,IAAA,CAAK4M,GAAG,IAAI;MAC/C,MAAM6D,UAAA,IAActF,GAAA,CAAI,CAAC,KAAKA,GAAA,CAAI,CAAC,GAAG7K,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMc,mBAAA,EAAqB,GAAG;MACvF,MAAM4J,KAAA,GAAOoF,KAAA,CAAMC,UAAA,CAAWd,WAAA,CAAY,CAAC;MAC3C,IAAI,CAACvE,KAAA,EAAM;QACT,MAAMrF,IAAA,GAAOoF,GAAA,CAAI,CAAC,EAAEP,MAAA,CAAO,CAAC;QAC5B,OAAO;UACLgB,IAAA,EAAM;UACNP,GAAA,EAAKtF,IAAA;UACLA;QACF;MACF;MACA,OAAOmF,UAAA,CAAWC,GAAA,EAAKC,KAAA,EAAMD,GAAA,CAAI,CAAC,GAAG,KAAKqB,KAAA,EAAO,KAAKjB,KAAK;IAC7D;EACF;EAEAmF,SAAS9D,GAAA,EAAa+D,SAAA,EAAmBC,QAAA,GAAW,IAA2C;IAC7F,IAAIrH,KAAA,GAAQ,KAAKgC,KAAA,CAAM/C,MAAA,CAAOxB,cAAA,CAAehH,IAAA,CAAK4M,GAAG;IACrD,IAAI,CAACrD,KAAA,EAAO;IAGZ,IAAIA,KAAA,CAAM,CAAC,KAAKqH,QAAA,CAASrH,KAAA,CAAM,KAAKgC,KAAA,CAAM7K,KAAA,CAAMuC,mBAAmB,GAAG;IAEtE,MAAM4N,QAAA,GAAWtH,KAAA,CAAM,CAAC,KAAKA,KAAA,CAAM,CAAC,KAAK;IAEzC,IAAI,CAACsH,QAAA,IAAY,CAACD,QAAA,IAAY,KAAKrF,KAAA,CAAM/C,MAAA,CAAO9B,WAAA,CAAY1G,IAAA,CAAK4Q,QAAQ,GAAG;MAE1E,MAAME,OAAA,GAAU,CAAC,GAAGvH,KAAA,CAAM,CAAC,CAAC,EAAEU,MAAA,GAAS;MACvC,IAAI8G,MAAA;QAAQC,OAAA;QAASC,UAAA,GAAaH,OAAA;QAASI,aAAA,GAAgB;MAE3D,MAAMC,MAAA,GAAS5H,KAAA,CAAM,CAAC,EAAE,CAAC,MAAM,MAAM,KAAKgC,KAAA,CAAM/C,MAAA,CAAOrB,iBAAA,GAAoB,KAAKoE,KAAA,CAAM/C,MAAA,CAAOnB,iBAAA;MAC7F8J,MAAA,CAAOC,SAAA,GAAY;MAGnBT,SAAA,GAAYA,SAAA,CAAU9F,KAAA,CAAM,KAAK+B,GAAA,CAAI3C,MAAA,GAAS6G,OAAO;MAErD,QAAQvH,KAAA,GAAQ4H,MAAA,CAAOnR,IAAA,CAAK2Q,SAAS,MAAM,MAAM;QAC/CI,MAAA,GAASxH,KAAA,CAAM,CAAC,KAAKA,KAAA,CAAM,CAAC,KAAKA,KAAA,CAAM,CAAC,KAAKA,KAAA,CAAM,CAAC,KAAKA,KAAA,CAAM,CAAC,KAAKA,KAAA,CAAM,CAAC;QAE5E,IAAI,CAACwH,MAAA,EAAQ;QAEbC,OAAA,GAAU,CAAC,GAAGD,MAAM,EAAE9G,MAAA;QAEtB,IAAIV,KAAA,CAAM,CAAC,KAAKA,KAAA,CAAM,CAAC,GAAG;UACxB0H,UAAA,IAAcD,OAAA;UACd;QACF,WAAWzH,KAAA,CAAM,CAAC,KAAKA,KAAA,CAAM,CAAC,GAAG;UAC/B,IAAIuH,OAAA,GAAU,KAAK,GAAGA,OAAA,GAAUE,OAAA,IAAW,IAAI;YAC7CE,aAAA,IAAiBF,OAAA;YACjB;UACF;QACF;QAEAC,UAAA,IAAcD,OAAA;QAEd,IAAIC,UAAA,GAAa,GAAG;QAGpBD,OAAA,GAAU7M,IAAA,CAAKC,GAAA,CAAI4M,OAAA,EAASA,OAAA,GAAUC,UAAA,GAAaC,aAAa;QAEhE,MAAMG,cAAA,GAAiB,CAAC,GAAG9H,KAAA,CAAM,CAAC,CAAC,EAAE,CAAC,EAAEU,MAAA;QACxC,MAAMoB,GAAA,GAAMuB,GAAA,CAAI/B,KAAA,CAAM,GAAGiG,OAAA,GAAUvH,KAAA,CAAM+H,KAAA,GAAQD,cAAA,GAAiBL,OAAO;QAGzE,IAAI7M,IAAA,CAAKC,GAAA,CAAI0M,OAAA,EAASE,OAAO,IAAI,GAAG;UAClC,MAAMO,KAAA,GAAOlG,GAAA,CAAIR,KAAA,CAAM,GAAG,EAAE;UAC5B,OAAO;YACLe,IAAA,EAAM;YACNP,GAAA;YACAtF,IAAA,EAAAwL,KAAA;YACA1F,MAAA,EAAQ,KAAKW,KAAA,CAAMV,YAAA,CAAayF,KAAI;UACtC;QACF;QAGA,MAAMxL,IAAA,GAAOsF,GAAA,CAAIR,KAAA,CAAM,GAAG,EAAE;QAC5B,OAAO;UACLe,IAAA,EAAM;UACNP,GAAA;UACAtF,IAAA;UACA8F,MAAA,EAAQ,KAAKW,KAAA,CAAMV,YAAA,CAAa/F,IAAI;QACtC;MACF;IACF;EACF;EAEAyL,SAAS5E,GAAA,EAA0C;IACjD,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAO3C,IAAA,CAAK7F,IAAA,CAAK4M,GAAG;IAC3C,IAAIzB,GAAA,EAAK;MACP,IAAIpF,IAAA,GAAOoF,GAAA,CAAI,CAAC,EAAE7K,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMY,iBAAA,EAAmB,GAAG;MACjE,MAAMmQ,gBAAA,GAAmB,KAAKlG,KAAA,CAAM7K,KAAA,CAAMW,YAAA,CAAa0H,IAAA,CAAKhD,IAAI;MAChE,MAAM2L,uBAAA,GAA0B,KAAKnG,KAAA,CAAM7K,KAAA,CAAMS,iBAAA,CAAkB4H,IAAA,CAAKhD,IAAI,KAAK,KAAKwF,KAAA,CAAM7K,KAAA,CAAMU,eAAA,CAAgB2H,IAAA,CAAKhD,IAAI;MAC3H,IAAI0L,gBAAA,IAAoBC,uBAAA,EAAyB;QAC/C3L,IAAA,GAAOA,IAAA,CAAK6H,SAAA,CAAU,GAAG7H,IAAA,CAAKkE,MAAA,GAAS,CAAC;MAC1C;MACA,OAAO;QACL2B,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVpF;MACF;IACF;EACF;EAEAM,GAAGuG,GAAA,EAAoC;IACrC,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOnC,EAAA,CAAGrG,IAAA,CAAK4M,GAAG;IACzC,IAAIzB,GAAA,EAAK;MACP,OAAO;QACLS,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;MACZ;IACF;EACF;EAEAlD,IAAI2E,GAAA,EAAqC;IACvC,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOP,GAAA,CAAIjI,IAAA,CAAK4M,GAAG;IAC1C,IAAIzB,GAAA,EAAK;MACP,OAAO;QACLS,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVpF,IAAA,EAAMoF,GAAA,CAAI,CAAC;QACXU,MAAA,EAAQ,KAAKW,KAAA,CAAMV,YAAA,CAAaX,GAAA,CAAI,CAAC,CAAC;MACxC;IACF;EACF;EAEA5D,SAASqF,GAAA,EAAsC;IAC7C,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOjB,QAAA,CAASvH,IAAA,CAAK4M,GAAG;IAC/C,IAAIzB,GAAA,EAAK;MACP,IAAIpF,IAAA,EAAMkD,IAAA;MACV,IAAIkC,GAAA,CAAI,CAAC,MAAM,KAAK;QAClBpF,IAAA,GAAOoF,GAAA,CAAI,CAAC;QACZlC,IAAA,GAAO,YAAYlD,IAAA;MACrB,OAAO;QACLA,IAAA,GAAOoF,GAAA,CAAI,CAAC;QACZlC,IAAA,GAAOlD,IAAA;MACT;MAEA,OAAO;QACL6F,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVpF,IAAA;QACAkD,IAAA;QACA4C,MAAA,EAAQ,CACN;UACED,IAAA,EAAM;UACNP,GAAA,EAAKtF,IAAA;UACLA;QACF;MAEJ;IACF;EACF;EAEAmC,IAAI0E,GAAA,EAAsC;IACxC,IAAIzB,GAAA;IACJ,IAAIA,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAON,GAAA,CAAIlI,IAAA,CAAK4M,GAAG,GAAG;MACzC,IAAI7G,IAAA,EAAMkD,IAAA;MACV,IAAIkC,GAAA,CAAI,CAAC,MAAM,KAAK;QAClBpF,IAAA,GAAOoF,GAAA,CAAI,CAAC;QACZlC,IAAA,GAAO,YAAYlD,IAAA;MACrB,OAAO;QAEL,IAAI4L,WAAA;QACJ,GAAG;UACDA,WAAA,GAAcxG,GAAA,CAAI,CAAC;UACnBA,GAAA,CAAI,CAAC,IAAI,KAAKI,KAAA,CAAM/C,MAAA,CAAOR,UAAA,CAAWhI,IAAA,CAAKmL,GAAA,CAAI,CAAC,CAAC,IAAI,CAAC,KAAK;QAC7D,SAASwG,WAAA,KAAgBxG,GAAA,CAAI,CAAC;QAC9BpF,IAAA,GAAOoF,GAAA,CAAI,CAAC;QACZ,IAAIA,GAAA,CAAI,CAAC,MAAM,QAAQ;UACrBlC,IAAA,GAAO,YAAYkC,GAAA,CAAI,CAAC;QAC1B,OAAO;UACLlC,IAAA,GAAOkC,GAAA,CAAI,CAAC;QACd;MACF;MACA,OAAO;QACLS,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVpF,IAAA;QACAkD,IAAA;QACA4C,MAAA,EAAQ,CACN;UACED,IAAA,EAAM;UACNP,GAAA,EAAKtF,IAAA;UACLA;QACF;MAEJ;IACF;EACF;EAEAO,WAAWsG,GAAA,EAAsC;IAC/C,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOzC,IAAA,CAAK/F,IAAA,CAAK4M,GAAG;IAC3C,IAAIzB,GAAA,EAAK;MACP,MAAMzB,OAAA,GAAU,KAAK8C,KAAA,CAAMf,KAAA,CAAM0E,UAAA;MACjC,OAAO;QACLvE,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVpF,IAAA,EAAMoF,GAAA,CAAI,CAAC;QACXzB;MACF;IACF;EACF;AACF;;;ACn2BO,IAAMkI,MAAA,GAAN,MAAMC,OAAA,CAAO;EAClBhG,MAAA;EACAU,OAAA;EACAd,KAAA;EAMQ/L,SAAA;EACAoS,WAAA;EAERrF,YAAYC,QAAA,EAAyB;IAEnC,KAAKb,MAAA,GAAS,EAAC;IACf,KAAKA,MAAA,CAAO2E,KAAA,GAAQ,eAAAuB,MAAA,CAAOC,MAAA,CAAO,IAAI;IACtC,KAAKzF,OAAA,GAAUG,QAAA,IAAW9M,SAAA;IAC1B,KAAK2M,OAAA,CAAQ7M,SAAA,GAAY,KAAK6M,OAAA,CAAQ7M,SAAA,IAAa,IAAI4M,UAAA,CAAW;IAClE,KAAK5M,SAAA,GAAY,KAAK6M,OAAA,CAAQ7M,SAAA;IAC9B,KAAKA,SAAA,CAAU6M,OAAA,GAAU,KAAKA,OAAA;IAC9B,KAAK7M,SAAA,CAAU8M,KAAA,GAAQ;IACvB,KAAKsF,WAAA,GAAc,EAAC;IACpB,KAAKrG,KAAA,GAAQ;MACXC,MAAA,EAAQ;MACRyE,UAAA,EAAY;MACZ7C,GAAA,EAAK;IACP;IAEA,MAAM/B,KAAA,GAAQ;MACZ7K,KAAA;MACA4H,KAAA,EAAOA,KAAA,CAAMC,MAAA;MACbC,MAAA,EAAQA,MAAA,CAAOD;IACjB;IAEA,IAAI,KAAKgE,OAAA,CAAQhN,QAAA,EAAU;MACzBgM,KAAA,CAAMjD,KAAA,GAAQA,KAAA,CAAM/I,QAAA;MACpBgM,KAAA,CAAM/C,MAAA,GAASA,MAAA,CAAOjJ,QAAA;IACxB,WAAW,KAAKgN,OAAA,CAAQlN,GAAA,EAAK;MAC3BkM,KAAA,CAAMjD,KAAA,GAAQA,KAAA,CAAMjJ,GAAA;MACpB,IAAI,KAAKkN,OAAA,CAAQpN,MAAA,EAAQ;QACvBoM,KAAA,CAAM/C,MAAA,GAASA,MAAA,CAAOrJ,MAAA;MACxB,OAAO;QACLoM,KAAA,CAAM/C,MAAA,GAASA,MAAA,CAAOnJ,GAAA;MACxB;IACF;IACA,KAAKK,SAAA,CAAU6L,KAAA,GAAQA,KAAA;EACzB;EAAA;AAAA;AAAA;EAKA,WAAWA,MAAA,EAAQ;IACjB,OAAO;MACLjD,KAAA;MACAE;IACF;EACF;EAAA;AAAA;AAAA;EAKA,OAAOyJ,IAAIrF,GAAA,EAAaF,QAAA,EAAyB;IAC/C,MAAMpB,MAAA,GAAQ,IAAIuG,OAAA,CAAOnF,QAAO;IAChC,OAAOpB,MAAA,CAAM2G,GAAA,CAAIrF,GAAG;EACtB;EAAA;AAAA;AAAA;EAKA,OAAOsF,UAAUtF,GAAA,EAAaF,QAAA,EAAyB;IACrD,MAAMpB,MAAA,GAAQ,IAAIuG,OAAA,CAAOnF,QAAO;IAChC,OAAOpB,MAAA,CAAMQ,YAAA,CAAac,GAAG;EAC/B;EAAA;AAAA;AAAA;EAKAqF,IAAIrF,GAAA,EAAa;IACfA,GAAA,GAAMA,GAAA,CAAItM,OAAA,CAAQI,KAAA,CAAMiD,cAAA,EAAgB,IAAI;IAE5C,KAAK4J,WAAA,CAAYX,GAAA,EAAK,KAAKf,MAAM;IAEjC,SAAS/B,CAAA,GAAI,GAAGA,CAAA,GAAI,KAAKgI,WAAA,CAAY7H,MAAA,EAAQH,CAAA,IAAK;MAChD,MAAMqI,IAAA,GAAO,KAAKL,WAAA,CAAYhI,CAAC;MAC/B,KAAKgC,YAAA,CAAaqG,IAAA,CAAKvF,GAAA,EAAKuF,IAAA,CAAKtG,MAAM;IACzC;IACA,KAAKiG,WAAA,GAAc,EAAC;IAEpB,OAAO,KAAKjG,MAAA;EACd;EAOA0B,YAAYX,GAAA,EAAaf,MAAA,GAAkB,EAAC,EAAGuG,oBAAA,GAAuB,OAAO;IAC3E,IAAI,KAAK7F,OAAA,CAAQhN,QAAA,EAAU;MACzBqN,GAAA,GAAMA,GAAA,CAAItM,OAAA,CAAQI,KAAA,CAAMa,aAAA,EAAe,MAAM,EAAEjB,OAAA,CAAQI,KAAA,CAAMkD,SAAA,EAAW,EAAE;IAC5E;IAEA,OAAOgJ,GAAA,EAAK;MACV,IAAIjB,KAAA;MAEJ,IAAI,KAAKY,OAAA,CAAQnN,UAAA,EAAYkJ,KAAA,EAAOkH,IAAA,CAAM6C,YAAA,IAAiB;QACzD,IAAI1G,KAAA,GAAQ0G,YAAA,CAAaC,IAAA,CAAK;UAAE9F,KAAA,EAAO;QAAK,GAAGI,GAAA,EAAKf,MAAM,GAAG;UAC3De,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;UACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;UACjB,OAAO;QACT;QACA,OAAO;MACT,CAAC,GAAG;QACF;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUiN,KAAA,CAAMC,GAAG,GAAG;QACrCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC,MAAMuD,SAAA,GAAY3B,MAAA,CAAO3B,EAAA,CAAG,EAAE;QAC9B,IAAIyB,KAAA,CAAMN,GAAA,CAAIpB,MAAA,KAAW,KAAKuD,SAAA,KAAc,QAAW;UAGrDA,SAAA,CAAUnC,GAAA,IAAO;QACnB,OAAO;UACLQ,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACnB;QACA;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUmG,IAAA,CAAK+G,GAAG,GAAG;QACpCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC,MAAMuD,SAAA,GAAY3B,MAAA,CAAO3B,EAAA,CAAG,EAAE;QAE9B,IAAIsD,SAAA,EAAW5B,IAAA,KAAS,eAAe4B,SAAA,EAAW5B,IAAA,KAAS,QAAQ;UACjE4B,SAAA,CAAUnC,GAAA,IAAO,OAAOM,KAAA,CAAMN,GAAA;UAC9BmC,SAAA,CAAUzH,IAAA,IAAQ,OAAO4F,KAAA,CAAM5F,IAAA;UAC/B,KAAK+L,WAAA,CAAY5H,EAAA,CAAG,EAAE,EAAG0C,GAAA,GAAMY,SAAA,CAAUzH,IAAA;QAC3C,OAAO;UACL8F,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACnB;QACA;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUiF,MAAA,CAAOiI,GAAG,GAAG;QACtCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUmF,OAAA,CAAQ+H,GAAG,GAAG;QACvCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUkF,EAAA,CAAGgI,GAAG,GAAG;QAClCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUiG,UAAA,CAAWiH,GAAG,GAAG;QAC1CA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAU4F,IAAA,CAAKsH,GAAG,GAAG;QACpCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAU+F,IAAA,CAAKmH,GAAG,GAAG;QACpCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAU2F,GAAA,CAAIuH,GAAG,GAAG;QACnCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC,MAAMuD,SAAA,GAAY3B,MAAA,CAAO3B,EAAA,CAAG,EAAE;QAC9B,IAAIsD,SAAA,EAAW5B,IAAA,KAAS,eAAe4B,SAAA,EAAW5B,IAAA,KAAS,QAAQ;UACjE4B,SAAA,CAAUnC,GAAA,IAAO,OAAOM,KAAA,CAAMN,GAAA;UAC9BmC,SAAA,CAAUzH,IAAA,IAAQ,OAAO4F,KAAA,CAAMN,GAAA;UAC/B,KAAKyG,WAAA,CAAY5H,EAAA,CAAG,EAAE,EAAG0C,GAAA,GAAMY,SAAA,CAAUzH,IAAA;QAC3C,WAAW,CAAC,KAAK8F,MAAA,CAAO2E,KAAA,CAAM7E,KAAA,CAAMlE,GAAG,GAAG;UACxC,KAAKoE,MAAA,CAAO2E,KAAA,CAAM7E,KAAA,CAAMlE,GAAG,IAAI;YAC7BwB,IAAA,EAAM0C,KAAA,CAAM1C,IAAA;YACZuC,KAAA,EAAOG,KAAA,CAAMH;UACf;QACF;QACA;MACF;MAGA,IAAIG,KAAA,GAAQ,KAAKjM,SAAA,CAAUoG,KAAA,CAAM8G,GAAG,GAAG;QACrCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUsF,QAAA,CAAS4H,GAAG,GAAG;QACxCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAIA,IAAI4G,MAAA,GAAS3F,GAAA;MACb,IAAI,KAAKL,OAAA,CAAQnN,UAAA,EAAYoT,UAAA,EAAY;QACvC,IAAIC,UAAA,GAAaC,QAAA;QACjB,MAAMC,OAAA,GAAU/F,GAAA,CAAI/B,KAAA,CAAM,CAAC;QAC3B,IAAI+H,SAAA;QACJ,KAAKrG,OAAA,CAAQnN,UAAA,CAAWoT,UAAA,CAAWK,OAAA,CAASC,aAAA,IAAkB;UAC5DF,SAAA,GAAYE,aAAA,CAAcR,IAAA,CAAK;YAAE9F,KAAA,EAAO;UAAK,GAAGmG,OAAO;UACvD,IAAI,OAAOC,SAAA,KAAc,YAAYA,SAAA,IAAa,GAAG;YACnDH,UAAA,GAAatO,IAAA,CAAKC,GAAA,CAAIqO,UAAA,EAAYG,SAAS;UAC7C;QACF,CAAC;QACD,IAAIH,UAAA,GAAaC,QAAA,IAAYD,UAAA,IAAc,GAAG;UAC5CF,MAAA,GAAS3F,GAAA,CAAIgB,SAAA,CAAU,GAAG6E,UAAA,GAAa,CAAC;QAC1C;MACF;MACA,IAAI,KAAKhH,KAAA,CAAM6B,GAAA,KAAQ3B,KAAA,GAAQ,KAAKjM,SAAA,CAAUgG,SAAA,CAAU6M,MAAM,IAAI;QAChE,MAAM/E,SAAA,GAAY3B,MAAA,CAAO3B,EAAA,CAAG,EAAE;QAC9B,IAAIkI,oBAAA,IAAwB5E,SAAA,EAAW5B,IAAA,KAAS,aAAa;UAC3D4B,SAAA,CAAUnC,GAAA,IAAO,OAAOM,KAAA,CAAMN,GAAA;UAC9BmC,SAAA,CAAUzH,IAAA,IAAQ,OAAO4F,KAAA,CAAM5F,IAAA;UAC/B,KAAK+L,WAAA,CAAY3H,GAAA,CAAI;UACrB,KAAK2H,WAAA,CAAY5H,EAAA,CAAG,EAAE,EAAG0C,GAAA,GAAMY,SAAA,CAAUzH,IAAA;QAC3C,OAAO;UACL8F,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACnB;QACAyG,oBAAA,GAAuBG,MAAA,CAAOtI,MAAA,KAAW2C,GAAA,CAAI3C,MAAA;QAC7C2C,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC;MACF;MAGA,IAAI0B,KAAA,GAAQ,KAAKjM,SAAA,CAAUqG,IAAA,CAAK6G,GAAG,GAAG;QACpCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC,MAAMuD,SAAA,GAAY3B,MAAA,CAAO3B,EAAA,CAAG,EAAE;QAC9B,IAAIsD,SAAA,EAAW5B,IAAA,KAAS,QAAQ;UAC9B4B,SAAA,CAAUnC,GAAA,IAAO,OAAOM,KAAA,CAAMN,GAAA;UAC9BmC,SAAA,CAAUzH,IAAA,IAAQ,OAAO4F,KAAA,CAAM5F,IAAA;UAC/B,KAAK+L,WAAA,CAAY3H,GAAA,CAAI;UACrB,KAAK2H,WAAA,CAAY5H,EAAA,CAAG,EAAE,EAAG0C,GAAA,GAAMY,SAAA,CAAUzH,IAAA;QAC3C,OAAO;UACL8F,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACnB;QACA;MACF;MAEA,IAAIiB,GAAA,EAAK;QACP,MAAMmG,MAAA,GAAS,4BAA4BnG,GAAA,CAAIoG,UAAA,CAAW,CAAC;QAC3D,IAAI,KAAKzG,OAAA,CAAQ9M,MAAA,EAAQ;UACvBwT,OAAA,CAAQC,KAAA,CAAMH,MAAM;UACpB;QACF,OAAO;UACL,MAAM,IAAII,KAAA,CAAMJ,MAAM;QACxB;MACF;IACF;IAEA,KAAKtH,KAAA,CAAM6B,GAAA,GAAM;IACjB,OAAOzB,MAAA;EACT;EAEArD,OAAOoE,GAAA,EAAaf,MAAA,GAAkB,EAAC,EAAG;IACxC,KAAKiG,WAAA,CAAYzH,IAAA,CAAK;MAAEuC,GAAA;MAAKf;IAAO,CAAC;IACrC,OAAOA,MAAA;EACT;EAAA;AAAA;AAAA;EAKAC,aAAac,GAAA,EAAaf,MAAA,GAAkB,EAAC,EAAY;IAEvD,IAAI8E,SAAA,GAAY/D,GAAA;IAChB,IAAIrD,KAAA,GAAgC;IAGpC,IAAI,KAAKsC,MAAA,CAAO2E,KAAA,EAAO;MACrB,MAAMA,KAAA,GAAQuB,MAAA,CAAOqB,IAAA,CAAK,KAAKvH,MAAA,CAAO2E,KAAK;MAC3C,IAAIA,KAAA,CAAMvG,MAAA,GAAS,GAAG;QACpB,QAAQV,KAAA,GAAQ,KAAK7J,SAAA,CAAU6L,KAAA,CAAM/C,MAAA,CAAOV,aAAA,CAAc9H,IAAA,CAAK2Q,SAAS,MAAM,MAAM;UAClF,IAAIH,KAAA,CAAM6C,QAAA,CAAS9J,KAAA,CAAM,CAAC,EAAEsB,KAAA,CAAMtB,KAAA,CAAM,CAAC,EAAE+J,WAAA,CAAY,GAAG,IAAI,GAAG,EAAE,CAAC,GAAG;YACrE3C,SAAA,GAAYA,SAAA,CAAU9F,KAAA,CAAM,GAAGtB,KAAA,CAAM+H,KAAK,IACtC,MAAM,IAAI7C,MAAA,CAAOlF,KAAA,CAAM,CAAC,EAAEU,MAAA,GAAS,CAAC,IAAI,MACxC0G,SAAA,CAAU9F,KAAA,CAAM,KAAKnL,SAAA,CAAU6L,KAAA,CAAM/C,MAAA,CAAOV,aAAA,CAAcsJ,SAAS;UACzE;QACF;MACF;IACF;IAGA,QAAQ7H,KAAA,GAAQ,KAAK7J,SAAA,CAAU6L,KAAA,CAAM/C,MAAA,CAAOlB,cAAA,CAAetH,IAAA,CAAK2Q,SAAS,MAAM,MAAM;MACnFA,SAAA,GAAYA,SAAA,CAAU9F,KAAA,CAAM,GAAGtB,KAAA,CAAM+H,KAAK,IAAI,OAAOX,SAAA,CAAU9F,KAAA,CAAM,KAAKnL,SAAA,CAAU6L,KAAA,CAAM/C,MAAA,CAAOlB,cAAA,CAAe8J,SAAS;IAC3H;IAGA,QAAQ7H,KAAA,GAAQ,KAAK7J,SAAA,CAAU6L,KAAA,CAAM/C,MAAA,CAAO1B,SAAA,CAAU9G,IAAA,CAAK2Q,SAAS,MAAM,MAAM;MAC9EA,SAAA,GAAYA,SAAA,CAAU9F,KAAA,CAAM,GAAGtB,KAAA,CAAM+H,KAAK,IAAI,MAAM,IAAI7C,MAAA,CAAOlF,KAAA,CAAM,CAAC,EAAEU,MAAA,GAAS,CAAC,IAAI,MAAM0G,SAAA,CAAU9F,KAAA,CAAM,KAAKnL,SAAA,CAAU6L,KAAA,CAAM/C,MAAA,CAAO1B,SAAA,CAAUsK,SAAS;IAC7J;IAEA,IAAImC,YAAA,GAAe;IACnB,IAAI3C,QAAA,GAAW;IACf,OAAOhE,GAAA,EAAK;MACV,IAAI,CAAC2G,YAAA,EAAc;QACjB3C,QAAA,GAAW;MACb;MACA2C,YAAA,GAAe;MAEf,IAAI5H,KAAA;MAGJ,IAAI,KAAKY,OAAA,CAAQnN,UAAA,EAAYoJ,MAAA,EAAQgH,IAAA,CAAM6C,YAAA,IAAiB;QAC1D,IAAI1G,KAAA,GAAQ0G,YAAA,CAAaC,IAAA,CAAK;UAAE9F,KAAA,EAAO;QAAK,GAAGI,GAAA,EAAKf,MAAM,GAAG;UAC3De,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;UACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;UACjB,OAAO;QACT;QACA,OAAO;MACT,CAAC,GAAG;QACF;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUyG,MAAA,CAAOyG,GAAG,GAAG;QACtCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAU+H,GAAA,CAAImF,GAAG,GAAG;QACnCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUiI,IAAA,CAAKiF,GAAG,GAAG;QACpCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUkI,OAAA,CAAQgF,GAAA,EAAK,KAAKf,MAAA,CAAO2E,KAAK,GAAG;QAC1D5D,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC,MAAMuD,SAAA,GAAY3B,MAAA,CAAO3B,EAAA,CAAG,EAAE;QAC9B,IAAIyB,KAAA,CAAMC,IAAA,KAAS,UAAU4B,SAAA,EAAW5B,IAAA,KAAS,QAAQ;UACvD4B,SAAA,CAAUnC,GAAA,IAAOM,KAAA,CAAMN,GAAA;UACvBmC,SAAA,CAAUzH,IAAA,IAAQ4F,KAAA,CAAM5F,IAAA;QAC1B,OAAO;UACL8F,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACnB;QACA;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUgR,QAAA,CAAS9D,GAAA,EAAK+D,SAAA,EAAWC,QAAQ,GAAG;QAC7DhE,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAU8R,QAAA,CAAS5E,GAAG,GAAG;QACxCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAU2G,EAAA,CAAGuG,GAAG,GAAG;QAClCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUuI,GAAA,CAAI2E,GAAG,GAAG;QACnCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAU6H,QAAA,CAASqF,GAAG,GAAG;QACxCA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAI,CAAC,KAAKF,KAAA,CAAMC,MAAA,KAAWC,KAAA,GAAQ,KAAKjM,SAAA,CAAUwI,GAAA,CAAI0E,GAAG,IAAI;QAC3DA,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAIA,IAAI4G,MAAA,GAAS3F,GAAA;MACb,IAAI,KAAKL,OAAA,CAAQnN,UAAA,EAAYoU,WAAA,EAAa;QACxC,IAAIf,UAAA,GAAaC,QAAA;QACjB,MAAMC,OAAA,GAAU/F,GAAA,CAAI/B,KAAA,CAAM,CAAC;QAC3B,IAAI+H,SAAA;QACJ,KAAKrG,OAAA,CAAQnN,UAAA,CAAWoU,WAAA,CAAYX,OAAA,CAASC,aAAA,IAAkB;UAC7DF,SAAA,GAAYE,aAAA,CAAcR,IAAA,CAAK;YAAE9F,KAAA,EAAO;UAAK,GAAGmG,OAAO;UACvD,IAAI,OAAOC,SAAA,KAAc,YAAYA,SAAA,IAAa,GAAG;YACnDH,UAAA,GAAatO,IAAA,CAAKC,GAAA,CAAIqO,UAAA,EAAYG,SAAS;UAC7C;QACF,CAAC;QACD,IAAIH,UAAA,GAAaC,QAAA,IAAYD,UAAA,IAAc,GAAG;UAC5CF,MAAA,GAAS3F,GAAA,CAAIgB,SAAA,CAAU,GAAG6E,UAAA,GAAa,CAAC;QAC1C;MACF;MACA,IAAI9G,KAAA,GAAQ,KAAKjM,SAAA,CAAU4G,UAAA,CAAWiM,MAAM,GAAG;QAC7C3F,GAAA,GAAMA,GAAA,CAAIgB,SAAA,CAAUjC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC,IAAI0B,KAAA,CAAMN,GAAA,CAAIR,KAAA,CAAM,EAAE,MAAM,KAAK;UAC/B+F,QAAA,GAAWjF,KAAA,CAAMN,GAAA,CAAIR,KAAA,CAAM,EAAE;QAC/B;QACA0I,YAAA,GAAe;QACf,MAAM/F,SAAA,GAAY3B,MAAA,CAAO3B,EAAA,CAAG,EAAE;QAC9B,IAAIsD,SAAA,EAAW5B,IAAA,KAAS,QAAQ;UAC9B4B,SAAA,CAAUnC,GAAA,IAAOM,KAAA,CAAMN,GAAA;UACvBmC,SAAA,CAAUzH,IAAA,IAAQ4F,KAAA,CAAM5F,IAAA;QAC1B,OAAO;UACL8F,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACnB;QACA;MACF;MAEA,IAAIiB,GAAA,EAAK;QACP,MAAMmG,MAAA,GAAS,4BAA4BnG,GAAA,CAAIoG,UAAA,CAAW,CAAC;QAC3D,IAAI,KAAKzG,OAAA,CAAQ9M,MAAA,EAAQ;UACvBwT,OAAA,CAAQC,KAAA,CAAMH,MAAM;UACpB;QACF,OAAO;UACL,MAAM,IAAII,KAAA,CAAMJ,MAAM;QACxB;MACF;IACF;IAEA,OAAOlH,MAAA;EACT;AACF;;;ACxcO,IAAM4H,SAAA,GAAN,MAAgB;EACrBlH,OAAA;EACAmH,MAAA;EAAA;EACAjH,YAAYC,QAAA,EAAyB;IACnC,KAAKH,OAAA,GAAUG,QAAA,IAAW9M,SAAA;EAC5B;EAEA+M,MAAMhB,KAAA,EAA6B;IACjC,OAAO;EACT;EAEA9F,KAAK;IAAEE,IAAA;IAAM+G,IAAA;IAAMpD;EAAQ,GAAwB;IACjD,MAAMiK,UAAA,IAAc7G,IAAA,IAAQ,IAAIvD,KAAA,CAAM7I,KAAA,CAAMmD,aAAa,IAAI,CAAC;IAE9D,MAAMgC,IAAA,GAAOE,IAAA,CAAKzF,OAAA,CAAQI,KAAA,CAAMoD,aAAA,EAAe,EAAE,IAAI;IAErD,IAAI,CAAC6P,UAAA,EAAY;MACf,OAAO,iBACFjK,OAAA,GAAU7D,IAAA,GAAO+C,OAAA,CAAO/C,IAAA,EAAM,IAAI,KACnC;IACN;IAEA,OAAO,gCACH+C,OAAA,CAAO+K,UAAU,IACjB,QACCjK,OAAA,GAAU7D,IAAA,GAAO+C,OAAA,CAAO/C,IAAA,EAAM,IAAI,KACnC;EACN;EAEAF,WAAW;IAAEkG;EAAO,GAA8B;IAChD,MAAM+H,IAAA,GAAO,KAAKF,MAAA,CAAOG,KAAA,CAAMhI,MAAM;IACrC,OAAO;AAAA,EAAiB+H,IAAI;AAAA;EAC9B;EAEAnO,KAAK;IAAEM;EAAK,GAAsC;IAChD,OAAOA,IAAA;EACT;EAEAlB,QAAQ;IAAEgH,MAAA;IAAQmB;EAAM,GAA2B;IACjD,OAAO,KAAKA,KAAK,IAAI,KAAK0G,MAAA,CAAOI,WAAA,CAAYjI,MAAM,CAAC,MAAMmB,KAAK;AAAA;EACjE;EAEApI,GAAG+G,KAAA,EAA0B;IAC3B,OAAO;EACT;EAEArG,KAAKqG,KAAA,EAA4B;IAC/B,MAAMoC,OAAA,GAAUpC,KAAA,CAAMoC,OAAA;IACtB,MAAMC,KAAA,GAAQrC,KAAA,CAAMqC,KAAA;IAEpB,IAAI4F,IAAA,GAAO;IACX,SAASG,CAAA,GAAI,GAAGA,CAAA,GAAIpI,KAAA,CAAMuC,KAAA,CAAMjE,MAAA,EAAQ8J,CAAA,IAAK;MAC3C,MAAMhE,IAAA,GAAOpE,KAAA,CAAMuC,KAAA,CAAM6F,CAAC;MAC1BH,IAAA,IAAQ,KAAKI,QAAA,CAASjE,IAAI;IAC5B;IAEA,MAAMnE,IAAA,GAAOmC,OAAA,GAAU,OAAO;IAC9B,MAAMkG,SAAA,GAAalG,OAAA,IAAWC,KAAA,KAAU,IAAM,aAAaA,KAAA,GAAQ,MAAO;IAC1E,OAAO,MAAMpC,IAAA,GAAOqI,SAAA,GAAY,QAAQL,IAAA,GAAO,OAAOhI,IAAA,GAAO;EAC/D;EAEAoI,SAASjE,IAAA,EAA+B;IACtC,IAAImE,QAAA,GAAW;IACf,IAAInE,IAAA,CAAKd,IAAA,EAAM;MACb,MAAMkF,QAAA,GAAW,KAAKA,QAAA,CAAS;QAAEjF,OAAA,EAAS,CAAC,CAACa,IAAA,CAAKb;MAAQ,CAAC;MAC1D,IAAIa,IAAA,CAAK9B,KAAA,EAAO;QACd,IAAI8B,IAAA,CAAKlE,MAAA,CAAO,CAAC,GAAGD,IAAA,KAAS,aAAa;UACxCmE,IAAA,CAAKlE,MAAA,CAAO,CAAC,EAAE9F,IAAA,GAAOoO,QAAA,GAAW,MAAMpE,IAAA,CAAKlE,MAAA,CAAO,CAAC,EAAE9F,IAAA;UACtD,IAAIgK,IAAA,CAAKlE,MAAA,CAAO,CAAC,EAAEA,MAAA,IAAUkE,IAAA,CAAKlE,MAAA,CAAO,CAAC,EAAEA,MAAA,CAAO5B,MAAA,GAAS,KAAK8F,IAAA,CAAKlE,MAAA,CAAO,CAAC,EAAEA,MAAA,CAAO,CAAC,EAAED,IAAA,KAAS,QAAQ;YACzGmE,IAAA,CAAKlE,MAAA,CAAO,CAAC,EAAEA,MAAA,CAAO,CAAC,EAAE9F,IAAA,GAAOoO,QAAA,GAAW,MAAMvL,OAAA,CAAOmH,IAAA,CAAKlE,MAAA,CAAO,CAAC,EAAEA,MAAA,CAAO,CAAC,EAAE9F,IAAI;YACrFgK,IAAA,CAAKlE,MAAA,CAAO,CAAC,EAAEA,MAAA,CAAO,CAAC,EAAEnC,OAAA,GAAU;UACrC;QACF,OAAO;UACLqG,IAAA,CAAKlE,MAAA,CAAOuI,OAAA,CAAQ;YAClBxI,IAAA,EAAM;YACNP,GAAA,EAAK8I,QAAA,GAAW;YAChBpO,IAAA,EAAMoO,QAAA,GAAW;YACjBzK,OAAA,EAAS;UACX,CAAC;QACH;MACF,OAAO;QACLwK,QAAA,IAAYC,QAAA,GAAW;MACzB;IACF;IAEAD,QAAA,IAAY,KAAKR,MAAA,CAAOG,KAAA,CAAM9D,IAAA,CAAKlE,MAAA,EAAQ,CAAC,CAACkE,IAAA,CAAK9B,KAAK;IAEvD,OAAO,OAAOiG,QAAQ;AAAA;EACxB;EAEAC,SAAS;IAAEjF;EAAQ,GAA4B;IAC7C,OAAO,aACFA,OAAA,GAAU,gBAAgB,MAC3B;EACN;EAEAxJ,UAAU;IAAEmG;EAAO,GAA6B;IAC9C,OAAO,MAAM,KAAK6H,MAAA,CAAOI,WAAA,CAAYjI,MAAM,CAAC;AAAA;EAC9C;EAEA/F,MAAM6F,KAAA,EAA6B;IACjC,IAAIqE,MAAA,GAAS;IAGb,IAAIE,IAAA,GAAO;IACX,SAAS6D,CAAA,GAAI,GAAGA,CAAA,GAAIpI,KAAA,CAAMqE,MAAA,CAAO/F,MAAA,EAAQ8J,CAAA,IAAK;MAC5C7D,IAAA,IAAQ,KAAKmE,SAAA,CAAU1I,KAAA,CAAMqE,MAAA,CAAO+D,CAAC,CAAC;IACxC;IACA/D,MAAA,IAAU,KAAKsE,QAAA,CAAS;MAAEvO,IAAA,EAAMmK;IAAK,CAAC;IAEtC,IAAI0D,IAAA,GAAO;IACX,SAASG,CAAA,GAAI,GAAGA,CAAA,GAAIpI,KAAA,CAAMmE,IAAA,CAAK7F,MAAA,EAAQ8J,CAAA,IAAK;MAC1C,MAAMzK,GAAA,GAAMqC,KAAA,CAAMmE,IAAA,CAAKiE,CAAC;MAExB7D,IAAA,GAAO;MACP,SAASqE,CAAA,GAAI,GAAGA,CAAA,GAAIjL,GAAA,CAAIW,MAAA,EAAQsK,CAAA,IAAK;QACnCrE,IAAA,IAAQ,KAAKmE,SAAA,CAAU/K,GAAA,CAAIiL,CAAC,CAAC;MAC/B;MAEAX,IAAA,IAAQ,KAAKU,QAAA,CAAS;QAAEvO,IAAA,EAAMmK;MAAK,CAAC;IACtC;IACA,IAAI0D,IAAA,EAAMA,IAAA,GAAO,UAAUA,IAAI;IAE/B,OAAO,uBAEH5D,MAAA,GACA,eACA4D,IAAA,GACA;EACN;EAEAU,SAAS;IAAEvO;EAAK,GAA4B;IAC1C,OAAO;AAAA,EAASA,IAAI;AAAA;EACtB;EAEAsO,UAAU1I,KAAA,EAAiC;IACzC,MAAM6I,OAAA,GAAU,KAAKd,MAAA,CAAOI,WAAA,CAAYnI,KAAA,CAAME,MAAM;IACpD,MAAMD,IAAA,GAAOD,KAAA,CAAMqE,MAAA,GAAS,OAAO;IACnC,MAAMN,IAAA,GAAM/D,KAAA,CAAMsE,KAAA,GACd,IAAIrE,IAAI,WAAWD,KAAA,CAAMsE,KAAK,OAC9B,IAAIrE,IAAI;IACZ,OAAO8D,IAAA,GAAM8E,OAAA,GAAU,KAAK5I,IAAI;AAAA;EAClC;EAAA;AAAA;AAAA;EAKA6I,OAAO;IAAE5I;EAAO,GAA0B;IACxC,OAAO,WAAW,KAAK6H,MAAA,CAAOI,WAAA,CAAYjI,MAAM,CAAC;EACnD;EAEA6I,GAAG;IAAE7I;EAAO,GAAsB;IAChC,OAAO,OAAO,KAAK6H,MAAA,CAAOI,WAAA,CAAYjI,MAAM,CAAC;EAC/C;EAEA2F,SAAS;IAAEzL;EAAK,GAA4B;IAC1C,OAAO,SAAS6C,OAAA,CAAO7C,IAAA,EAAM,IAAI,CAAC;EACpC;EAEAM,GAAGsF,KAAA,EAA0B;IAC3B,OAAO;EACT;EAEA1D,IAAI;IAAE4D;EAAO,GAAuB;IAClC,OAAO,QAAQ,KAAK6H,MAAA,CAAOI,WAAA,CAAYjI,MAAM,CAAC;EAChD;EAEAlE,KAAK;IAAEsB,IAAA;IAAMuC,KAAA;IAAOK;EAAO,GAAwB;IACjD,MAAM9F,IAAA,GAAO,KAAK2N,MAAA,CAAOI,WAAA,CAAYjI,MAAM;IAC3C,MAAM8I,SAAA,GAAY3L,QAAA,CAASC,IAAI;IAC/B,IAAI0L,SAAA,KAAc,MAAM;MACtB,OAAO5O,IAAA;IACT;IACAkD,IAAA,GAAO0L,SAAA;IACP,IAAIC,GAAA,GAAM,cAAc3L,IAAA,GAAO;IAC/B,IAAIuC,KAAA,EAAO;MACToJ,GAAA,IAAO,aAAchM,OAAA,CAAO4C,KAAK,IAAK;IACxC;IACAoJ,GAAA,IAAO,MAAM7O,IAAA,GAAO;IACpB,OAAO6O,GAAA;EACT;EAEAC,MAAM;IAAE5L,IAAA;IAAMuC,KAAA;IAAOzF,IAAA;IAAM8F;EAAO,GAAyB;IACzD,IAAIA,MAAA,EAAQ;MACV9F,IAAA,GAAO,KAAK2N,MAAA,CAAOI,WAAA,CAAYjI,MAAA,EAAQ,KAAK6H,MAAA,CAAOoB,YAAY;IACjE;IACA,MAAMH,SAAA,GAAY3L,QAAA,CAASC,IAAI;IAC/B,IAAI0L,SAAA,KAAc,MAAM;MACtB,OAAO/L,OAAA,CAAO7C,IAAI;IACpB;IACAkD,IAAA,GAAO0L,SAAA;IAEP,IAAIC,GAAA,GAAM,aAAa3L,IAAI,UAAUlD,IAAI;IACzC,IAAIyF,KAAA,EAAO;MACToJ,GAAA,IAAO,WAAWhM,OAAA,CAAO4C,KAAK,CAAC;IACjC;IACAoJ,GAAA,IAAO;IACP,OAAOA,GAAA;EACT;EAEA7O,KAAK4F,KAAA,EAA6C;IAChD,OAAO,YAAYA,KAAA,IAASA,KAAA,CAAME,MAAA,GAC9B,KAAK6H,MAAA,CAAOI,WAAA,CAAYnI,KAAA,CAAME,MAAM,IACnC,aAAaF,KAAA,IAASA,KAAA,CAAMjC,OAAA,GAAUiC,KAAA,CAAM5F,IAAA,GAAO6C,OAAA,CAAO+C,KAAA,CAAM5F,IAAI;EAC3E;AACF;;;ACpNO,IAAMgP,aAAA,GAAN,MAAoB;EAAA;EAEzBN,OAAO;IAAE1O;EAAK,GAAkB;IAC9B,OAAOA,IAAA;EACT;EAEA2O,GAAG;IAAE3O;EAAK,GAAc;IACtB,OAAOA,IAAA;EACT;EAEAyL,SAAS;IAAEzL;EAAK,GAAoB;IAClC,OAAOA,IAAA;EACT;EAEAkC,IAAI;IAAElC;EAAK,GAAe;IACxB,OAAOA,IAAA;EACT;EAEAN,KAAK;IAAEM;EAAK,GAA6B;IACvC,OAAOA,IAAA;EACT;EAEAA,KAAK;IAAEA;EAAK,GAA6C;IACvD,OAAOA,IAAA;EACT;EAEA4B,KAAK;IAAE5B;EAAK,GAAgB;IAC1B,OAAO,KAAKA,IAAA;EACd;EAEA8O,MAAM;IAAE9O;EAAK,GAAiB;IAC5B,OAAO,KAAKA,IAAA;EACd;EAEAM,GAAA,EAAK;IACH,OAAO;EACT;AACF;;;AClCO,IAAM2O,OAAA,GAAN,MAAMC,QAAA,CAAQ;EACnB1I,OAAA;EACA/M,QAAA;EACAsV,YAAA;EACArI,YAAYC,QAAA,EAAyB;IACnC,KAAKH,OAAA,GAAUG,QAAA,IAAW9M,SAAA;IAC1B,KAAK2M,OAAA,CAAQ/M,QAAA,GAAW,KAAK+M,OAAA,CAAQ/M,QAAA,IAAY,IAAIiU,SAAA,CAAU;IAC/D,KAAKjU,QAAA,GAAW,KAAK+M,OAAA,CAAQ/M,QAAA;IAC7B,KAAKA,QAAA,CAAS+M,OAAA,GAAU,KAAKA,OAAA;IAC7B,KAAK/M,QAAA,CAASkU,MAAA,GAAS;IACvB,KAAKoB,YAAA,GAAe,IAAIC,aAAA,CAAc;EACxC;EAAA;AAAA;AAAA;EAKA,OAAOlB,MAAMhI,MAAA,EAAiBa,QAAA,EAAyB;IACrD,MAAMwI,OAAA,GAAS,IAAID,QAAA,CAAQvI,QAAO;IAClC,OAAOwI,OAAA,CAAOrB,KAAA,CAAMhI,MAAM;EAC5B;EAAA;AAAA;AAAA;EAKA,OAAOiI,YAAYjI,MAAA,EAAiBa,QAAA,EAAyB;IAC3D,MAAMwI,OAAA,GAAS,IAAID,QAAA,CAAQvI,QAAO;IAClC,OAAOwI,OAAA,CAAOpB,WAAA,CAAYjI,MAAM;EAClC;EAAA;AAAA;AAAA;EAKAgI,MAAMhI,MAAA,EAAiByB,GAAA,GAAM,MAAc;IACzC,IAAIsH,GAAA,GAAM;IAEV,SAAS9K,CAAA,GAAI,GAAGA,CAAA,GAAI+B,MAAA,CAAO5B,MAAA,EAAQH,CAAA,IAAK;MACtC,MAAMqL,QAAA,GAAWtJ,MAAA,CAAO/B,CAAC;MAGzB,IAAI,KAAKyC,OAAA,CAAQnN,UAAA,EAAYgW,SAAA,GAAYD,QAAA,CAASvJ,IAAI,GAAG;QACvD,MAAMyJ,YAAA,GAAeF,QAAA;QACrB,MAAMG,GAAA,GAAM,KAAK/I,OAAA,CAAQnN,UAAA,CAAWgW,SAAA,CAAUC,YAAA,CAAazJ,IAAI,EAAE0G,IAAA,CAAK;UAAEoB,MAAA,EAAQ;QAAK,GAAG2B,YAAY;QACpG,IAAIC,GAAA,KAAQ,SAAS,CAAC,CAAC,SAAS,MAAM,WAAW,QAAQ,SAAS,cAAc,QAAQ,QAAQ,aAAa,MAAM,EAAEjC,QAAA,CAASgC,YAAA,CAAazJ,IAAI,GAAG;UAChJgJ,GAAA,IAAOU,GAAA,IAAO;UACd;QACF;MACF;MAEA,MAAM3J,KAAA,GAAQwJ,QAAA;MAEd,QAAQxJ,KAAA,CAAMC,IAAA;QACZ,KAAK;UAAS;YACZgJ,GAAA,IAAO,KAAKpV,QAAA,CAASmN,KAAA,CAAMhB,KAAK;YAChC;UACF;QACA,KAAK;UAAM;YACTiJ,GAAA,IAAO,KAAKpV,QAAA,CAASoF,EAAA,CAAG+G,KAAK;YAC7B;UACF;QACA,KAAK;UAAW;YACdiJ,GAAA,IAAO,KAAKpV,QAAA,CAASqF,OAAA,CAAQ8G,KAAK;YAClC;UACF;QACA,KAAK;UAAQ;YACXiJ,GAAA,IAAO,KAAKpV,QAAA,CAASqG,IAAA,CAAK8F,KAAK;YAC/B;UACF;QACA,KAAK;UAAS;YACZiJ,GAAA,IAAO,KAAKpV,QAAA,CAASsG,KAAA,CAAM6F,KAAK;YAChC;UACF;QACA,KAAK;UAAc;YACjBiJ,GAAA,IAAO,KAAKpV,QAAA,CAASmG,UAAA,CAAWgG,KAAK;YACrC;UACF;QACA,KAAK;UAAQ;YACXiJ,GAAA,IAAO,KAAKpV,QAAA,CAAS8F,IAAA,CAAKqG,KAAK;YAC/B;UACF;QACA,KAAK;UAAQ;YACXiJ,GAAA,IAAO,KAAKpV,QAAA,CAASiG,IAAA,CAAKkG,KAAK;YAC/B;UACF;QACA,KAAK;UAAa;YAChBiJ,GAAA,IAAO,KAAKpV,QAAA,CAASkG,SAAA,CAAUiG,KAAK;YACpC;UACF;QACA,KAAK;UAAQ;YACX,IAAI4J,SAAA,GAAY5J,KAAA;YAChB,IAAIiI,IAAA,GAAO,KAAKpU,QAAA,CAASuG,IAAA,CAAKwP,SAAS;YACvC,OAAOzL,CAAA,GAAI,IAAI+B,MAAA,CAAO5B,MAAA,IAAU4B,MAAA,CAAO/B,CAAA,GAAI,CAAC,EAAE8B,IAAA,KAAS,QAAQ;cAC7D2J,SAAA,GAAY1J,MAAA,CAAO,EAAE/B,CAAC;cACtB8J,IAAA,IAAQ,OAAO,KAAKpU,QAAA,CAASuG,IAAA,CAAKwP,SAAS;YAC7C;YACA,IAAIjI,GAAA,EAAK;cACPsH,GAAA,IAAO,KAAKpV,QAAA,CAASkG,SAAA,CAAU;gBAC7BkG,IAAA,EAAM;gBACNP,GAAA,EAAKuI,IAAA;gBACL7N,IAAA,EAAM6N,IAAA;gBACN/H,MAAA,EAAQ,CAAC;kBAAED,IAAA,EAAM;kBAAQP,GAAA,EAAKuI,IAAA;kBAAM7N,IAAA,EAAM6N,IAAA;kBAAMlK,OAAA,EAAS;gBAAK,CAAC;cACjE,CAAC;YACH,OAAO;cACLkL,GAAA,IAAOhB,IAAA;YACT;YACA;UACF;QAEA;UAAS;YACP,MAAMb,MAAA,GAAS,iBAAiBpH,KAAA,CAAMC,IAAA,GAAO;YAC7C,IAAI,KAAKW,OAAA,CAAQ9M,MAAA,EAAQ;cACvBwT,OAAA,CAAQC,KAAA,CAAMH,MAAM;cACpB,OAAO;YACT,OAAO;cACL,MAAM,IAAII,KAAA,CAAMJ,MAAM;YACxB;UACF;MACF;IACF;IAEA,OAAO6B,GAAA;EACT;EAAA;AAAA;AAAA;EAKAd,YAAYjI,MAAA,EAAiBrM,QAAA,GAAsC,KAAKA,QAAA,EAAkB;IACxF,IAAIoV,GAAA,GAAM;IAEV,SAAS9K,CAAA,GAAI,GAAGA,CAAA,GAAI+B,MAAA,CAAO5B,MAAA,EAAQH,CAAA,IAAK;MACtC,MAAMqL,QAAA,GAAWtJ,MAAA,CAAO/B,CAAC;MAGzB,IAAI,KAAKyC,OAAA,CAAQnN,UAAA,EAAYgW,SAAA,GAAYD,QAAA,CAASvJ,IAAI,GAAG;QACvD,MAAM0J,GAAA,GAAM,KAAK/I,OAAA,CAAQnN,UAAA,CAAWgW,SAAA,CAAUD,QAAA,CAASvJ,IAAI,EAAE0G,IAAA,CAAK;UAAEoB,MAAA,EAAQ;QAAK,GAAGyB,QAAQ;QAC5F,IAAIG,GAAA,KAAQ,SAAS,CAAC,CAAC,UAAU,QAAQ,QAAQ,SAAS,UAAU,MAAM,YAAY,MAAM,OAAO,MAAM,EAAEjC,QAAA,CAAS8B,QAAA,CAASvJ,IAAI,GAAG;UAClIgJ,GAAA,IAAOU,GAAA,IAAO;UACd;QACF;MACF;MAEA,MAAM3J,KAAA,GAAQwJ,QAAA;MAEd,QAAQxJ,KAAA,CAAMC,IAAA;QACZ,KAAK;UAAU;YACbgJ,GAAA,IAAOpV,QAAA,CAASuG,IAAA,CAAK4F,KAAK;YAC1B;UACF;QACA,KAAK;UAAQ;YACXiJ,GAAA,IAAOpV,QAAA,CAASiG,IAAA,CAAKkG,KAAK;YAC1B;UACF;QACA,KAAK;UAAQ;YACXiJ,GAAA,IAAOpV,QAAA,CAASmI,IAAA,CAAKgE,KAAK;YAC1B;UACF;QACA,KAAK;UAAS;YACZiJ,GAAA,IAAOpV,QAAA,CAASqV,KAAA,CAAMlJ,KAAK;YAC3B;UACF;QACA,KAAK;UAAU;YACbiJ,GAAA,IAAOpV,QAAA,CAASiV,MAAA,CAAO9I,KAAK;YAC5B;UACF;QACA,KAAK;UAAM;YACTiJ,GAAA,IAAOpV,QAAA,CAASkV,EAAA,CAAG/I,KAAK;YACxB;UACF;QACA,KAAK;UAAY;YACfiJ,GAAA,IAAOpV,QAAA,CAASgS,QAAA,CAAS7F,KAAK;YAC9B;UACF;QACA,KAAK;UAAM;YACTiJ,GAAA,IAAOpV,QAAA,CAAS6G,EAAA,CAAGsF,KAAK;YACxB;UACF;QACA,KAAK;UAAO;YACViJ,GAAA,IAAOpV,QAAA,CAASyI,GAAA,CAAI0D,KAAK;YACzB;UACF;QACA,KAAK;UAAQ;YACXiJ,GAAA,IAAOpV,QAAA,CAASuG,IAAA,CAAK4F,KAAK;YAC1B;UACF;QACA;UAAS;YACP,MAAMoH,MAAA,GAAS,iBAAiBpH,KAAA,CAAMC,IAAA,GAAO;YAC7C,IAAI,KAAKW,OAAA,CAAQ9M,MAAA,EAAQ;cACvBwT,OAAA,CAAQC,KAAA,CAAMH,MAAM;cACpB,OAAO;YACT,OAAO;cACL,MAAM,IAAII,KAAA,CAAMJ,MAAM;YACxB;UACF;MACF;IACF;IACA,OAAO6B,GAAA;EACT;AACF;;;ACvMO,IAAMY,MAAA,GAAN,MAAa;EAClBjJ,OAAA;EACAjE,KAAA;EAEAmE,YAAYC,QAAA,EAAyB;IACnC,KAAKH,OAAA,GAAUG,QAAA,IAAW9M,SAAA;EAC5B;EAEA,OAAO6V,gBAAA,GAAmB,mBAAIC,GAAA,CAAI,CAChC,cACA,eACA,mBACD;EAAA;AAAA;AAAA;EAKDC,WAAWC,QAAA,EAAkB;IAC3B,OAAOA,QAAA;EACT;EAAA;AAAA;AAAA;EAKAC,YAAYhN,KAAA,EAAc;IACxB,OAAOA,KAAA;EACT;EAAA;AAAA;AAAA;EAKAiN,iBAAiBjK,MAAA,EAA8B;IAC7C,OAAOA,MAAA;EACT;EAAA;AAAA;AAAA;EAKAkK,aAAA,EAAe;IACb,OAAO,KAAKzN,KAAA,GAAQsJ,MAAA,CAAOK,GAAA,GAAML,MAAA,CAAOM,SAAA;EAC1C;EAAA;AAAA;AAAA;EAKA8D,cAAA,EAAgB;IACd,OAAO,KAAK1N,KAAA,GAAQ0M,OAAA,CAAQnB,KAAA,GAAQmB,OAAA,CAAQlB,WAAA;EAC9C;AACF;;;ACtCO,IAAMmC,MAAA,GAAN,MAAa;EAClBC,QAAA,GAAWjX,YAAA,CAAa;EACxBsN,OAAA,GAAU,KAAK4J,UAAA;EAEftC,KAAA,GAAQ,KAAKuC,aAAA,CAAc,IAAI;EAC/BtC,WAAA,GAAc,KAAKsC,aAAA,CAAc,KAAK;EAEtCC,MAAA,GAASrB,OAAA;EACTsB,QAAA,GAAW7C,SAAA;EACX8C,YAAA,GAAexB,aAAA;EACfyB,KAAA,GAAQ5E,MAAA;EACR6E,SAAA,GAAYnK,UAAA;EACZoK,KAAA,GAAQlB,MAAA;EAER/I,YAAA,GAAekK,IAAA,EAAyB;IACtC,KAAKC,GAAA,CAAI,GAAGD,IAAI;EAClB;EAAA;AAAA;AAAA;EAKAhX,WAAWkM,MAAA,EAA8BgL,QAAA,EAA2D;IAClG,IAAIC,MAAA,GAAyB,EAAC;IAC9B,WAAWnL,KAAA,IAASE,MAAA,EAAQ;MAC1BiL,MAAA,GAASA,MAAA,CAAOC,MAAA,CAAOF,QAAA,CAASvE,IAAA,CAAK,MAAM3G,KAAK,CAAC;MACjD,QAAQA,KAAA,CAAMC,IAAA;QACZ,KAAK;UAAS;YACZ,MAAMoL,UAAA,GAAarL,KAAA;YACnB,WAAWuE,IAAA,IAAQ8G,UAAA,CAAWhH,MAAA,EAAQ;cACpC8G,MAAA,GAASA,MAAA,CAAOC,MAAA,CAAO,KAAKpX,UAAA,CAAWuQ,IAAA,CAAKrE,MAAA,EAAQgL,QAAQ,CAAC;YAC/D;YACA,WAAWvN,GAAA,IAAO0N,UAAA,CAAWlH,IAAA,EAAM;cACjC,WAAWI,IAAA,IAAQ5G,GAAA,EAAK;gBACtBwN,MAAA,GAASA,MAAA,CAAOC,MAAA,CAAO,KAAKpX,UAAA,CAAWuQ,IAAA,CAAKrE,MAAA,EAAQgL,QAAQ,CAAC;cAC/D;YACF;YACA;UACF;QACA,KAAK;UAAQ;YACX,MAAMI,SAAA,GAAYtL,KAAA;YAClBmL,MAAA,GAASA,MAAA,CAAOC,MAAA,CAAO,KAAKpX,UAAA,CAAWsX,SAAA,CAAU/I,KAAA,EAAO2I,QAAQ,CAAC;YACjE;UACF;QACA;UAAS;YACP,MAAMxB,YAAA,GAAe1J,KAAA;YACrB,IAAI,KAAKuK,QAAA,CAAS9W,UAAA,EAAY8X,WAAA,GAAc7B,YAAA,CAAazJ,IAAI,GAAG;cAC9D,KAAKsK,QAAA,CAAS9W,UAAA,CAAW8X,WAAA,CAAY7B,YAAA,CAAazJ,IAAI,EAAEiH,OAAA,CAASqE,WAAA,IAAgB;gBAC/E,MAAMC,OAAA,GAAS9B,YAAA,CAAa6B,WAAW,EAAEE,IAAA,CAAK1E,QAAQ;gBACtDoE,MAAA,GAASA,MAAA,CAAOC,MAAA,CAAO,KAAKpX,UAAA,CAAWwX,OAAA,EAAQN,QAAQ,CAAC;cAC1D,CAAC;YACH,WAAWxB,YAAA,CAAaxJ,MAAA,EAAQ;cAC9BiL,MAAA,GAASA,MAAA,CAAOC,MAAA,CAAO,KAAKpX,UAAA,CAAW0V,YAAA,CAAaxJ,MAAA,EAAQgL,QAAQ,CAAC;YACvE;UACF;MACF;IACF;IACA,OAAOC,MAAA;EACT;EAEAF,IAAA,GAAOD,IAAA,EAAyB;IAC9B,MAAMvX,UAAA,GAA0C,KAAK8W,QAAA,CAAS9W,UAAA,IAAc;MAAEgW,SAAA,EAAW,CAAC;MAAG8B,WAAA,EAAa,CAAC;IAAE;IAE7GP,IAAA,CAAK9D,OAAA,CAASwE,IAAA,IAAS;MAErB,MAAMC,IAAA,GAAO;QAAE,GAAGD;MAAK;MAGvBC,IAAA,CAAKpY,KAAA,GAAQ,KAAKgX,QAAA,CAAShX,KAAA,IAASoY,IAAA,CAAKpY,KAAA,IAAS;MAGlD,IAAImY,IAAA,CAAKjY,UAAA,EAAY;QACnBiY,IAAA,CAAKjY,UAAA,CAAWyT,OAAA,CAAS0E,GAAA,IAAQ;UAC/B,IAAI,CAACA,GAAA,CAAIhX,IAAA,EAAM;YACb,MAAM,IAAI4S,KAAA,CAAM,yBAAyB;UAC3C;UACA,IAAI,cAAcoE,GAAA,EAAK;YACrB,MAAMC,YAAA,GAAepY,UAAA,CAAWgW,SAAA,CAAUmC,GAAA,CAAIhX,IAAI;YAClD,IAAIiX,YAAA,EAAc;cAEhBpY,UAAA,CAAWgW,SAAA,CAAUmC,GAAA,CAAIhX,IAAI,IAAI,aAAYkX,KAAA,EAAM;gBACjD,IAAInC,GAAA,GAAMiC,GAAA,CAAI/X,QAAA,CAASkY,KAAA,CAAM,MAAMD,KAAI;gBACvC,IAAInC,GAAA,KAAQ,OAAO;kBACjBA,GAAA,GAAMkC,YAAA,CAAaE,KAAA,CAAM,MAAMD,KAAI;gBACrC;gBACA,OAAOnC,GAAA;cACT;YACF,OAAO;cACLlW,UAAA,CAAWgW,SAAA,CAAUmC,GAAA,CAAIhX,IAAI,IAAIgX,GAAA,CAAI/X,QAAA;YACvC;UACF;UACA,IAAI,eAAe+X,GAAA,EAAK;YACtB,IAAI,CAACA,GAAA,CAAItM,KAAA,IAAUsM,GAAA,CAAItM,KAAA,KAAU,WAAWsM,GAAA,CAAItM,KAAA,KAAU,UAAW;cACnE,MAAM,IAAIkI,KAAA,CAAM,6CAA6C;YAC/D;YACA,MAAMwE,QAAA,GAAWvY,UAAA,CAAWmY,GAAA,CAAItM,KAAK;YACrC,IAAI0M,QAAA,EAAU;cACZA,QAAA,CAASvD,OAAA,CAAQmD,GAAA,CAAI7X,SAAS;YAChC,OAAO;cACLN,UAAA,CAAWmY,GAAA,CAAItM,KAAK,IAAI,CAACsM,GAAA,CAAI7X,SAAS;YACxC;YACA,IAAI6X,GAAA,CAAIvJ,KAAA,EAAO;cACb,IAAIuJ,GAAA,CAAItM,KAAA,KAAU,SAAS;gBACzB,IAAI7L,UAAA,CAAWoT,UAAA,EAAY;kBACzBpT,UAAA,CAAWoT,UAAA,CAAWnI,IAAA,CAAKkN,GAAA,CAAIvJ,KAAK;gBACtC,OAAO;kBACL5O,UAAA,CAAWoT,UAAA,GAAa,CAAC+E,GAAA,CAAIvJ,KAAK;gBACpC;cACF,WAAWuJ,GAAA,CAAItM,KAAA,KAAU,UAAU;gBACjC,IAAI7L,UAAA,CAAWoU,WAAA,EAAa;kBAC1BpU,UAAA,CAAWoU,WAAA,CAAYnJ,IAAA,CAAKkN,GAAA,CAAIvJ,KAAK;gBACvC,OAAO;kBACL5O,UAAA,CAAWoU,WAAA,GAAc,CAAC+D,GAAA,CAAIvJ,KAAK;gBACrC;cACF;YACF;UACF;UACA,IAAI,iBAAiBuJ,GAAA,IAAOA,GAAA,CAAIL,WAAA,EAAa;YAC3C9X,UAAA,CAAW8X,WAAA,CAAYK,GAAA,CAAIhX,IAAI,IAAIgX,GAAA,CAAIL,WAAA;UACzC;QACF,CAAC;QACDI,IAAA,CAAKlY,UAAA,GAAaA,UAAA;MACpB;MAGA,IAAIiY,IAAA,CAAK7X,QAAA,EAAU;QACjB,MAAMA,QAAA,GAAW,KAAK0W,QAAA,CAAS1W,QAAA,IAAY,IAAIiU,SAAA,CAAU,KAAKyC,QAAQ;QACtE,WAAW0B,IAAA,IAAQP,IAAA,CAAK7X,QAAA,EAAU;UAChC,IAAI,EAAEoY,IAAA,IAAQpY,QAAA,GAAW;YACvB,MAAM,IAAI2T,KAAA,CAAM,aAAayE,IAAI,kBAAkB;UACrD;UACA,IAAI,CAAC,WAAW,QAAQ,EAAEvE,QAAA,CAASuE,IAAI,GAAG;YAExC;UACF;UACA,MAAMC,YAAA,GAAeD,IAAA;UACrB,MAAME,YAAA,GAAeT,IAAA,CAAK7X,QAAA,CAASqY,YAAY;UAC/C,MAAML,YAAA,GAAehY,QAAA,CAASqY,YAAY;UAE1CrY,QAAA,CAASqY,YAAY,IAAI,IAAIJ,KAAA,KAAoB;YAC/C,IAAInC,GAAA,GAAMwC,YAAA,CAAaJ,KAAA,CAAMlY,QAAA,EAAUiY,KAAI;YAC3C,IAAInC,GAAA,KAAQ,OAAO;cACjBA,GAAA,GAAMkC,YAAA,CAAaE,KAAA,CAAMlY,QAAA,EAAUiY,KAAI;YACzC;YACA,OAAOnC,GAAA,IAAO;UAChB;QACF;QACAgC,IAAA,CAAK9X,QAAA,GAAWA,QAAA;MAClB;MACA,IAAI6X,IAAA,CAAK3X,SAAA,EAAW;QAClB,MAAMA,SAAA,GAAY,KAAKwW,QAAA,CAASxW,SAAA,IAAa,IAAI4M,UAAA,CAAW,KAAK4J,QAAQ;QACzE,WAAW0B,IAAA,IAAQP,IAAA,CAAK3X,SAAA,EAAW;UACjC,IAAI,EAAEkY,IAAA,IAAQlY,SAAA,GAAY;YACxB,MAAM,IAAIyT,KAAA,CAAM,cAAcyE,IAAI,kBAAkB;UACtD;UACA,IAAI,CAAC,WAAW,SAAS,OAAO,EAAEvE,QAAA,CAASuE,IAAI,GAAG;YAEhD;UACF;UACA,MAAMG,aAAA,GAAgBH,IAAA;UACtB,MAAMI,aAAA,GAAgBX,IAAA,CAAK3X,SAAA,CAAUqY,aAAa;UAClD,MAAME,aAAA,GAAgBvY,SAAA,CAAUqY,aAAa;UAG7CrY,SAAA,CAAUqY,aAAa,IAAI,IAAIN,KAAA,KAAoB;YACjD,IAAInC,GAAA,GAAM0C,aAAA,CAAcN,KAAA,CAAMhY,SAAA,EAAW+X,KAAI;YAC7C,IAAInC,GAAA,KAAQ,OAAO;cACjBA,GAAA,GAAM2C,aAAA,CAAcP,KAAA,CAAMhY,SAAA,EAAW+X,KAAI;YAC3C;YACA,OAAOnC,GAAA;UACT;QACF;QACAgC,IAAA,CAAK5X,SAAA,GAAYA,SAAA;MACnB;MAGA,IAAI2X,IAAA,CAAK/X,KAAA,EAAO;QACd,MAAMA,KAAA,GAAQ,KAAK4W,QAAA,CAAS5W,KAAA,IAAS,IAAIkW,MAAA,CAAO;QAChD,WAAWoC,IAAA,IAAQP,IAAA,CAAK/X,KAAA,EAAO;UAC7B,IAAI,EAAEsY,IAAA,IAAQtY,KAAA,GAAQ;YACpB,MAAM,IAAI6T,KAAA,CAAM,SAASyE,IAAI,kBAAkB;UACjD;UACA,IAAI,CAAC,WAAW,OAAO,EAAEvE,QAAA,CAASuE,IAAI,GAAG;YAEvC;UACF;UACA,MAAMM,SAAA,GAAYN,IAAA;UAClB,MAAMO,SAAA,GAAYd,IAAA,CAAK/X,KAAA,CAAM4Y,SAAS;UACtC,MAAME,QAAA,GAAW9Y,KAAA,CAAM4Y,SAAS;UAChC,IAAI1C,MAAA,CAAOC,gBAAA,CAAiB4C,GAAA,CAAIT,IAAI,GAAG;YAErCtY,KAAA,CAAM4Y,SAAS,IAAKI,GAAA,IAAiB;cACnC,IAAI,KAAKpC,QAAA,CAAShX,KAAA,EAAO;gBACvB,OAAOqZ,OAAA,CAAQC,OAAA,CAAQL,SAAA,CAAU7F,IAAA,CAAKhT,KAAA,EAAOgZ,GAAG,CAAC,EAAEG,IAAA,CAAKC,IAAA,IAAO;kBAC7D,OAAON,QAAA,CAAS9F,IAAA,CAAKhT,KAAA,EAAOoZ,IAAG;gBACjC,CAAC;cACH;cAEA,MAAMpD,GAAA,GAAM6C,SAAA,CAAU7F,IAAA,CAAKhT,KAAA,EAAOgZ,GAAG;cACrC,OAAOF,QAAA,CAAS9F,IAAA,CAAKhT,KAAA,EAAOgW,GAAG;YACjC;UACF,OAAO;YAELhW,KAAA,CAAM4Y,SAAS,IAAI,IAAIT,KAAA,KAAoB;cACzC,IAAInC,GAAA,GAAM6C,SAAA,CAAUT,KAAA,CAAMpY,KAAA,EAAOmY,KAAI;cACrC,IAAInC,GAAA,KAAQ,OAAO;gBACjBA,GAAA,GAAM8C,QAAA,CAASV,KAAA,CAAMpY,KAAA,EAAOmY,KAAI;cAClC;cACA,OAAOnC,GAAA;YACT;UACF;QACF;QACAgC,IAAA,CAAKhY,KAAA,GAAQA,KAAA;MACf;MAGA,IAAI+X,IAAA,CAAK1X,UAAA,EAAY;QACnB,MAAMgZ,WAAA,GAAa,KAAKzC,QAAA,CAASvW,UAAA;QACjC,MAAMiZ,cAAA,GAAiBvB,IAAA,CAAK1X,UAAA;QAC5B2X,IAAA,CAAK3X,UAAA,GAAa,UAASgM,KAAA,EAAO;UAChC,IAAImL,MAAA,GAAyB,EAAC;UAC9BA,MAAA,CAAOzM,IAAA,CAAKuO,cAAA,CAAetG,IAAA,CAAK,MAAM3G,KAAK,CAAC;UAC5C,IAAIgN,WAAA,EAAY;YACd7B,MAAA,GAASA,MAAA,CAAOC,MAAA,CAAO4B,WAAA,CAAWrG,IAAA,CAAK,MAAM3G,KAAK,CAAC;UACrD;UACA,OAAOmL,MAAA;QACT;MACF;MAEA,KAAKZ,QAAA,GAAW;QAAE,GAAG,KAAKA,QAAA;QAAU,GAAGoB;MAAK;IAC9C,CAAC;IAED,OAAO;EACT;EAEAnB,WAAWhW,GAAA,EAAoB;IAC7B,KAAK+V,QAAA,GAAW;MAAE,GAAG,KAAKA,QAAA;MAAU,GAAG/V;IAAI;IAC3C,OAAO;EACT;EAEAqM,MAAMI,GAAA,EAAaF,QAAA,EAAyB;IAC1C,OAAOkF,MAAA,CAAOK,GAAA,CAAIrF,GAAA,EAAKF,QAAA,IAAW,KAAKwJ,QAAQ;EACjD;EAEAxC,OAAO7H,MAAA,EAAiBa,QAAA,EAAyB;IAC/C,OAAOsI,OAAA,CAAQnB,KAAA,CAAMhI,MAAA,EAAQa,QAAA,IAAW,KAAKwJ,QAAQ;EACvD;EAEQE,cAAcyC,SAAA,EAAoB;IAQxC,MAAMC,MAAA,GAAyBjF,CAACjH,GAAA,EAAaF,QAAA,KAAwC;MACnF,MAAMqM,OAAA,GAAU;QAAE,GAAGrM;MAAQ;MAC7B,MAAMvM,GAAA,GAAM;QAAE,GAAG,KAAK+V,QAAA;QAAU,GAAG6C;MAAQ;MAE3C,MAAMC,UAAA,GAAa,KAAKC,OAAA,CAAQ,CAAC,CAAC9Y,GAAA,CAAIV,MAAA,EAAQ,CAAC,CAACU,GAAA,CAAIjB,KAAK;MAGzD,IAAI,KAAKgX,QAAA,CAAShX,KAAA,KAAU,QAAQ6Z,OAAA,CAAQ7Z,KAAA,KAAU,OAAO;QAC3D,OAAO8Z,UAAA,CAAW,IAAI7F,KAAA,CAAM,oIAAoI,CAAC;MACnK;MAGA,IAAI,OAAOvG,GAAA,KAAQ,eAAeA,GAAA,KAAQ,MAAM;QAC9C,OAAOoM,UAAA,CAAW,IAAI7F,KAAA,CAAM,gDAAgD,CAAC;MAC/E;MACA,IAAI,OAAOvG,GAAA,KAAQ,UAAU;QAC3B,OAAOoM,UAAA,CAAW,IAAI7F,KAAA,CAAM,0CACxBpB,MAAA,CAAOmH,SAAA,CAAUC,QAAA,CAAS7G,IAAA,CAAK1F,GAAG,IAAI,mBAAmB,CAAC;MAChE;MAEA,IAAIzM,GAAA,CAAIb,KAAA,EAAO;QACba,GAAA,CAAIb,KAAA,CAAMiN,OAAA,GAAUpM,GAAA;QACpBA,GAAA,CAAIb,KAAA,CAAMgJ,KAAA,GAAQuQ,SAAA;MACpB;MAEA,MAAMvN,MAAA,GAAQnL,GAAA,CAAIb,KAAA,GAAQa,GAAA,CAAIb,KAAA,CAAMyW,YAAA,CAAa,IAAK8C,SAAA,GAAYjH,MAAA,CAAOK,GAAA,GAAML,MAAA,CAAOM,SAAA;MACtF,MAAMgD,OAAA,GAAS/U,GAAA,CAAIb,KAAA,GAAQa,GAAA,CAAIb,KAAA,CAAM0W,aAAA,CAAc,IAAK6C,SAAA,GAAY7D,OAAA,CAAQnB,KAAA,GAAQmB,OAAA,CAAQlB,WAAA;MAE5F,IAAI3T,GAAA,CAAIjB,KAAA,EAAO;QACb,OAAOqZ,OAAA,CAAQC,OAAA,CAAQrY,GAAA,CAAIb,KAAA,GAAQa,GAAA,CAAIb,KAAA,CAAMqW,UAAA,CAAW/I,GAAG,IAAIA,GAAG,EAC/D6L,IAAA,CAAKW,IAAA,IAAO9N,MAAA,CAAM8N,IAAA,EAAKjZ,GAAG,CAAC,EAC3BsY,IAAA,CAAK5M,MAAA,IAAU1L,GAAA,CAAIb,KAAA,GAAQa,GAAA,CAAIb,KAAA,CAAMwW,gBAAA,CAAiBjK,MAAM,IAAIA,MAAM,EACtE4M,IAAA,CAAK5M,MAAA,IAAU1L,GAAA,CAAIR,UAAA,GAAa4Y,OAAA,CAAQc,GAAA,CAAI,KAAK1Z,UAAA,CAAWkM,MAAA,EAAQ1L,GAAA,CAAIR,UAAU,CAAC,EAAE8Y,IAAA,CAAK,MAAM5M,MAAM,IAAIA,MAAM,EAChH4M,IAAA,CAAK5M,MAAA,IAAUqJ,OAAA,CAAOrJ,MAAA,EAAQ1L,GAAG,CAAC,EAClCsY,IAAA,CAAK5P,KAAA,IAAQ1I,GAAA,CAAIb,KAAA,GAAQa,GAAA,CAAIb,KAAA,CAAMuW,WAAA,CAAYhN,KAAI,IAAIA,KAAI,EAC3DyQ,KAAA,CAAMN,UAAU;MACrB;MAEA,IAAI;QACF,IAAI7Y,GAAA,CAAIb,KAAA,EAAO;UACbsN,GAAA,GAAMzM,GAAA,CAAIb,KAAA,CAAMqW,UAAA,CAAW/I,GAAG;QAChC;QACA,IAAIf,MAAA,GAASP,MAAA,CAAMsB,GAAA,EAAKzM,GAAG;QAC3B,IAAIA,GAAA,CAAIb,KAAA,EAAO;UACbuM,MAAA,GAAS1L,GAAA,CAAIb,KAAA,CAAMwW,gBAAA,CAAiBjK,MAAM;QAC5C;QACA,IAAI1L,GAAA,CAAIR,UAAA,EAAY;UAClB,KAAKA,UAAA,CAAWkM,MAAA,EAAQ1L,GAAA,CAAIR,UAAU;QACxC;QACA,IAAIkJ,KAAA,GAAOqM,OAAA,CAAOrJ,MAAA,EAAQ1L,GAAG;QAC7B,IAAIA,GAAA,CAAIb,KAAA,EAAO;UACbuJ,KAAA,GAAO1I,GAAA,CAAIb,KAAA,CAAMuW,WAAA,CAAYhN,KAAI;QACnC;QACA,OAAOA,KAAA;MACT,SAAS0Q,CAAA,EAAG;QACV,OAAOP,UAAA,CAAWO,CAAU;MAC9B;IACF;IAEA,OAAOT,MAAA;EACT;EAEQG,QAAQxZ,MAAA,EAAiBP,KAAA,EAAgB;IAC/C,OAAQqa,CAAA,IAAuC;MAC7CA,CAAA,CAAEC,OAAA,IAAW;MAEb,IAAI/Z,MAAA,EAAQ;QACV,MAAMga,GAAA,GAAM,mCACR7Q,OAAA,CAAO2Q,CAAA,CAAEC,OAAA,GAAU,IAAI,IAAI,IAC3B;QACJ,IAAIta,KAAA,EAAO;UACT,OAAOqZ,OAAA,CAAQC,OAAA,CAAQiB,GAAG;QAC5B;QACA,OAAOA,GAAA;MACT;MAEA,IAAIva,KAAA,EAAO;QACT,OAAOqZ,OAAA,CAAQmB,MAAA,CAAOH,CAAC;MACzB;MACA,MAAMA,CAAA;IACR;EACF;AACF;;;ACjVA,IAAMI,cAAA,GAAiB,IAAI1D,MAAA,CAAO;AAqB3B,SAAS2D,OAAOhN,GAAA,EAAazM,GAAA,EAAsD;EACxF,OAAOwZ,cAAA,CAAe9F,KAAA,CAAMjH,GAAA,EAAKzM,GAAG;AACtC;AAOAyZ,MAAA,CAAOrN,OAAA,GACPqN,MAAA,CAAOzD,UAAA,GAAa,UAASzJ,QAAA,EAAwB;EACnDiN,cAAA,CAAexD,UAAA,CAAWzJ,QAAO;EACjCkN,MAAA,CAAO1D,QAAA,GAAWyD,cAAA,CAAezD,QAAA;EACjCrW,cAAA,CAAe+Z,MAAA,CAAO1D,QAAQ;EAC9B,OAAO0D,MAAA;AACT;AAKAA,MAAA,CAAOC,WAAA,GAAc5a,YAAA;AAErB2a,MAAA,CAAO1D,QAAA,GAAWtW,SAAA;AAMlBga,MAAA,CAAOhD,GAAA,GAAM,aAAYD,IAAA,EAAyB;EAChDgD,cAAA,CAAe/C,GAAA,CAAI,GAAGD,IAAI;EAC1BiD,MAAA,CAAO1D,QAAA,GAAWyD,cAAA,CAAezD,QAAA;EACjCrW,cAAA,CAAe+Z,MAAA,CAAO1D,QAAQ;EAC9B,OAAO0D,MAAA;AACT;AAMAA,MAAA,CAAOja,UAAA,GAAa,UAASkM,MAAA,EAA8BgL,QAAA,EAA2D;EACpH,OAAO8C,cAAA,CAAeha,UAAA,CAAWkM,MAAA,EAAQgL,QAAQ;AACnD;AASA+C,MAAA,CAAO9F,WAAA,GAAc6F,cAAA,CAAe7F,WAAA;AAKpC8F,MAAA,CAAOvD,MAAA,GAASrB,OAAA;AAChB4E,MAAA,CAAOlG,MAAA,GAASsB,OAAA,CAAQnB,KAAA;AACxB+F,MAAA,CAAOtD,QAAA,GAAW7C,SAAA;AAClBmG,MAAA,CAAOrD,YAAA,GAAexB,aAAA;AACtB6E,MAAA,CAAOpD,KAAA,GAAQ5E,MAAA;AACfgI,MAAA,CAAOpN,KAAA,GAAQoF,MAAA,CAAOK,GAAA;AACtB2H,MAAA,CAAOnD,SAAA,GAAYnK,UAAA;AACnBsN,MAAA,CAAOlD,KAAA,GAAQlB,MAAA;AACfoE,MAAA,CAAO/F,KAAA,GAAQ+F,MAAA;AAER,IAAMrN,OAAA,GAAUqN,MAAA,CAAOrN,OAAA;AACvB,IAAM4J,UAAA,GAAayD,MAAA,CAAOzD,UAAA;AAC1B,IAAMS,GAAA,GAAMgD,MAAA,CAAOhD,GAAA;AACnB,IAAMjX,UAAA,GAAaia,MAAA,CAAOja,UAAA;AAC1B,IAAMmU,WAAA,GAAc8F,MAAA,CAAO9F,WAAA;AAC3B,IAAMD,KAAA,GAAQ+F,MAAA;AACd,IAAMlG,MAAA,GAASsB,OAAA,CAAQnB,KAAA;AACvB,IAAMrH,KAAA,GAAQoF,MAAA,CAAOK,GAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}